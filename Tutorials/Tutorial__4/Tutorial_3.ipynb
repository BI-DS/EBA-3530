{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47611360",
   "metadata": {},
   "source": [
    "# Tutorial 3:\n",
    "\n",
    "In this tutorial we are going to cover causal inference. \n",
    "\n",
    "### 0.0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8c6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python packages\n",
    "%matplotlib inline  \n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "plt.rcParams[\"figure.figsize\"] = [10,8]  # Set default figure size\n",
    "\n",
    "# set a random seed\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69edae7",
   "metadata": {},
   "source": [
    "### 1 OVB:\n",
    "\n",
    "##### 1.1 Simulating data:\n",
    "\n",
    "For this exercise, we will assume the following DGP in population:\n",
    "\n",
    "$$\n",
    " y = \\alpha + \\beta_1 \\cdot x_1 + \\beta_2\\cdot w + \\varepsilon, \\: \\: \\varepsilon\\sim N(0,1) \n",
    "$$\n",
    "\n",
    "$x_1$ and $w$ are related in the following way:\n",
    "\n",
    "$$\n",
    "w = \\pi \\cdot x_1 + u, \\: \\: u \\sim N(0,1)\n",
    "$$\n",
    "\n",
    "\n",
    "As in the lecture, $w$ denotes an omitted variable. To make the problem less abstract, suppose that the data set contains observations on working individuals. $y$ denotes hourly wage, $x_1$ denotes years of education, and $w$ denotes innate ability, which cannot be observed.\n",
    "\n",
    "\n",
    "What do you think:\n",
    "* Are wages and education positively or negatively correlated?\n",
    "* Are wages and ability positively or negatively correlated?\n",
    "* Are ability and education positively or negatively correlated?\n",
    "* In which direction do you expect the bias to go?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f096aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simul(N, π, α, β1, β2):\n",
    "    \"\"\"\n",
    "    This function simulates a data set that to illustrate the effects of OVB.\n",
    "    \n",
    "    The population model is given by: \n",
    "        y = α + β1*x1 + β2*w + ε \n",
    "        w and x1 are correlated random variables that both have a causal effect on y\n",
    "        \n",
    "    To create correlation, w is generated as:\n",
    "        w = π*x1 + u\n",
    "        \n",
    "    ε and u are residuals, γ1, β1 and β2 are regression coefficients. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # draw x1, u, and ε\n",
    "    x1 = np.random.randn(N)\n",
    "    u  = np.random.randn(N)\n",
    "    ε  = np.random.randn(N)\n",
    "    \n",
    "    # generate x2 such that it is correlated with x1\n",
    "    w = π*x1 + u\n",
    "    \n",
    "    # generate y\n",
    "    y = α + β1*x1 + β2*w + ε\n",
    "    \n",
    "    return y, x1, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d8d06",
   "metadata": {},
   "source": [
    "Let us now simulate some data with a 1000 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0663c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N  = 1000\n",
    "π  = 0.5\n",
    "α  = 1\n",
    "β1 = 0.3\n",
    "β2 = 0.6\n",
    "\n",
    "simulated_data = simul(N, π, α, β1, β2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27651f8",
   "metadata": {},
   "source": [
    "To make the problem less abstract, let's check whether the variables are indeed correlated. Since we know the true DGP, we can compute the correlation analytically:\n",
    "\n",
    "Inserting for `w` into the equation for `y`, we get:\n",
    "\n",
    "$$\n",
    "    y = \\alpha + \\beta_1 \\cdot x_1 + \\beta_2\\cdot(\\pi \\cdot x_1 + u) + \\varepsilon \n",
    "$$\n",
    "\n",
    "The correlation coefficient of $y$ and $x_1$ is given by (you can confirm the algebra at home): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb24027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.457495710997814"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(β1 + β2*π) / np.sqrt(β1**2 + (β2**2)*(π**2) + β1*β2*π*2 + β2**2 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f9caf",
   "metadata": {},
   "source": [
    "Let's now compute the correlation between `y` and `x1` and `w` using `pd.corrcoef` as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e484a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.45898365, 0.60515368],\n",
       "       [0.45898365, 1.        , 0.46739167],\n",
       "       [0.60515368, 0.46739167, 1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(simulated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95b141",
   "metadata": {},
   "source": [
    "As we can see, our predictions are correct. Both `x1` and `w` are correlated with one another and the outcome variable `y`. Our function thus seems to do its job. We can now turn to estimating regressions including and excluding `w`. Will OLS be able to uncover the true coefficient?\n",
    "\n",
    "##### 1.2 Estimating the population  model (including $w$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460b0a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.406</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.405</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   340.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.84e-113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:52</td>     <th>  Log-Likelihood:    </th> <td> -1419.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2845.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   997</td>      <th>  BIC:               </th> <td>   2860.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0088</td> <td>    0.032</td> <td>   31.834</td> <td> 0.000</td> <td>    0.947</td> <td>    1.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.2987</td> <td>    0.037</td> <td>    8.162</td> <td> 0.000</td> <td>    0.227</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.5621</td> <td>    0.031</td> <td>   18.101</td> <td> 0.000</td> <td>    0.501</td> <td>    0.623</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.664</td> <th>  Durbin-Watson:     </th> <td>   2.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.160</td> <th>  Jarque-Bera (JB):  </th> <td>   3.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.074</td> <th>  Prob(JB):          </th> <td>   0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.761</td> <th>  Cond. No.          </th> <td>    1.71</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.406\n",
       "Model:                            OLS   Adj. R-squared:                  0.405\n",
       "Method:                 Least Squares   F-statistic:                     340.6\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):          1.84e-113\n",
       "Time:                        19:26:52   Log-Likelihood:                -1419.4\n",
       "No. Observations:                1000   AIC:                             2845.\n",
       "Df Residuals:                     997   BIC:                             2860.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.0088      0.032     31.834      0.000       0.947       1.071\n",
       "x1             0.2987      0.037      8.162      0.000       0.227       0.370\n",
       "x2             0.5621      0.031     18.101      0.000       0.501       0.623\n",
       "==============================================================================\n",
       "Omnibus:                        3.664   Durbin-Watson:                   2.069\n",
       "Prob(Omnibus):                  0.160   Jarque-Bera (JB):                3.292\n",
       "Skew:                          -0.074   Prob(JB):                        0.193\n",
       "Kurtosis:                       2.761   Cond. No.                         1.71\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# setting up the regression matrices\n",
    "Y = simulated_data[0][:,None]\n",
    "\n",
    "# add a constant\n",
    "X = np.hstack((np.ones([Y.shape[0],1]), simulated_data[1][:,None], simulated_data[2][:,None]))\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119938f",
   "metadata": {},
   "source": [
    "As we can see from the estimation output, OLS applied to the \"true\" model yields consistent parameter estimates. Let's now omit `w` from the model to see the effect of omitted variable bias.\n",
    "\n",
    "##### 1.3 Estimating the model without `w`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab41173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   266.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>2.96e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:52</td>     <th>  Log-Likelihood:    </th> <td> -1561.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   3127.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   3137.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0178</td> <td>    0.037</td> <td>   27.880</td> <td> 0.000</td> <td>    0.946</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6083</td> <td>    0.037</td> <td>   16.320</td> <td> 0.000</td> <td>    0.535</td> <td>    0.681</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.643</td> <th>  Durbin-Watson:     </th> <td>   2.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.440</td> <th>  Jarque-Bera (JB):  </th> <td>   1.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.076</td> <th>  Prob(JB):          </th> <td>   0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.867</td> <th>  Cond. No.          </th> <td>    1.02</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.211\n",
       "Model:                            OLS   Adj. R-squared:                  0.210\n",
       "Method:                 Least Squares   F-statistic:                     266.4\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):           2.96e-53\n",
       "Time:                        19:26:52   Log-Likelihood:                -1561.5\n",
       "No. Observations:                1000   AIC:                             3127.\n",
       "Df Residuals:                     998   BIC:                             3137.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.0178      0.037     27.880      0.000       0.946       1.089\n",
       "x1             0.6083      0.037     16.320      0.000       0.535       0.681\n",
       "==============================================================================\n",
       "Omnibus:                        1.643   Durbin-Watson:                   2.088\n",
       "Prob(Omnibus):                  0.440   Jarque-Bera (JB):                1.706\n",
       "Skew:                          -0.076   Prob(JB):                        0.426\n",
       "Kurtosis:                       2.867   Cond. No.                         1.02\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a constant\n",
    "X = np.hstack((np.ones([Y.shape[0],1]), simulated_data[1][:,None]))\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f529fd",
   "metadata": {},
   "source": [
    "As we can see, OLS fails to consistently estimate the true parameters, because on of the fundamental assumptions is violated. Also, note that we can even reject `H0: β1 = 0.3`! This can lead to wrong conclusions in real life applications! Keep in mind that these results are invalid!\n",
    "\n",
    "###### The size and direction of the bias\n",
    "\n",
    "In class we showed that in the case of OVB, OLS will falsely attribute parts of the effect of `w` on `y` to `x1`.\n",
    "\n",
    "Formally:\n",
    "\n",
    "$$\n",
    "\\hat{\\delta} = \\hat{\\beta_1} + \\hat{\\beta_2}\\cdot \\hat{\\pi}\n",
    "$$\n",
    "\n",
    "Given our simulated data and the regression output from above, we can confirm this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f6214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "δ1 = β1 + β2*π\n",
    "print(δ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e4897",
   "metadata": {},
   "source": [
    "The remaining differences from this result are due to sampling variability.\n",
    "\n",
    "In class you also learned how the bias depends on the sign of the true parameters. As a reminder:\n",
    "\n",
    "|            | Corr(x1,w)>0 |  Corr(x1,w)<0 |\n",
    "| :---       |    :----:     |     :----:     | \n",
    "| β2>0       |       +       |        -       |  \n",
    "| β2<0       |       -       |        +       |\n",
    "\n",
    "Since `x1` and `w`, as well as `w` and `y` are positively correlated, we find the coefficient to be positively biased in our simulation. As a counterexample, let's generate a new DGP where $\\beta_2$ is negative and re-run out estimation excluding `w` from the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e971a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.1449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.704</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:53</td>     <th>  Log-Likelihood:    </th> <td> -1550.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   3105.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   3115.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0232</td> <td>    0.036</td> <td>   28.342</td> <td> 0.000</td> <td>    0.952</td> <td>    1.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0138</td> <td>    0.036</td> <td>   -0.381</td> <td> 0.704</td> <td>   -0.085</td> <td>    0.057</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.464</td> <th>  Durbin-Watson:     </th> <td>   1.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.793</td> <th>  Jarque-Bera (JB):  </th> <td>   0.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.052</td> <th>  Prob(JB):          </th> <td>   0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.977</td> <th>  Cond. No.          </th> <td>    1.01</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                    0.1449\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):              0.704\n",
       "Time:                        19:26:53   Log-Likelihood:                -1550.4\n",
       "No. Observations:                1000   AIC:                             3105.\n",
       "Df Residuals:                     998   BIC:                             3115.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.0232      0.036     28.342      0.000       0.952       1.094\n",
       "x1            -0.0138      0.036     -0.381      0.704      -0.085       0.057\n",
       "==============================================================================\n",
       "Omnibus:                        0.464   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.793   Jarque-Bera (JB):                0.479\n",
       "Skew:                           0.052   Prob(JB):                        0.787\n",
       "Kurtosis:                       2.977   Cond. No.                         1.01\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate a new DGP with negative β2\n",
    "simulated_data2 = simul(N, π, α, β1, -β2)\n",
    "\n",
    "# extract Y\n",
    "Y = simulated_data2[0][:,None]\n",
    "\n",
    "# add a constant\n",
    "X = np.hstack((np.ones([Y.shape[0],1]), simulated_data2[1][:,None]))\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb83d2",
   "metadata": {},
   "source": [
    "As we can see, the estimated coefficient is now negative. Moreover, we can no longer reject `H0: β1 = 0`. Let's plug it into out formula for calculating the bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afc20437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "δ1 = β1 + -β2*π\n",
    "print(δ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9ae14",
   "metadata": {},
   "source": [
    "While the true coefficient from the simulation is 0.3, the correlation structure between `x1`, `w`, and `y` is such that OLS will underestimate the effect of `x1` on `y`. In our case the bias is so large that OLS will estimate the effect to be 0! Recall that the effect is positive and equal to 0.3 in our simulations! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a8006",
   "metadata": {},
   "source": [
    "###### 1.4 Control variables:\n",
    "\n",
    "Lastly, let's suppose that we have a control variable at hand that is correlated with `w`. For simplicity, let's assume:\n",
    "\n",
    "$$\n",
    "x_3 = a + b \\cdot w + \\xi, \\: \\: \\: \\xi \\sim N(0,1) \n",
    "$$\n",
    "\n",
    "We will write a function and see how the inclusion of a control variable impacts our bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecac868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genX3(w, a, b):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function simulates a control variable.\n",
    "    \"\"\"\n",
    "    \n",
    "    # read out N\n",
    "    N = len(w)\n",
    "    \n",
    "    # generate x3\n",
    "    x3 = a + b*w + np.random.rand(N)[:,None]\n",
    "    \n",
    "    return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056793d4",
   "metadata": {},
   "source": [
    "To start off, let's compute an example with `a=0` and `b=0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7846918a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   281.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.24e-97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:53</td>     <th>  Log-Likelihood:    </th> <td> -1456.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2918.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   997</td>      <th>  BIC:               </th> <td>   2933.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5895</td> <td>    0.043</td> <td>   13.658</td> <td> 0.000</td> <td>    0.505</td> <td>    0.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.3736</td> <td>    0.037</td> <td>   10.126</td> <td> 0.000</td> <td>    0.301</td> <td>    0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8454</td> <td>    0.055</td> <td>   15.306</td> <td> 0.000</td> <td>    0.737</td> <td>    0.954</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.330</td> <th>  Durbin-Watson:     </th> <td>   2.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.042</td> <th>  Jarque-Bera (JB):  </th> <td>   5.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.093</td> <th>  Prob(JB):          </th> <td>  0.0725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.698</td> <th>  Cond. No.          </th> <td>    2.41</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.361\n",
       "Model:                            OLS   Adj. R-squared:                  0.360\n",
       "Method:                 Least Squares   F-statistic:                     281.4\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):           1.24e-97\n",
       "Time:                        19:26:53   Log-Likelihood:                -1456.0\n",
       "No. Observations:                1000   AIC:                             2918.\n",
       "Df Residuals:                     997   BIC:                             2933.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5895      0.043     13.658      0.000       0.505       0.674\n",
       "x1             0.3736      0.037     10.126      0.000       0.301       0.446\n",
       "x2             0.8454      0.055     15.306      0.000       0.737       0.954\n",
       "==============================================================================\n",
       "Omnibus:                        6.330   Durbin-Watson:                   2.073\n",
       "Prob(Omnibus):                  0.042   Jarque-Bera (JB):                5.248\n",
       "Skew:                          -0.093   Prob(JB):                       0.0725\n",
       "Kurtosis:                       2.698   Cond. No.                         2.41\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = genX3(simulated_data[2][:,None], 0, 0.5)\n",
    "\n",
    "# extract Y\n",
    "Y = simulated_data[0][:,None]\n",
    "\n",
    "# add a constant\n",
    "X = np.hstack((np.ones([Y.shape[0],1]), simulated_data[1][:,None], x3))\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca028f4",
   "metadata": {},
   "source": [
    "We can see that the bias is less extreme in this case. Finally, let's investigate how the bias of depends on the correlation between `w` and `x3`, so the omitted variable and our control. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e2cf59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# define a function that computes the bias for different values of b\n",
    "def get_bias(Y, X1, w, β1, b):\n",
    "    \n",
    "    \"\"\"\n",
    "    function for computing the bias based on different b\n",
    "    \"\"\"\n",
    "    \n",
    "    bias = []\n",
    "    \n",
    "    for i in b:\n",
    "\n",
    "        X3 = genX3(w, 0, i)\n",
    "        \n",
    "        X = np.hstack((np.ones([Y.shape[0],1]), X1, X3))\n",
    "    \n",
    "        # run the regression\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        \n",
    "        bias.append(results.params[1] - β1)\n",
    "    \n",
    "    return bias\n",
    "\n",
    "# create an interval for b\n",
    "b = np.arange(0,1.01,0.01)\n",
    "\n",
    "# call the get_bias function\n",
    "bias = get_bias(Y, simulated_data[1][:,None], simulated_data[2][:,None], β1, b)\n",
    "\n",
    "# plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(b, bias)\n",
    "plt.xlabel('b')\n",
    "plt.ylabel('bias')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2f950",
   "metadata": {},
   "source": [
    "Thus, the more highly the control variable is correlated with the omitted variable, the smaller the bias in the OLS parameter. It also tells you, however, that the added controls must be useful. Just adding a bunch of controls as such is not going to mitigate the ovb and we should not place more trust into models just because they are larger. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a04c8",
   "metadata": {},
   "source": [
    "### 2.0 Instrumental variables:\n",
    "\n",
    "We are again going to simulate a DGP to illustrate 2SLS.\n",
    "\n",
    "Let us assume the following model:\n",
    "\n",
    "$$\n",
    "X_1 = \\gamma\\cdot Z + \\xi, \\:\\: \\xi\\sim N(0,1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 \\cdot X_1 + u, \\:\\: u\\sim N(0,1)\n",
    "$$\n",
    "\n",
    "Note that the \"endogenous part\" of $X_1$ is expressed as $\\xi$. In a first step, let us assume that $u$ and $\\xi$ are uncorrelated. In this case, we do not have an omitted variable problem and OLS should consistently estimate the true parameter. This is, because $X_1$ is only endogenous due to correlation between $\\xi$ and $u$. In a next step, we will make $u$ and $\\xi$ correlated, by assuming:\n",
    "\n",
    "$$\n",
    "u = b\\cdot \\xi + \\eta, \\:\\: \\eta\\sim N(0,1)\n",
    "$$\n",
    "\n",
    "Two things are important here. First, note that the instrument `Z` only appears in the equation for `X1` but is itself not included in the population equation for `Y`. `Z` should hence only have an effect on `Y` through `X1`. Second, somewhat trivially, because `Z` is in the population equation of `X1`, it is correlated with `X1`. The additional assumptions necessary for IV are hence fulfilled by construction. Later, we will relax these assumptions and see what happens. \n",
    "\n",
    "Let's start by writing a simulation function.\n",
    "\n",
    "##### 2.1 A quick OLS investigation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a060e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simul_IV(N, γ, β0, β1, b):\n",
    "    \"\"\"\n",
    "    This function simulates a data set that to illustrate the properties of IV regression.       \n",
    "    \"\"\"\n",
    "    \n",
    "    # draw x1, u, and ε\n",
    "    z = np.random.randn(N)\n",
    "    ξ  = np.random.randn(N)\n",
    "    η  = np.random.randn(N)\n",
    "    \n",
    "    # generate x1 such that it is correlated with x1\n",
    "    x1 = γ*z + ξ\n",
    "    \n",
    "    # generate u\n",
    "    u = b*ξ + η\n",
    "    \n",
    "    # generate y\n",
    "    y = β0 + β1*x1 + u\n",
    "    \n",
    "    return y, x1, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7227309",
   "metadata": {},
   "source": [
    "As mentioned, let's first see what happens, if $\\xi$ and $u$ are uncorrelated, by setting $b=0$. As before, we will run OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b00c17cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   479.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>4.93e-87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:54</td>     <th>  Log-Likelihood:    </th> <td> -1427.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2859.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   2868.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9597</td> <td>    0.032</td> <td>   30.049</td> <td> 0.000</td> <td>    0.897</td> <td>    1.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6338</td> <td>    0.029</td> <td>   21.886</td> <td> 0.000</td> <td>    0.577</td> <td>    0.691</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.465</td> <th>  Durbin-Watson:     </th> <td>   2.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.793</td> <th>  Jarque-Bera (JB):  </th> <td>   0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.042</td> <th>  Prob(JB):          </th> <td>   0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.046</td> <th>  Cond. No.          </th> <td>    1.11</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.324\n",
       "Model:                            OLS   Adj. R-squared:                  0.324\n",
       "Method:                 Least Squares   F-statistic:                     479.0\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):           4.93e-87\n",
       "Time:                        19:26:54   Log-Likelihood:                -1427.3\n",
       "No. Observations:                1000   AIC:                             2859.\n",
       "Df Residuals:                     998   BIC:                             2868.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9597      0.032     30.049      0.000       0.897       1.022\n",
       "x1             0.6338      0.029     21.886      0.000       0.577       0.691\n",
       "==============================================================================\n",
       "Omnibus:                        0.465   Durbin-Watson:                   2.005\n",
       "Prob(Omnibus):                  0.793   Jarque-Bera (JB):                0.382\n",
       "Skew:                           0.042   Prob(JB):                        0.826\n",
       "Kurtosis:                       3.046   Cond. No.                         1.11\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set simulation parameters\n",
    "N = 1000\n",
    "γ = 0.5\n",
    "β0 = 1\n",
    "β1 = 0.6\n",
    "b = 0\n",
    "\n",
    "# simulate data\n",
    "IV_data = simul_IV(N, γ, β0, β1, b)\n",
    "\n",
    "# setting up the regression matrices\n",
    "Y = IV_data[0][:,None]\n",
    "\n",
    "# add a constant\n",
    "X = np.hstack((np.ones([Y.shape[0],1]), IV_data[1][:,None]))\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64388cf9",
   "metadata": {},
   "source": [
    "As we can see, OLS estimates the parameter consistently up to sampling variability. We will now make $\\xi$ and $u$ correlated, by setting $b\\neq 0$ and re-run the OLS estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e05536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.559</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.558</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1263.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>2.00e-179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:54</td>     <th>  Log-Likelihood:    </th> <td> -1436.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2878.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   2888.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0478</td> <td>    0.032</td> <td>   32.485</td> <td> 0.000</td> <td>    0.985</td> <td>    1.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.9903</td> <td>    0.028</td> <td>   35.538</td> <td> 0.000</td> <td>    0.936</td> <td>    1.045</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.373</td> <th>  Durbin-Watson:     </th> <td>   1.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.830</td> <th>  Jarque-Bera (JB):  </th> <td>   0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.037</td> <th>  Prob(JB):          </th> <td>   0.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.927</td> <th>  Cond. No.          </th> <td>    1.16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.559\n",
       "Model:                            OLS   Adj. R-squared:                  0.558\n",
       "Method:                 Least Squares   F-statistic:                     1263.\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):          2.00e-179\n",
       "Time:                        19:26:54   Log-Likelihood:                -1436.9\n",
       "No. Observations:                1000   AIC:                             2878.\n",
       "Df Residuals:                     998   BIC:                             2888.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.0478      0.032     32.485      0.000       0.985       1.111\n",
       "x1             0.9903      0.028     35.538      0.000       0.936       1.045\n",
       "==============================================================================\n",
       "Omnibus:                        0.373   Durbin-Watson:                   1.939\n",
       "Prob(Omnibus):                  0.830   Jarque-Bera (JB):                0.448\n",
       "Skew:                           0.037   Prob(JB):                        0.799\n",
       "Kurtosis:                       2.927   Cond. No.                         1.16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set simulation parameters\n",
    "N = 1000\n",
    "γ = 0.5\n",
    "β0 = 1\n",
    "β1 = 0.6\n",
    "b = 0.5\n",
    "\n",
    "# simulate data\n",
    "IV_data = simul_IV(N, γ, β0, β1, b)\n",
    "\n",
    "# setting up the regression matrices\n",
    "Y = IV_data[0][:,None]\n",
    "\n",
    "# add a constant\n",
    "X = np.hstack((np.ones([Y.shape[0],1]), IV_data[1][:,None]))\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d8efcf",
   "metadata": {},
   "source": [
    "As we can see, the coefficient estimates are severely biased and estimation is inconsistent. We are back to the OVB case. Pause for a minute to recall where the endogeneity comes from. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3f95ef",
   "metadata": {},
   "source": [
    "##### 2.2 Applying 2SLS:\n",
    "\n",
    "Before we jump into 2SLS, let's quickly check whether the instrument is weak. We will use the rule-of-thumb criterion for the first stage regression, by examining the F-statistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb3957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   280.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.21e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:54</td>     <th>  Log-Likelihood:    </th> <td> -1440.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2885.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   2895.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0613</td> <td>    0.032</td> <td>    1.893</td> <td> 0.059</td> <td>   -0.002</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.5517</td> <td>    0.033</td> <td>   16.743</td> <td> 0.000</td> <td>    0.487</td> <td>    0.616</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.380</td> <th>  Durbin-Watson:     </th> <td>   1.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.501</td> <th>  Jarque-Bera (JB):  </th> <td>   1.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.090</td> <th>  Prob(JB):          </th> <td>   0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.989</td> <th>  Cond. No.          </th> <td>    1.03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.219\n",
       "Model:                            OLS   Adj. R-squared:                  0.219\n",
       "Method:                 Least Squares   F-statistic:                     280.3\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):           1.21e-55\n",
       "Time:                        19:26:54   Log-Likelihood:                -1440.6\n",
       "No. Observations:                1000   AIC:                             2885.\n",
       "Df Residuals:                     998   BIC:                             2895.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0613      0.032      1.893      0.059      -0.002       0.125\n",
       "x1             0.5517      0.033     16.743      0.000       0.487       0.616\n",
       "==============================================================================\n",
       "Omnibus:                        1.380   Durbin-Watson:                   1.974\n",
       "Prob(Omnibus):                  0.501   Jarque-Bera (JB):                1.369\n",
       "Skew:                           0.090   Prob(JB):                        0.504\n",
       "Kurtosis:                       2.989   Cond. No.                         1.03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the regression\n",
    "model = sm.OLS(IV_data[1][:,None], np.hstack((np.ones([N,1]), IV_data[2][:,None])))\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "params = results.params\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11d161",
   "metadata": {},
   "source": [
    "We can see that the F-statistic is a lot bigger than 10. Weak instruments should thus not be a problem (by construction we set $\\gamma$ to a rather large value). We also know that $z$ is exogenous by construction. We are now ready to apply 2SLS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce435fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:              dependent   R-squared:                      0.4816\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.4811\n",
      "No. Observations:                1000   F-statistic:                    93.413\n",
      "Date:                Fri, Apr 23 2021   P-value (F-stat)                0.0000\n",
      "Time:                        19:26:55   Distribution:                  chi2(1)\n",
      "Cov. Estimator:            unadjusted                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "exog           1.0655     0.0350     30.418     0.0000      0.9968      1.1341\n",
      "endog          0.6227     0.0644     9.6650     0.0000      0.4964      0.7489\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: endog\n",
      "Instruments: instruments\n",
      "Unadjusted Covariance (Homoskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "from linearmodels import IV2SLS\n",
    "\n",
    "controls = np.ones([Y.shape[0],1])\n",
    "\n",
    "X1 = IV_data[1][:,None]\n",
    "Z = IV_data[2][:,None]\n",
    "ivolsmod = IV2SLS(Y, controls, X1, Z)\n",
    "res_ols = ivolsmod.fit(cov_type='unadjusted')\n",
    "print(res_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27174265",
   "metadata": {},
   "source": [
    "As we can see, using 2SLS has indeed solved the problem. Recall a few important details:\n",
    "* With OVB, OLS is biased and inconsistent\n",
    "* 2SLS is biased but consistent\n",
    "* We can consistently estimate the parameters, provided that the assumptions for good instruments hold.\n",
    "\n",
    "Lastly, let's confirm that the coefficient of interest can also be computed as the reduced form coefficient divided by the coefficient from the first stage. Since we have computed the first stage already above, we only need to compute the reduced form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c942d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   50.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.97e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:55</td>     <th>  Log-Likelihood:    </th> <td> -1821.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   3646.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   3656.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.1036</td> <td>    0.047</td> <td>   23.316</td> <td> 0.000</td> <td>    1.011</td> <td>    1.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.3435</td> <td>    0.048</td> <td>    7.126</td> <td> 0.000</td> <td>    0.249</td> <td>    0.438</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.389</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.823</td> <th>  Jarque-Bera (JB):  </th> <td>   0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.038</td> <th>  Prob(JB):          </th> <td>   0.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.926</td> <th>  Cond. No.          </th> <td>    1.03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.048\n",
       "Model:                            OLS   Adj. R-squared:                  0.047\n",
       "Method:                 Least Squares   F-statistic:                     50.79\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):           1.97e-12\n",
       "Time:                        19:26:55   Log-Likelihood:                -1821.0\n",
       "No. Observations:                1000   AIC:                             3646.\n",
       "Df Residuals:                     998   BIC:                             3656.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.1036      0.047     23.316      0.000       1.011       1.197\n",
       "x1             0.3435      0.048      7.126      0.000       0.249       0.438\n",
       "==============================================================================\n",
       "Omnibus:                        0.389   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.823   Jarque-Bera (JB):                0.464\n",
       "Skew:                           0.038   Prob(JB):                        0.793\n",
       "Kurtosis:                       2.926   Cond. No.                         1.03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced form\n",
    "model = sm.OLS(Y, np.hstack((np.ones([N,1]), Z)))\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "params_r = results.params\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ef477",
   "metadata": {},
   "source": [
    "Given these estimates, we can compute the 2SLS coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bfdd6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6226556180041475"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_r[1]/params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97d666",
   "metadata": {},
   "source": [
    "As you can observe, the coefficient is equivalent to the one produced by applying 2SLS directly.\n",
    "\n",
    "##### 2.3 the weak instruments problem:\n",
    "\n",
    "Given that 2SLS is consistent, is it a good idea to throw in as many instruments as we have? Do we have to worry about weak instruments? By the power of simulation, let's see what happens, if we add a lot of non-useful instruments to the list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d68df891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:              dependent   R-squared:                      0.5586\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.5582\n",
      "No. Observations:                1000   F-statistic:                    1183.9\n",
      "Date:                Fri, Apr 23 2021   P-value (F-stat)                0.0000\n",
      "Time:                        19:26:56   Distribution:                  chi2(1)\n",
      "Cov. Estimator:            unadjusted                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "exog           1.0478     0.0322     32.515     0.0000      0.9847      1.1110\n",
      "endog          0.9907     0.0288     34.408     0.0000      0.9343      1.0472\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: endog\n",
      "Instruments: instruments.0, instruments.1, instruments.2, instruments.3, instruments.4, instruments.5, instruments.6, instruments.7, instruments.8, instruments.9, instruments.10, instruments.11, instruments.12, instruments.13, instruments.14, instruments.15, instruments.16, instruments.17, instruments.18, instruments.19, instruments.20, instruments.21, instruments.22, instruments.23, instruments.24, instruments.25, instruments.26, instruments.27, instruments.28, instruments.29, instruments.30, instruments.31, instruments.32, instruments.33, instruments.34, instruments.35, instruments.36, instruments.37, instruments.38, instruments.39, instruments.40, instruments.41, instruments.42, instruments.43, instruments.44, instruments.45, instruments.46, instruments.47, instruments.48, instruments.49, instruments.50, instruments.51, instruments.52, instruments.53, instruments.54, instruments.55, instruments.56, instruments.57, instruments.58, instruments.59, instruments.60, instruments.61, instruments.62, instruments.63, instruments.64, instruments.65, instruments.66, instruments.67, instruments.68, instruments.69, instruments.70, instruments.71, instruments.72, instruments.73, instruments.74, instruments.75, instruments.76, instruments.77, instruments.78, instruments.79, instruments.80, instruments.81, instruments.82, instruments.83, instruments.84, instruments.85, instruments.86, instruments.87, instruments.88, instruments.89, instruments.90, instruments.91, instruments.92, instruments.93, instruments.94, instruments.95, instruments.96, instruments.97, instruments.98, instruments.99, instruments.100, instruments.101, instruments.102, instruments.103, instruments.104, instruments.105, instruments.106, instruments.107, instruments.108, instruments.109, instruments.110, instruments.111, instruments.112, instruments.113, instruments.114, instruments.115, instruments.116, instruments.117, instruments.118, instruments.119, instruments.120, instruments.121, instruments.122, instruments.123, instruments.124, instruments.125, instruments.126, instruments.127, instruments.128, instruments.129, instruments.130, instruments.131, instruments.132, instruments.133, instruments.134, instruments.135, instruments.136, instruments.137, instruments.138, instruments.139, instruments.140, instruments.141, instruments.142, instruments.143, instruments.144, instruments.145, instruments.146, instruments.147, instruments.148, instruments.149, instruments.150, instruments.151, instruments.152, instruments.153, instruments.154, instruments.155, instruments.156, instruments.157, instruments.158, instruments.159, instruments.160, instruments.161, instruments.162, instruments.163, instruments.164, instruments.165, instruments.166, instruments.167, instruments.168, instruments.169, instruments.170, instruments.171, instruments.172, instruments.173, instruments.174, instruments.175, instruments.176, instruments.177, instruments.178, instruments.179, instruments.180, instruments.181, instruments.182, instruments.183, instruments.184, instruments.185, instruments.186, instruments.187, instruments.188, instruments.189, instruments.190, instruments.191, instruments.192, instruments.193, instruments.194, instruments.195, instruments.196, instruments.197, instruments.198, instruments.199, instruments.200, instruments.201, instruments.202, instruments.203, instruments.204, instruments.205, instruments.206, instruments.207, instruments.208, instruments.209, instruments.210, instruments.211, instruments.212, instruments.213, instruments.214, instruments.215, instruments.216, instruments.217, instruments.218, instruments.219, instruments.220, instruments.221, instruments.222, instruments.223, instruments.224, instruments.225, instruments.226, instruments.227, instruments.228, instruments.229, instruments.230, instruments.231, instruments.232, instruments.233, instruments.234, instruments.235, instruments.236, instruments.237, instruments.238, instruments.239, instruments.240, instruments.241, instruments.242, instruments.243, instruments.244, instruments.245, instruments.246, instruments.247, instruments.248, instruments.249, instruments.250, instruments.251, instruments.252, instruments.253, instruments.254, instruments.255, instruments.256, instruments.257, instruments.258, instruments.259, instruments.260, instruments.261, instruments.262, instruments.263, instruments.264, instruments.265, instruments.266, instruments.267, instruments.268, instruments.269, instruments.270, instruments.271, instruments.272, instruments.273, instruments.274, instruments.275, instruments.276, instruments.277, instruments.278, instruments.279, instruments.280, instruments.281, instruments.282, instruments.283, instruments.284, instruments.285, instruments.286, instruments.287, instruments.288, instruments.289, instruments.290, instruments.291, instruments.292, instruments.293, instruments.294, instruments.295, instruments.296, instruments.297, instruments.298, instruments.299, instruments.300, instruments.301, instruments.302, instruments.303, instruments.304, instruments.305, instruments.306, instruments.307, instruments.308, instruments.309, instruments.310, instruments.311, instruments.312, instruments.313, instruments.314, instruments.315, instruments.316, instruments.317, instruments.318, instruments.319, instruments.320, instruments.321, instruments.322, instruments.323, instruments.324, instruments.325, instruments.326, instruments.327, instruments.328, instruments.329, instruments.330, instruments.331, instruments.332, instruments.333, instruments.334, instruments.335, instruments.336, instruments.337, instruments.338, instruments.339, instruments.340, instruments.341, instruments.342, instruments.343, instruments.344, instruments.345, instruments.346, instruments.347, instruments.348, instruments.349, instruments.350, instruments.351, instruments.352, instruments.353, instruments.354, instruments.355, instruments.356, instruments.357, instruments.358, instruments.359, instruments.360, instruments.361, instruments.362, instruments.363, instruments.364, instruments.365, instruments.366, instruments.367, instruments.368, instruments.369, instruments.370, instruments.371, instruments.372, instruments.373, instruments.374, instruments.375, instruments.376, instruments.377, instruments.378, instruments.379, instruments.380, instruments.381, instruments.382, instruments.383, instruments.384, instruments.385, instruments.386, instruments.387, instruments.388, instruments.389, instruments.390, instruments.391, instruments.392, instruments.393, instruments.394, instruments.395, instruments.396, instruments.397, instruments.398, instruments.399, instruments.400, instruments.401, instruments.402, instruments.403, instruments.404, instruments.405, instruments.406, instruments.407, instruments.408, instruments.409, instruments.410, instruments.411, instruments.412, instruments.413, instruments.414, instruments.415, instruments.416, instruments.417, instruments.418, instruments.419, instruments.420, instruments.421, instruments.422, instruments.423, instruments.424, instruments.425, instruments.426, instruments.427, instruments.428, instruments.429, instruments.430, instruments.431, instruments.432, instruments.433, instruments.434, instruments.435, instruments.436, instruments.437, instruments.438, instruments.439, instruments.440, instruments.441, instruments.442, instruments.443, instruments.444, instruments.445, instruments.446, instruments.447, instruments.448, instruments.449, instruments.450, instruments.451, instruments.452, instruments.453, instruments.454, instruments.455, instruments.456, instruments.457, instruments.458, instruments.459, instruments.460, instruments.461, instruments.462, instruments.463, instruments.464, instruments.465, instruments.466, instruments.467, instruments.468, instruments.469, instruments.470, instruments.471, instruments.472, instruments.473, instruments.474, instruments.475, instruments.476, instruments.477, instruments.478, instruments.479, instruments.480, instruments.481, instruments.482, instruments.483, instruments.484, instruments.485, instruments.486, instruments.487, instruments.488, instruments.489, instruments.490, instruments.491, instruments.492, instruments.493, instruments.494, instruments.495, instruments.496, instruments.497, instruments.498, instruments.499, instruments.500, instruments.501, instruments.502, instruments.503, instruments.504, instruments.505, instruments.506, instruments.507, instruments.508, instruments.509, instruments.510, instruments.511, instruments.512, instruments.513, instruments.514, instruments.515, instruments.516, instruments.517, instruments.518, instruments.519, instruments.520, instruments.521, instruments.522, instruments.523, instruments.524, instruments.525, instruments.526, instruments.527, instruments.528, instruments.529, instruments.530, instruments.531, instruments.532, instruments.533, instruments.534, instruments.535, instruments.536, instruments.537, instruments.538, instruments.539, instruments.540, instruments.541, instruments.542, instruments.543, instruments.544, instruments.545, instruments.546, instruments.547, instruments.548, instruments.549, instruments.550, instruments.551, instruments.552, instruments.553, instruments.554, instruments.555, instruments.556, instruments.557, instruments.558, instruments.559, instruments.560, instruments.561, instruments.562, instruments.563, instruments.564, instruments.565, instruments.566, instruments.567, instruments.568, instruments.569, instruments.570, instruments.571, instruments.572, instruments.573, instruments.574, instruments.575, instruments.576, instruments.577, instruments.578, instruments.579, instruments.580, instruments.581, instruments.582, instruments.583, instruments.584, instruments.585, instruments.586, instruments.587, instruments.588, instruments.589, instruments.590, instruments.591, instruments.592, instruments.593, instruments.594, instruments.595, instruments.596, instruments.597, instruments.598, instruments.599, instruments.600, instruments.601, instruments.602, instruments.603, instruments.604, instruments.605, instruments.606, instruments.607, instruments.608, instruments.609, instruments.610, instruments.611, instruments.612, instruments.613, instruments.614, instruments.615, instruments.616, instruments.617, instruments.618, instruments.619, instruments.620, instruments.621, instruments.622, instruments.623, instruments.624, instruments.625, instruments.626, instruments.627, instruments.628, instruments.629, instruments.630, instruments.631, instruments.632, instruments.633, instruments.634, instruments.635, instruments.636, instruments.637, instruments.638, instruments.639, instruments.640, instruments.641, instruments.642, instruments.643, instruments.644, instruments.645, instruments.646, instruments.647, instruments.648, instruments.649, instruments.650, instruments.651, instruments.652, instruments.653, instruments.654, instruments.655, instruments.656, instruments.657, instruments.658, instruments.659, instruments.660, instruments.661, instruments.662, instruments.663, instruments.664, instruments.665, instruments.666, instruments.667, instruments.668, instruments.669, instruments.670, instruments.671, instruments.672, instruments.673, instruments.674, instruments.675, instruments.676, instruments.677, instruments.678, instruments.679, instruments.680, instruments.681, instruments.682, instruments.683, instruments.684, instruments.685, instruments.686, instruments.687, instruments.688, instruments.689, instruments.690, instruments.691, instruments.692, instruments.693, instruments.694, instruments.695, instruments.696, instruments.697, instruments.698, instruments.699, instruments.700, instruments.701, instruments.702, instruments.703, instruments.704, instruments.705, instruments.706, instruments.707, instruments.708, instruments.709, instruments.710, instruments.711, instruments.712, instruments.713, instruments.714, instruments.715, instruments.716, instruments.717, instruments.718, instruments.719, instruments.720, instruments.721, instruments.722, instruments.723, instruments.724, instruments.725, instruments.726, instruments.727, instruments.728, instruments.729, instruments.730, instruments.731, instruments.732, instruments.733, instruments.734, instruments.735, instruments.736, instruments.737, instruments.738, instruments.739, instruments.740, instruments.741, instruments.742, instruments.743, instruments.744, instruments.745, instruments.746, instruments.747, instruments.748, instruments.749, instruments.750, instruments.751, instruments.752, instruments.753, instruments.754, instruments.755, instruments.756, instruments.757, instruments.758, instruments.759, instruments.760, instruments.761, instruments.762, instruments.763, instruments.764, instruments.765, instruments.766, instruments.767, instruments.768, instruments.769, instruments.770, instruments.771, instruments.772, instruments.773, instruments.774, instruments.775, instruments.776, instruments.777, instruments.778, instruments.779, instruments.780, instruments.781, instruments.782, instruments.783, instruments.784, instruments.785, instruments.786, instruments.787, instruments.788, instruments.789, instruments.790, instruments.791, instruments.792, instruments.793, instruments.794, instruments.795, instruments.796, instruments.797, instruments.798, instruments.799, instruments.800, instruments.801, instruments.802, instruments.803, instruments.804, instruments.805, instruments.806, instruments.807, instruments.808, instruments.809, instruments.810, instruments.811, instruments.812, instruments.813, instruments.814, instruments.815, instruments.816, instruments.817, instruments.818, instruments.819, instruments.820, instruments.821, instruments.822, instruments.823, instruments.824, instruments.825, instruments.826, instruments.827, instruments.828, instruments.829, instruments.830, instruments.831, instruments.832, instruments.833, instruments.834, instruments.835, instruments.836, instruments.837, instruments.838, instruments.839, instruments.840, instruments.841, instruments.842, instruments.843, instruments.844, instruments.845, instruments.846, instruments.847, instruments.848, instruments.849, instruments.850, instruments.851, instruments.852, instruments.853, instruments.854, instruments.855, instruments.856, instruments.857, instruments.858, instruments.859, instruments.860, instruments.861, instruments.862, instruments.863, instruments.864, instruments.865, instruments.866, instruments.867, instruments.868, instruments.869, instruments.870, instruments.871, instruments.872, instruments.873, instruments.874, instruments.875, instruments.876, instruments.877, instruments.878, instruments.879, instruments.880, instruments.881, instruments.882, instruments.883, instruments.884, instruments.885, instruments.886, instruments.887, instruments.888, instruments.889, instruments.890, instruments.891, instruments.892, instruments.893, instruments.894, instruments.895, instruments.896, instruments.897, instruments.898, instruments.899, instruments.900\n",
      "Unadjusted Covariance (Homoskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "controls = np.ones([Y.shape[0],1])\n",
    "\n",
    "X1 = IV_data[1][:,None]\n",
    "Z = IV_data[2][:,None]\n",
    "ivolsmod = IV2SLS(Y, controls, X1, np.hstack((Z, np.random.rand(N,900))))\n",
    "res_ols = ivolsmod.fit(cov_type='unadjusted')\n",
    "print(res_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc81c9",
   "metadata": {},
   "source": [
    "Note that now the 2SLS coefficients are essentially the same as OLS! Of course this is a rather extreme example, but adding a lot of weak instruments biases 2SLS in the direction of OLS. The reason is that due to sampling uncertainty, the coefficients in the first stage are usually different from 0 (even though the instruments here are completely irrelevant). A little of the correlation between the first and second stage errors then makes it way into into the 2SLS estimates. It turns out, that this bias is a function of the F-statistic of the first stage. Let's look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d29b4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>0.00469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:57</td>     <th>  Log-Likelihood:    </th> <td> -210.59</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2225.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   6652.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   901</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0689</td> <td>    0.093</td> <td>    0.737</td> <td> 0.463</td> <td>   -0.117</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6518</td> <td>    0.098</td> <td>    6.671</td> <td> 0.000</td> <td>    0.458</td> <td>    0.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1241</td> <td>    0.095</td> <td>   -1.306</td> <td> 0.195</td> <td>   -0.313</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1608</td> <td>    0.108</td> <td>    1.487</td> <td> 0.140</td> <td>   -0.054</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0449</td> <td>    0.086</td> <td>   -0.525</td> <td> 0.601</td> <td>   -0.215</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.1317</td> <td>    0.084</td> <td>    1.565</td> <td> 0.121</td> <td>   -0.035</td> <td>    0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.1142</td> <td>    0.096</td> <td>   -1.191</td> <td> 0.237</td> <td>   -0.304</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.3082</td> <td>    0.125</td> <td>    2.458</td> <td> 0.016</td> <td>    0.059</td> <td>    0.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0619</td> <td>    0.086</td> <td>    0.722</td> <td> 0.472</td> <td>   -0.108</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0602</td> <td>    0.092</td> <td>   -0.657</td> <td> 0.513</td> <td>   -0.242</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0581</td> <td>    0.101</td> <td>   -0.574</td> <td> 0.567</td> <td>   -0.259</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0078</td> <td>    0.099</td> <td>    0.079</td> <td> 0.937</td> <td>   -0.188</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0682</td> <td>    0.095</td> <td>   -0.717</td> <td> 0.475</td> <td>   -0.257</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.1603</td> <td>    0.097</td> <td>   -1.651</td> <td> 0.102</td> <td>   -0.353</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0697</td> <td>    0.107</td> <td>    0.649</td> <td> 0.518</td> <td>   -0.144</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.2320</td> <td>    0.108</td> <td>   -2.155</td> <td> 0.034</td> <td>   -0.446</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0905</td> <td>    0.100</td> <td>   -0.907</td> <td> 0.367</td> <td>   -0.289</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.1728</td> <td>    0.096</td> <td>   -1.804</td> <td> 0.074</td> <td>   -0.363</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0597</td> <td>    0.091</td> <td>    0.654</td> <td> 0.514</td> <td>   -0.121</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0616</td> <td>    0.103</td> <td>   -0.599</td> <td> 0.550</td> <td>   -0.265</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.0747</td> <td>    0.097</td> <td>   -0.773</td> <td> 0.441</td> <td>   -0.267</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.1111</td> <td>    0.110</td> <td>    1.006</td> <td> 0.317</td> <td>   -0.108</td> <td>    0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.1132</td> <td>    0.091</td> <td>    1.247</td> <td> 0.215</td> <td>   -0.067</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.1014</td> <td>    0.098</td> <td>   -1.031</td> <td> 0.305</td> <td>   -0.296</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0118</td> <td>    0.103</td> <td>   -0.115</td> <td> 0.909</td> <td>   -0.217</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.1430</td> <td>    0.101</td> <td>   -1.417</td> <td> 0.160</td> <td>   -0.343</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.1758</td> <td>    0.099</td> <td>    1.769</td> <td> 0.080</td> <td>   -0.021</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.0374</td> <td>    0.102</td> <td>    0.365</td> <td> 0.716</td> <td>   -0.166</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.1522</td> <td>    0.096</td> <td>   -1.582</td> <td> 0.117</td> <td>   -0.343</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.0639</td> <td>    0.089</td> <td>    0.722</td> <td> 0.472</td> <td>   -0.112</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.1140</td> <td>    0.094</td> <td>    1.212</td> <td> 0.228</td> <td>   -0.073</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.0099</td> <td>    0.094</td> <td>   -0.106</td> <td> 0.916</td> <td>   -0.197</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.1487</td> <td>    0.095</td> <td>    1.566</td> <td> 0.121</td> <td>   -0.040</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0387</td> <td>    0.094</td> <td>   -0.411</td> <td> 0.682</td> <td>   -0.226</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0227</td> <td>    0.095</td> <td>    0.239</td> <td> 0.811</td> <td>   -0.165</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.0347</td> <td>    0.086</td> <td>    0.402</td> <td> 0.688</td> <td>   -0.137</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.0587</td> <td>    0.101</td> <td>   -0.579</td> <td> 0.564</td> <td>   -0.260</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.0511</td> <td>    0.099</td> <td>   -0.515</td> <td> 0.608</td> <td>   -0.248</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.1198</td> <td>    0.097</td> <td>   -1.237</td> <td> 0.219</td> <td>   -0.312</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.0934</td> <td>    0.108</td> <td>   -0.863</td> <td> 0.390</td> <td>   -0.308</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.0716</td> <td>    0.096</td> <td>    0.743</td> <td> 0.459</td> <td>   -0.119</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    0.2645</td> <td>    0.110</td> <td>    2.395</td> <td> 0.018</td> <td>    0.045</td> <td>    0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>    0.0013</td> <td>    0.091</td> <td>    0.015</td> <td> 0.988</td> <td>   -0.179</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>    0.0325</td> <td>    0.094</td> <td>    0.346</td> <td> 0.730</td> <td>   -0.154</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.0747</td> <td>    0.097</td> <td>   -0.770</td> <td> 0.443</td> <td>   -0.267</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.0946</td> <td>    0.100</td> <td>   -0.943</td> <td> 0.348</td> <td>   -0.294</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.0331</td> <td>    0.104</td> <td>    0.320</td> <td> 0.750</td> <td>   -0.172</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.0234</td> <td>    0.104</td> <td>   -0.224</td> <td> 0.823</td> <td>   -0.231</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.1362</td> <td>    0.098</td> <td>   -1.396</td> <td> 0.166</td> <td>   -0.330</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    0.0205</td> <td>    0.096</td> <td>    0.214</td> <td> 0.831</td> <td>   -0.170</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.1232</td> <td>    0.089</td> <td>    1.377</td> <td> 0.172</td> <td>   -0.054</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>    0.0174</td> <td>    0.099</td> <td>    0.176</td> <td> 0.861</td> <td>   -0.179</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.0316</td> <td>    0.093</td> <td>   -0.340</td> <td> 0.734</td> <td>   -0.216</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    0.0154</td> <td>    0.092</td> <td>    0.167</td> <td> 0.868</td> <td>   -0.168</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.0972</td> <td>    0.092</td> <td>   -1.057</td> <td> 0.293</td> <td>   -0.280</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>   -0.1017</td> <td>    0.093</td> <td>   -1.097</td> <td> 0.275</td> <td>   -0.285</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>   -0.0360</td> <td>    0.107</td> <td>   -0.337</td> <td> 0.737</td> <td>   -0.248</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>    0.0424</td> <td>    0.093</td> <td>    0.454</td> <td> 0.651</td> <td>   -0.143</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>   -0.1929</td> <td>    0.085</td> <td>   -2.259</td> <td> 0.026</td> <td>   -0.362</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>   -0.1194</td> <td>    0.094</td> <td>   -1.275</td> <td> 0.205</td> <td>   -0.305</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>   -0.1468</td> <td>    0.115</td> <td>   -1.271</td> <td> 0.207</td> <td>   -0.376</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>    0.2386</td> <td>    0.102</td> <td>    2.347</td> <td> 0.021</td> <td>    0.037</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>   -0.0960</td> <td>    0.088</td> <td>   -1.091</td> <td> 0.278</td> <td>   -0.271</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>   -0.0274</td> <td>    0.091</td> <td>   -0.300</td> <td> 0.764</td> <td>   -0.208</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>    0.0741</td> <td>    0.090</td> <td>    0.822</td> <td> 0.413</td> <td>   -0.105</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>   -0.1528</td> <td>    0.102</td> <td>   -1.493</td> <td> 0.139</td> <td>   -0.356</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>   -0.1495</td> <td>    0.099</td> <td>   -1.507</td> <td> 0.135</td> <td>   -0.346</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>   -0.1483</td> <td>    0.110</td> <td>   -1.348</td> <td> 0.181</td> <td>   -0.367</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>   -0.0441</td> <td>    0.090</td> <td>   -0.492</td> <td> 0.624</td> <td>   -0.222</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>   -0.0070</td> <td>    0.077</td> <td>   -0.090</td> <td> 0.928</td> <td>   -0.161</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>   -0.0707</td> <td>    0.090</td> <td>   -0.784</td> <td> 0.435</td> <td>   -0.250</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>   -0.0107</td> <td>    0.106</td> <td>   -0.101</td> <td> 0.920</td> <td>   -0.221</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>   -0.2737</td> <td>    0.104</td> <td>   -2.623</td> <td> 0.010</td> <td>   -0.481</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>    0.1977</td> <td>    0.091</td> <td>    2.185</td> <td> 0.031</td> <td>    0.018</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>    0.1325</td> <td>    0.096</td> <td>    1.374</td> <td> 0.172</td> <td>   -0.059</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>    0.1569</td> <td>    0.099</td> <td>    1.580</td> <td> 0.117</td> <td>   -0.040</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>    0.1292</td> <td>    0.101</td> <td>    1.284</td> <td> 0.202</td> <td>   -0.071</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>   -0.0537</td> <td>    0.095</td> <td>   -0.568</td> <td> 0.572</td> <td>   -0.242</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>   -0.0002</td> <td>    0.103</td> <td>   -0.002</td> <td> 0.998</td> <td>   -0.205</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>    0.2563</td> <td>    0.090</td> <td>    2.835</td> <td> 0.006</td> <td>    0.077</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>   -0.1127</td> <td>    0.106</td> <td>   -1.064</td> <td> 0.290</td> <td>   -0.323</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>    0.0892</td> <td>    0.109</td> <td>    0.815</td> <td> 0.417</td> <td>   -0.128</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>    0.1673</td> <td>    0.105</td> <td>    1.588</td> <td> 0.115</td> <td>   -0.042</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>   -0.0070</td> <td>    0.100</td> <td>   -0.070</td> <td> 0.945</td> <td>   -0.205</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>    0.1772</td> <td>    0.104</td> <td>    1.710</td> <td> 0.090</td> <td>   -0.028</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>    0.0336</td> <td>    0.089</td> <td>    0.378</td> <td> 0.706</td> <td>   -0.143</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>   -0.1389</td> <td>    0.088</td> <td>   -1.575</td> <td> 0.118</td> <td>   -0.314</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>   -0.0384</td> <td>    0.108</td> <td>   -0.356</td> <td> 0.722</td> <td>   -0.252</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>    0.1223</td> <td>    0.089</td> <td>    1.378</td> <td> 0.171</td> <td>   -0.054</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>   -0.0563</td> <td>    0.095</td> <td>   -0.595</td> <td> 0.553</td> <td>   -0.244</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>   -0.1359</td> <td>    0.089</td> <td>   -1.529</td> <td> 0.130</td> <td>   -0.312</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>    0.0544</td> <td>    0.096</td> <td>    0.569</td> <td> 0.571</td> <td>   -0.135</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>   -0.0126</td> <td>    0.085</td> <td>   -0.148</td> <td> 0.883</td> <td>   -0.182</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>    0.0257</td> <td>    0.094</td> <td>    0.275</td> <td> 0.784</td> <td>   -0.160</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>    0.0526</td> <td>    0.104</td> <td>    0.508</td> <td> 0.613</td> <td>   -0.153</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>   -0.0387</td> <td>    0.094</td> <td>   -0.414</td> <td> 0.680</td> <td>   -0.224</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    0.0392</td> <td>    0.108</td> <td>    0.365</td> <td> 0.716</td> <td>   -0.174</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>    0.0203</td> <td>    0.092</td> <td>    0.221</td> <td> 0.826</td> <td>   -0.162</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>    0.1530</td> <td>    0.107</td> <td>    1.433</td> <td> 0.155</td> <td>   -0.059</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>   -0.2688</td> <td>    0.104</td> <td>   -2.594</td> <td> 0.011</td> <td>   -0.474</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>    0.0777</td> <td>    0.098</td> <td>    0.796</td> <td> 0.428</td> <td>   -0.116</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th>  <td>   -0.1207</td> <td>    0.103</td> <td>   -1.168</td> <td> 0.246</td> <td>   -0.326</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th>  <td>   -0.1128</td> <td>    0.086</td> <td>   -1.307</td> <td> 0.194</td> <td>   -0.284</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th>  <td>    0.1069</td> <td>    0.107</td> <td>    1.003</td> <td> 0.318</td> <td>   -0.105</td> <td>    0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th>  <td>    0.0558</td> <td>    0.093</td> <td>    0.602</td> <td> 0.549</td> <td>   -0.128</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th>  <td>    0.0513</td> <td>    0.103</td> <td>    0.497</td> <td> 0.620</td> <td>   -0.153</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th>  <td>    0.1188</td> <td>    0.100</td> <td>    1.186</td> <td> 0.239</td> <td>   -0.080</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th>  <td>    0.1834</td> <td>    0.110</td> <td>    1.670</td> <td> 0.098</td> <td>   -0.035</td> <td>    0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th>  <td>    0.0329</td> <td>    0.101</td> <td>    0.326</td> <td> 0.745</td> <td>   -0.167</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th>  <td>    0.2485</td> <td>    0.097</td> <td>    2.573</td> <td> 0.012</td> <td>    0.057</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th>  <td>   -0.0983</td> <td>    0.082</td> <td>   -1.192</td> <td> 0.236</td> <td>   -0.262</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th>  <td>    0.0029</td> <td>    0.095</td> <td>    0.030</td> <td> 0.976</td> <td>   -0.186</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th>  <td>   -0.2383</td> <td>    0.101</td> <td>   -2.367</td> <td> 0.020</td> <td>   -0.438</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th>  <td>    0.0415</td> <td>    0.092</td> <td>    0.449</td> <td> 0.654</td> <td>   -0.142</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th>  <td>    0.0427</td> <td>    0.089</td> <td>    0.481</td> <td> 0.632</td> <td>   -0.134</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th>  <td>    0.0063</td> <td>    0.102</td> <td>    0.062</td> <td> 0.951</td> <td>   -0.197</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th>  <td>    0.1491</td> <td>    0.093</td> <td>    1.604</td> <td> 0.112</td> <td>   -0.035</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th>  <td>   -0.1267</td> <td>    0.081</td> <td>   -1.558</td> <td> 0.122</td> <td>   -0.288</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th>  <td>    0.0899</td> <td>    0.108</td> <td>    0.835</td> <td> 0.406</td> <td>   -0.124</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x119</th>  <td>    0.1420</td> <td>    0.096</td> <td>    1.483</td> <td> 0.141</td> <td>   -0.048</td> <td>    0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x120</th>  <td>    0.0369</td> <td>    0.090</td> <td>    0.408</td> <td> 0.684</td> <td>   -0.142</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x121</th>  <td>    0.0365</td> <td>    0.096</td> <td>    0.382</td> <td> 0.703</td> <td>   -0.153</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x122</th>  <td>    0.0158</td> <td>    0.100</td> <td>    0.158</td> <td> 0.874</td> <td>   -0.182</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x123</th>  <td>   -0.1779</td> <td>    0.092</td> <td>   -1.933</td> <td> 0.056</td> <td>   -0.360</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x124</th>  <td>    0.1677</td> <td>    0.088</td> <td>    1.908</td> <td> 0.059</td> <td>   -0.007</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x125</th>  <td>   -0.0721</td> <td>    0.100</td> <td>   -0.724</td> <td> 0.471</td> <td>   -0.270</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x126</th>  <td>    0.1319</td> <td>    0.099</td> <td>    1.329</td> <td> 0.187</td> <td>   -0.065</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x127</th>  <td>   -0.0574</td> <td>    0.088</td> <td>   -0.654</td> <td> 0.515</td> <td>   -0.232</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x128</th>  <td>    0.1494</td> <td>    0.098</td> <td>    1.530</td> <td> 0.129</td> <td>   -0.044</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x129</th>  <td>   -0.0641</td> <td>    0.090</td> <td>   -0.715</td> <td> 0.476</td> <td>   -0.242</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x130</th>  <td>   -0.2117</td> <td>    0.102</td> <td>   -2.068</td> <td> 0.041</td> <td>   -0.415</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x131</th>  <td>    0.0080</td> <td>    0.086</td> <td>    0.093</td> <td> 0.926</td> <td>   -0.163</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x132</th>  <td>    0.2239</td> <td>    0.088</td> <td>    2.537</td> <td> 0.013</td> <td>    0.049</td> <td>    0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x133</th>  <td>    0.0156</td> <td>    0.096</td> <td>    0.162</td> <td> 0.872</td> <td>   -0.175</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x134</th>  <td>   -0.0134</td> <td>    0.096</td> <td>   -0.140</td> <td> 0.889</td> <td>   -0.203</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x135</th>  <td>    0.0163</td> <td>    0.095</td> <td>    0.172</td> <td> 0.864</td> <td>   -0.171</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x136</th>  <td>    0.0167</td> <td>    0.103</td> <td>    0.162</td> <td> 0.871</td> <td>   -0.187</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x137</th>  <td>   -0.0382</td> <td>    0.103</td> <td>   -0.373</td> <td> 0.710</td> <td>   -0.242</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x138</th>  <td>    0.2713</td> <td>    0.099</td> <td>    2.751</td> <td> 0.007</td> <td>    0.076</td> <td>    0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x139</th>  <td>    0.0011</td> <td>    0.088</td> <td>    0.013</td> <td> 0.990</td> <td>   -0.174</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x140</th>  <td>   -0.0325</td> <td>    0.091</td> <td>   -0.357</td> <td> 0.721</td> <td>   -0.213</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x141</th>  <td>    0.1099</td> <td>    0.099</td> <td>    1.109</td> <td> 0.270</td> <td>   -0.087</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x142</th>  <td>    0.0464</td> <td>    0.108</td> <td>    0.429</td> <td> 0.669</td> <td>   -0.168</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x143</th>  <td>   -0.1365</td> <td>    0.092</td> <td>   -1.476</td> <td> 0.143</td> <td>   -0.320</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x144</th>  <td>   -0.0563</td> <td>    0.107</td> <td>   -0.528</td> <td> 0.599</td> <td>   -0.268</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x145</th>  <td>    0.0694</td> <td>    0.092</td> <td>    0.754</td> <td> 0.452</td> <td>   -0.113</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x146</th>  <td>   -0.0624</td> <td>    0.102</td> <td>   -0.612</td> <td> 0.542</td> <td>   -0.265</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x147</th>  <td>    0.1139</td> <td>    0.091</td> <td>    1.248</td> <td> 0.215</td> <td>   -0.067</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x148</th>  <td>    0.0549</td> <td>    0.088</td> <td>    0.626</td> <td> 0.533</td> <td>   -0.119</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x149</th>  <td>   -0.1183</td> <td>    0.092</td> <td>   -1.287</td> <td> 0.201</td> <td>   -0.301</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x150</th>  <td>   -0.1122</td> <td>    0.106</td> <td>   -1.056</td> <td> 0.294</td> <td>   -0.323</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x151</th>  <td>    0.0507</td> <td>    0.093</td> <td>    0.548</td> <td> 0.585</td> <td>   -0.133</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x152</th>  <td>    0.0716</td> <td>    0.102</td> <td>    0.698</td> <td> 0.487</td> <td>   -0.132</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x153</th>  <td>    0.1872</td> <td>    0.107</td> <td>    1.750</td> <td> 0.083</td> <td>   -0.025</td> <td>    0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x154</th>  <td>    0.1174</td> <td>    0.101</td> <td>    1.162</td> <td> 0.248</td> <td>   -0.083</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x155</th>  <td>    0.0767</td> <td>    0.103</td> <td>    0.745</td> <td> 0.458</td> <td>   -0.127</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x156</th>  <td>    0.0388</td> <td>    0.092</td> <td>    0.420</td> <td> 0.675</td> <td>   -0.145</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x157</th>  <td>    0.0076</td> <td>    0.097</td> <td>    0.078</td> <td> 0.938</td> <td>   -0.185</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x158</th>  <td>    0.1458</td> <td>    0.082</td> <td>    1.773</td> <td> 0.079</td> <td>   -0.017</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x159</th>  <td>   -0.3022</td> <td>    0.099</td> <td>   -3.038</td> <td> 0.003</td> <td>   -0.500</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x160</th>  <td>    0.0685</td> <td>    0.100</td> <td>    0.683</td> <td> 0.496</td> <td>   -0.130</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x161</th>  <td>   -0.0914</td> <td>    0.089</td> <td>   -1.030</td> <td> 0.306</td> <td>   -0.267</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x162</th>  <td>    0.1205</td> <td>    0.101</td> <td>    1.189</td> <td> 0.237</td> <td>   -0.081</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x163</th>  <td>   -0.1700</td> <td>    0.090</td> <td>   -1.885</td> <td> 0.062</td> <td>   -0.349</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x164</th>  <td>   -0.0161</td> <td>    0.114</td> <td>   -0.142</td> <td> 0.887</td> <td>   -0.242</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x165</th>  <td>   -0.1175</td> <td>    0.101</td> <td>   -1.158</td> <td> 0.250</td> <td>   -0.319</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x166</th>  <td>    0.0905</td> <td>    0.096</td> <td>    0.940</td> <td> 0.349</td> <td>   -0.100</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x167</th>  <td>   -0.0323</td> <td>    0.114</td> <td>   -0.284</td> <td> 0.777</td> <td>   -0.259</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x168</th>  <td>    0.0022</td> <td>    0.088</td> <td>    0.025</td> <td> 0.980</td> <td>   -0.173</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x169</th>  <td>   -0.1243</td> <td>    0.095</td> <td>   -1.314</td> <td> 0.192</td> <td>   -0.312</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x170</th>  <td>    0.0666</td> <td>    0.095</td> <td>    0.703</td> <td> 0.484</td> <td>   -0.121</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x171</th>  <td>    0.0135</td> <td>    0.089</td> <td>    0.151</td> <td> 0.880</td> <td>   -0.164</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x172</th>  <td>    0.2430</td> <td>    0.108</td> <td>    2.251</td> <td> 0.027</td> <td>    0.029</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x173</th>  <td>    0.0767</td> <td>    0.098</td> <td>    0.780</td> <td> 0.437</td> <td>   -0.118</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x174</th>  <td>   -0.2467</td> <td>    0.084</td> <td>   -2.922</td> <td> 0.004</td> <td>   -0.414</td> <td>   -0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x175</th>  <td>    0.0502</td> <td>    0.117</td> <td>    0.429</td> <td> 0.669</td> <td>   -0.182</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x176</th>  <td>   -0.0622</td> <td>    0.107</td> <td>   -0.579</td> <td> 0.564</td> <td>   -0.275</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x177</th>  <td>    0.1050</td> <td>    0.097</td> <td>    1.083</td> <td> 0.281</td> <td>   -0.087</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x178</th>  <td>   -0.2222</td> <td>    0.092</td> <td>   -2.403</td> <td> 0.018</td> <td>   -0.406</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x179</th>  <td>    0.0924</td> <td>    0.107</td> <td>    0.864</td> <td> 0.390</td> <td>   -0.120</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x180</th>  <td>   -0.0195</td> <td>    0.091</td> <td>   -0.215</td> <td> 0.830</td> <td>   -0.200</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x181</th>  <td>    0.1207</td> <td>    0.094</td> <td>    1.283</td> <td> 0.203</td> <td>   -0.066</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x182</th>  <td>   -0.0375</td> <td>    0.103</td> <td>   -0.363</td> <td> 0.717</td> <td>   -0.242</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x183</th>  <td>    0.0117</td> <td>    0.107</td> <td>    0.109</td> <td> 0.914</td> <td>   -0.201</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x184</th>  <td>    0.1184</td> <td>    0.110</td> <td>    1.081</td> <td> 0.282</td> <td>   -0.099</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x185</th>  <td>   -0.0303</td> <td>    0.088</td> <td>   -0.343</td> <td> 0.732</td> <td>   -0.205</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x186</th>  <td>    0.0240</td> <td>    0.093</td> <td>    0.259</td> <td> 0.796</td> <td>   -0.160</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x187</th>  <td>   -0.0855</td> <td>    0.087</td> <td>   -0.977</td> <td> 0.331</td> <td>   -0.259</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x188</th>  <td>    0.1224</td> <td>    0.104</td> <td>    1.175</td> <td> 0.243</td> <td>   -0.084</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x189</th>  <td>   -0.0815</td> <td>    0.110</td> <td>   -0.738</td> <td> 0.462</td> <td>   -0.301</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x190</th>  <td>    0.1136</td> <td>    0.099</td> <td>    1.147</td> <td> 0.254</td> <td>   -0.083</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x191</th>  <td>    0.0073</td> <td>    0.100</td> <td>    0.073</td> <td> 0.942</td> <td>   -0.192</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x192</th>  <td>    0.0088</td> <td>    0.097</td> <td>    0.090</td> <td> 0.928</td> <td>   -0.184</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x193</th>  <td>   -0.0688</td> <td>    0.106</td> <td>   -0.649</td> <td> 0.518</td> <td>   -0.279</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x194</th>  <td>   -0.0063</td> <td>    0.096</td> <td>   -0.065</td> <td> 0.948</td> <td>   -0.197</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x195</th>  <td>   -0.0124</td> <td>    0.092</td> <td>   -0.135</td> <td> 0.893</td> <td>   -0.195</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x196</th>  <td>   -0.1842</td> <td>    0.107</td> <td>   -1.717</td> <td> 0.089</td> <td>   -0.397</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x197</th>  <td>   -0.0608</td> <td>    0.096</td> <td>   -0.634</td> <td> 0.527</td> <td>   -0.251</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x198</th>  <td>   -0.0361</td> <td>    0.097</td> <td>   -0.371</td> <td> 0.711</td> <td>   -0.229</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x199</th>  <td>   -0.0211</td> <td>    0.100</td> <td>   -0.212</td> <td> 0.833</td> <td>   -0.219</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x200</th>  <td>   -0.0686</td> <td>    0.092</td> <td>   -0.749</td> <td> 0.456</td> <td>   -0.250</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x201</th>  <td>    0.0619</td> <td>    0.101</td> <td>    0.615</td> <td> 0.540</td> <td>   -0.138</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x202</th>  <td>   -0.1188</td> <td>    0.096</td> <td>   -1.237</td> <td> 0.219</td> <td>   -0.310</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x203</th>  <td>   -0.1423</td> <td>    0.091</td> <td>   -1.567</td> <td> 0.120</td> <td>   -0.322</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x204</th>  <td>    0.0742</td> <td>    0.101</td> <td>    0.736</td> <td> 0.463</td> <td>   -0.126</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x205</th>  <td>   -0.1232</td> <td>    0.109</td> <td>   -1.130</td> <td> 0.261</td> <td>   -0.339</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x206</th>  <td>   -0.1031</td> <td>    0.104</td> <td>   -0.991</td> <td> 0.324</td> <td>   -0.310</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x207</th>  <td>    0.0329</td> <td>    0.105</td> <td>    0.312</td> <td> 0.756</td> <td>   -0.176</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x208</th>  <td>   -0.1038</td> <td>    0.096</td> <td>   -1.079</td> <td> 0.283</td> <td>   -0.295</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x209</th>  <td>    0.0631</td> <td>    0.094</td> <td>    0.670</td> <td> 0.504</td> <td>   -0.124</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x210</th>  <td>   -0.2320</td> <td>    0.101</td> <td>   -2.302</td> <td> 0.023</td> <td>   -0.432</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x211</th>  <td>    0.0293</td> <td>    0.096</td> <td>    0.304</td> <td> 0.762</td> <td>   -0.162</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x212</th>  <td>   -0.3021</td> <td>    0.107</td> <td>   -2.830</td> <td> 0.006</td> <td>   -0.514</td> <td>   -0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x213</th>  <td>    0.1520</td> <td>    0.080</td> <td>    1.907</td> <td> 0.060</td> <td>   -0.006</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x214</th>  <td>    0.0511</td> <td>    0.103</td> <td>    0.496</td> <td> 0.621</td> <td>   -0.153</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x215</th>  <td>   -0.1273</td> <td>    0.103</td> <td>   -1.237</td> <td> 0.219</td> <td>   -0.331</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x216</th>  <td>    0.0109</td> <td>    0.087</td> <td>    0.125</td> <td> 0.901</td> <td>   -0.163</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x217</th>  <td>    0.0515</td> <td>    0.097</td> <td>    0.533</td> <td> 0.595</td> <td>   -0.140</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x218</th>  <td>    0.0399</td> <td>    0.100</td> <td>    0.398</td> <td> 0.692</td> <td>   -0.159</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x219</th>  <td>    0.0275</td> <td>    0.098</td> <td>    0.280</td> <td> 0.780</td> <td>   -0.167</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x220</th>  <td>   -0.0915</td> <td>    0.104</td> <td>   -0.878</td> <td> 0.382</td> <td>   -0.298</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x221</th>  <td>   -0.1841</td> <td>    0.095</td> <td>   -1.939</td> <td> 0.055</td> <td>   -0.373</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x222</th>  <td>   -0.0031</td> <td>    0.093</td> <td>   -0.033</td> <td> 0.974</td> <td>   -0.187</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x223</th>  <td>   -0.0803</td> <td>    0.105</td> <td>   -0.765</td> <td> 0.446</td> <td>   -0.288</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x224</th>  <td>    0.0304</td> <td>    0.097</td> <td>    0.312</td> <td> 0.756</td> <td>   -0.163</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x225</th>  <td>    0.1578</td> <td>    0.089</td> <td>    1.779</td> <td> 0.078</td> <td>   -0.018</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x226</th>  <td>    0.0323</td> <td>    0.096</td> <td>    0.338</td> <td> 0.736</td> <td>   -0.157</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x227</th>  <td>   -0.0306</td> <td>    0.080</td> <td>   -0.384</td> <td> 0.702</td> <td>   -0.189</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x228</th>  <td>   -0.0980</td> <td>    0.098</td> <td>   -1.002</td> <td> 0.319</td> <td>   -0.292</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x229</th>  <td>   -0.0347</td> <td>    0.108</td> <td>   -0.322</td> <td> 0.748</td> <td>   -0.249</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x230</th>  <td>    0.1874</td> <td>    0.106</td> <td>    1.766</td> <td> 0.080</td> <td>   -0.023</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x231</th>  <td>   -0.1462</td> <td>    0.091</td> <td>   -1.604</td> <td> 0.112</td> <td>   -0.327</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x232</th>  <td>    0.1813</td> <td>    0.097</td> <td>    1.865</td> <td> 0.065</td> <td>   -0.012</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x233</th>  <td>    0.0514</td> <td>    0.104</td> <td>    0.493</td> <td> 0.623</td> <td>   -0.155</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x234</th>  <td>   -0.2205</td> <td>    0.101</td> <td>   -2.192</td> <td> 0.031</td> <td>   -0.420</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x235</th>  <td>    0.0909</td> <td>    0.098</td> <td>    0.926</td> <td> 0.357</td> <td>   -0.104</td> <td>    0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x236</th>  <td>    0.0675</td> <td>    0.114</td> <td>    0.590</td> <td> 0.557</td> <td>   -0.159</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x237</th>  <td>   -0.2021</td> <td>    0.104</td> <td>   -1.947</td> <td> 0.054</td> <td>   -0.408</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x238</th>  <td>    0.1379</td> <td>    0.104</td> <td>    1.325</td> <td> 0.188</td> <td>   -0.069</td> <td>    0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x239</th>  <td>   -0.0926</td> <td>    0.094</td> <td>   -0.987</td> <td> 0.326</td> <td>   -0.279</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x240</th>  <td>   -0.1299</td> <td>    0.088</td> <td>   -1.481</td> <td> 0.142</td> <td>   -0.304</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x241</th>  <td>   -0.0542</td> <td>    0.091</td> <td>   -0.593</td> <td> 0.555</td> <td>   -0.236</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x242</th>  <td>   -0.0469</td> <td>    0.090</td> <td>   -0.523</td> <td> 0.602</td> <td>   -0.225</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x243</th>  <td>   -0.0447</td> <td>    0.087</td> <td>   -0.515</td> <td> 0.607</td> <td>   -0.217</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x244</th>  <td>   -0.2715</td> <td>    0.097</td> <td>   -2.805</td> <td> 0.006</td> <td>   -0.464</td> <td>   -0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x245</th>  <td>    0.0796</td> <td>    0.090</td> <td>    0.883</td> <td> 0.380</td> <td>   -0.099</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x246</th>  <td>    0.0414</td> <td>    0.087</td> <td>    0.474</td> <td> 0.637</td> <td>   -0.132</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x247</th>  <td>    0.1927</td> <td>    0.119</td> <td>    1.620</td> <td> 0.108</td> <td>   -0.043</td> <td>    0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x248</th>  <td>   -0.0901</td> <td>    0.093</td> <td>   -0.972</td> <td> 0.333</td> <td>   -0.274</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x249</th>  <td>    0.1095</td> <td>    0.095</td> <td>    1.147</td> <td> 0.254</td> <td>   -0.080</td> <td>    0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x250</th>  <td>   -0.1233</td> <td>    0.095</td> <td>   -1.302</td> <td> 0.196</td> <td>   -0.311</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x251</th>  <td>   -0.0366</td> <td>    0.092</td> <td>   -0.399</td> <td> 0.691</td> <td>   -0.219</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x252</th>  <td>   -0.1879</td> <td>    0.104</td> <td>   -1.803</td> <td> 0.074</td> <td>   -0.395</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x253</th>  <td>   -0.0824</td> <td>    0.098</td> <td>   -0.840</td> <td> 0.403</td> <td>   -0.277</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x254</th>  <td>   -0.1967</td> <td>    0.090</td> <td>   -2.175</td> <td> 0.032</td> <td>   -0.376</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x255</th>  <td>   -0.2006</td> <td>    0.106</td> <td>   -1.900</td> <td> 0.060</td> <td>   -0.410</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x256</th>  <td>   -0.0005</td> <td>    0.090</td> <td>   -0.006</td> <td> 0.995</td> <td>   -0.180</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x257</th>  <td>   -0.0861</td> <td>    0.101</td> <td>   -0.849</td> <td> 0.398</td> <td>   -0.287</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x258</th>  <td>   -0.0057</td> <td>    0.094</td> <td>   -0.061</td> <td> 0.952</td> <td>   -0.192</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x259</th>  <td>   -0.1008</td> <td>    0.097</td> <td>   -1.036</td> <td> 0.303</td> <td>   -0.294</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x260</th>  <td>    0.1092</td> <td>    0.108</td> <td>    1.012</td> <td> 0.314</td> <td>   -0.105</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x261</th>  <td>    0.0695</td> <td>    0.107</td> <td>    0.652</td> <td> 0.516</td> <td>   -0.142</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x262</th>  <td>    0.0869</td> <td>    0.097</td> <td>    0.897</td> <td> 0.372</td> <td>   -0.105</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x263</th>  <td>   -0.1211</td> <td>    0.096</td> <td>   -1.263</td> <td> 0.210</td> <td>   -0.311</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x264</th>  <td>   -0.1357</td> <td>    0.088</td> <td>   -1.538</td> <td> 0.127</td> <td>   -0.311</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x265</th>  <td>    0.0690</td> <td>    0.090</td> <td>    0.764</td> <td> 0.447</td> <td>   -0.110</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x266</th>  <td>   -0.1704</td> <td>    0.093</td> <td>   -1.825</td> <td> 0.071</td> <td>   -0.356</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x267</th>  <td>   -0.0292</td> <td>    0.092</td> <td>   -0.318</td> <td> 0.751</td> <td>   -0.211</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x268</th>  <td>    0.0317</td> <td>    0.095</td> <td>    0.332</td> <td> 0.740</td> <td>   -0.157</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x269</th>  <td>    0.0154</td> <td>    0.096</td> <td>    0.160</td> <td> 0.873</td> <td>   -0.175</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x270</th>  <td>   -0.0731</td> <td>    0.088</td> <td>   -0.826</td> <td> 0.411</td> <td>   -0.249</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x271</th>  <td>   -0.0131</td> <td>    0.102</td> <td>   -0.129</td> <td> 0.898</td> <td>   -0.216</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x272</th>  <td>   -0.2091</td> <td>    0.100</td> <td>   -2.082</td> <td> 0.040</td> <td>   -0.408</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x273</th>  <td>    0.0430</td> <td>    0.093</td> <td>    0.460</td> <td> 0.646</td> <td>   -0.142</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x274</th>  <td>   -0.1206</td> <td>    0.106</td> <td>   -1.139</td> <td> 0.257</td> <td>   -0.331</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x275</th>  <td>    0.1919</td> <td>    0.102</td> <td>    1.875</td> <td> 0.064</td> <td>   -0.011</td> <td>    0.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x276</th>  <td>   -0.1260</td> <td>    0.100</td> <td>   -1.257</td> <td> 0.212</td> <td>   -0.325</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x277</th>  <td>   -0.0156</td> <td>    0.101</td> <td>   -0.154</td> <td> 0.878</td> <td>   -0.217</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x278</th>  <td>    0.1237</td> <td>    0.092</td> <td>    1.338</td> <td> 0.184</td> <td>   -0.060</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x279</th>  <td>   -0.1207</td> <td>    0.103</td> <td>   -1.172</td> <td> 0.244</td> <td>   -0.325</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x280</th>  <td>    0.0675</td> <td>    0.108</td> <td>    0.625</td> <td> 0.533</td> <td>   -0.147</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x281</th>  <td>   -0.0307</td> <td>    0.089</td> <td>   -0.346</td> <td> 0.730</td> <td>   -0.207</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x282</th>  <td>   -0.1886</td> <td>    0.093</td> <td>   -2.038</td> <td> 0.044</td> <td>   -0.372</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x283</th>  <td>   -0.0262</td> <td>    0.088</td> <td>   -0.299</td> <td> 0.766</td> <td>   -0.200</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x284</th>  <td>    0.1654</td> <td>    0.097</td> <td>    1.713</td> <td> 0.090</td> <td>   -0.026</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x285</th>  <td>   -0.0225</td> <td>    0.093</td> <td>   -0.241</td> <td> 0.810</td> <td>   -0.208</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x286</th>  <td>    0.0055</td> <td>    0.102</td> <td>    0.054</td> <td> 0.957</td> <td>   -0.197</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x287</th>  <td>    0.0864</td> <td>    0.096</td> <td>    0.899</td> <td> 0.371</td> <td>   -0.104</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x288</th>  <td>    0.1221</td> <td>    0.098</td> <td>    1.252</td> <td> 0.214</td> <td>   -0.071</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x289</th>  <td>    0.0383</td> <td>    0.090</td> <td>    0.424</td> <td> 0.673</td> <td>   -0.141</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x290</th>  <td>   -0.0112</td> <td>    0.105</td> <td>   -0.107</td> <td> 0.915</td> <td>   -0.219</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x291</th>  <td>    0.0017</td> <td>    0.084</td> <td>    0.020</td> <td> 0.984</td> <td>   -0.166</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x292</th>  <td>    0.0262</td> <td>    0.102</td> <td>    0.256</td> <td> 0.798</td> <td>   -0.176</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x293</th>  <td>   -0.1821</td> <td>    0.093</td> <td>   -1.957</td> <td> 0.053</td> <td>   -0.367</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x294</th>  <td>    0.0161</td> <td>    0.111</td> <td>    0.146</td> <td> 0.884</td> <td>   -0.203</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x295</th>  <td>    0.0565</td> <td>    0.094</td> <td>    0.603</td> <td> 0.548</td> <td>   -0.129</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x296</th>  <td>    0.0653</td> <td>    0.098</td> <td>    0.666</td> <td> 0.507</td> <td>   -0.129</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x297</th>  <td>    0.0685</td> <td>    0.099</td> <td>    0.691</td> <td> 0.491</td> <td>   -0.128</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x298</th>  <td>   -0.0558</td> <td>    0.087</td> <td>   -0.641</td> <td> 0.523</td> <td>   -0.229</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x299</th>  <td>   -0.0260</td> <td>    0.089</td> <td>   -0.292</td> <td> 0.771</td> <td>   -0.202</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x300</th>  <td>   -0.1151</td> <td>    0.099</td> <td>   -1.165</td> <td> 0.247</td> <td>   -0.311</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x301</th>  <td>    0.0103</td> <td>    0.094</td> <td>    0.109</td> <td> 0.914</td> <td>   -0.177</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x302</th>  <td>   -0.0634</td> <td>    0.098</td> <td>   -0.650</td> <td> 0.517</td> <td>   -0.257</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x303</th>  <td>    0.1010</td> <td>    0.098</td> <td>    1.034</td> <td> 0.304</td> <td>   -0.093</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x304</th>  <td>   -0.0330</td> <td>    0.096</td> <td>   -0.344</td> <td> 0.731</td> <td>   -0.223</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x305</th>  <td>   -0.0455</td> <td>    0.098</td> <td>   -0.466</td> <td> 0.642</td> <td>   -0.239</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x306</th>  <td>   -0.1239</td> <td>    0.089</td> <td>   -1.394</td> <td> 0.167</td> <td>   -0.300</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x307</th>  <td>   -0.1180</td> <td>    0.087</td> <td>   -1.350</td> <td> 0.180</td> <td>   -0.291</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x308</th>  <td>   -0.0132</td> <td>    0.087</td> <td>   -0.151</td> <td> 0.880</td> <td>   -0.187</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x309</th>  <td>   -0.1094</td> <td>    0.100</td> <td>   -1.096</td> <td> 0.276</td> <td>   -0.308</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x310</th>  <td>    0.0585</td> <td>    0.102</td> <td>    0.575</td> <td> 0.566</td> <td>   -0.143</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x311</th>  <td>   -0.0574</td> <td>    0.083</td> <td>   -0.689</td> <td> 0.493</td> <td>   -0.223</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x312</th>  <td>    0.0541</td> <td>    0.089</td> <td>    0.607</td> <td> 0.545</td> <td>   -0.123</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x313</th>  <td>   -0.1389</td> <td>    0.095</td> <td>   -1.460</td> <td> 0.148</td> <td>   -0.328</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x314</th>  <td>   -0.0674</td> <td>    0.095</td> <td>   -0.711</td> <td> 0.478</td> <td>   -0.255</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x315</th>  <td>    0.2338</td> <td>    0.095</td> <td>    2.456</td> <td> 0.016</td> <td>    0.045</td> <td>    0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x316</th>  <td>    0.0138</td> <td>    0.107</td> <td>    0.129</td> <td> 0.898</td> <td>   -0.199</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x317</th>  <td>   -0.0599</td> <td>    0.090</td> <td>   -0.662</td> <td> 0.509</td> <td>   -0.240</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x318</th>  <td>    0.0442</td> <td>    0.082</td> <td>    0.537</td> <td> 0.592</td> <td>   -0.119</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x319</th>  <td>   -0.1601</td> <td>    0.084</td> <td>   -1.906</td> <td> 0.060</td> <td>   -0.327</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x320</th>  <td>   -0.2258</td> <td>    0.098</td> <td>   -2.309</td> <td> 0.023</td> <td>   -0.420</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x321</th>  <td>    0.1742</td> <td>    0.096</td> <td>    1.812</td> <td> 0.073</td> <td>   -0.017</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x322</th>  <td>   -0.1382</td> <td>    0.098</td> <td>   -1.407</td> <td> 0.162</td> <td>   -0.333</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x323</th>  <td>    0.0593</td> <td>    0.107</td> <td>    0.553</td> <td> 0.581</td> <td>   -0.153</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x324</th>  <td>    0.0505</td> <td>    0.096</td> <td>    0.528</td> <td> 0.599</td> <td>   -0.139</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x325</th>  <td>    0.0613</td> <td>    0.092</td> <td>    0.666</td> <td> 0.507</td> <td>   -0.121</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x326</th>  <td>   -0.2138</td> <td>    0.099</td> <td>   -2.154</td> <td> 0.034</td> <td>   -0.411</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x327</th>  <td>   -0.0933</td> <td>    0.088</td> <td>   -1.056</td> <td> 0.294</td> <td>   -0.269</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x328</th>  <td>    0.0948</td> <td>    0.087</td> <td>    1.087</td> <td> 0.280</td> <td>   -0.078</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x329</th>  <td>   -0.2036</td> <td>    0.092</td> <td>   -2.215</td> <td> 0.029</td> <td>   -0.386</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x330</th>  <td>   -0.1470</td> <td>    0.095</td> <td>   -1.543</td> <td> 0.126</td> <td>   -0.336</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x331</th>  <td>    0.0210</td> <td>    0.101</td> <td>    0.209</td> <td> 0.835</td> <td>   -0.179</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x332</th>  <td>   -0.1556</td> <td>    0.091</td> <td>   -1.702</td> <td> 0.092</td> <td>   -0.337</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x333</th>  <td>   -0.0174</td> <td>    0.091</td> <td>   -0.192</td> <td> 0.848</td> <td>   -0.197</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x334</th>  <td>    0.0712</td> <td>    0.092</td> <td>    0.776</td> <td> 0.440</td> <td>   -0.111</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x335</th>  <td>   -0.0238</td> <td>    0.109</td> <td>   -0.219</td> <td> 0.827</td> <td>   -0.240</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x336</th>  <td>    0.1141</td> <td>    0.095</td> <td>    1.206</td> <td> 0.231</td> <td>   -0.074</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x337</th>  <td>   -0.1903</td> <td>    0.097</td> <td>   -1.968</td> <td> 0.052</td> <td>   -0.382</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x338</th>  <td>    0.2025</td> <td>    0.096</td> <td>    2.120</td> <td> 0.036</td> <td>    0.013</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x339</th>  <td>    0.2132</td> <td>    0.096</td> <td>    2.223</td> <td> 0.029</td> <td>    0.023</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x340</th>  <td>    0.0441</td> <td>    0.088</td> <td>    0.504</td> <td> 0.616</td> <td>   -0.130</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x341</th>  <td>   -0.1502</td> <td>    0.103</td> <td>   -1.457</td> <td> 0.148</td> <td>   -0.355</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x342</th>  <td>   -0.1692</td> <td>    0.099</td> <td>   -1.705</td> <td> 0.091</td> <td>   -0.366</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x343</th>  <td>   -0.0336</td> <td>    0.088</td> <td>   -0.384</td> <td> 0.702</td> <td>   -0.208</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x344</th>  <td>   -0.0036</td> <td>    0.092</td> <td>   -0.039</td> <td> 0.969</td> <td>   -0.186</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x345</th>  <td>   -0.0798</td> <td>    0.094</td> <td>   -0.850</td> <td> 0.398</td> <td>   -0.266</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x346</th>  <td>    0.0369</td> <td>    0.096</td> <td>    0.383</td> <td> 0.703</td> <td>   -0.154</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x347</th>  <td>    0.0085</td> <td>    0.088</td> <td>    0.097</td> <td> 0.923</td> <td>   -0.165</td> <td>    0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x348</th>  <td>   -0.0753</td> <td>    0.096</td> <td>   -0.783</td> <td> 0.436</td> <td>   -0.266</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x349</th>  <td>    0.0711</td> <td>    0.092</td> <td>    0.773</td> <td> 0.441</td> <td>   -0.111</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x350</th>  <td>    0.1258</td> <td>    0.092</td> <td>    1.367</td> <td> 0.175</td> <td>   -0.057</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x351</th>  <td>   -0.0136</td> <td>    0.100</td> <td>   -0.136</td> <td> 0.892</td> <td>   -0.212</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x352</th>  <td>   -0.0433</td> <td>    0.103</td> <td>   -0.423</td> <td> 0.674</td> <td>   -0.247</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x353</th>  <td>    0.0833</td> <td>    0.103</td> <td>    0.812</td> <td> 0.419</td> <td>   -0.120</td> <td>    0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x354</th>  <td>   -0.0559</td> <td>    0.086</td> <td>   -0.651</td> <td> 0.517</td> <td>   -0.226</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x355</th>  <td>   -0.1099</td> <td>    0.103</td> <td>   -1.065</td> <td> 0.290</td> <td>   -0.315</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x356</th>  <td>   -0.1491</td> <td>    0.091</td> <td>   -1.646</td> <td> 0.103</td> <td>   -0.329</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x357</th>  <td>    0.0899</td> <td>    0.103</td> <td>    0.874</td> <td> 0.384</td> <td>   -0.114</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x358</th>  <td>    0.0981</td> <td>    0.107</td> <td>    0.918</td> <td> 0.361</td> <td>   -0.114</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x359</th>  <td>   -0.0234</td> <td>    0.090</td> <td>   -0.260</td> <td> 0.795</td> <td>   -0.202</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x360</th>  <td>    0.0177</td> <td>    0.099</td> <td>    0.179</td> <td> 0.859</td> <td>   -0.179</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x361</th>  <td>   -0.0373</td> <td>    0.105</td> <td>   -0.354</td> <td> 0.724</td> <td>   -0.247</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x362</th>  <td>   -0.1120</td> <td>    0.100</td> <td>   -1.116</td> <td> 0.267</td> <td>   -0.311</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x363</th>  <td>   -0.0976</td> <td>    0.088</td> <td>   -1.115</td> <td> 0.268</td> <td>   -0.271</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x364</th>  <td>   -0.2084</td> <td>    0.094</td> <td>   -2.225</td> <td> 0.028</td> <td>   -0.394</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x365</th>  <td>    0.0369</td> <td>    0.104</td> <td>    0.354</td> <td> 0.724</td> <td>   -0.170</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x366</th>  <td>    0.0903</td> <td>    0.108</td> <td>    0.833</td> <td> 0.407</td> <td>   -0.125</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x367</th>  <td>    0.0575</td> <td>    0.088</td> <td>    0.650</td> <td> 0.518</td> <td>   -0.118</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x368</th>  <td>    0.0553</td> <td>    0.098</td> <td>    0.564</td> <td> 0.574</td> <td>   -0.139</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x369</th>  <td>   -0.1429</td> <td>    0.106</td> <td>   -1.347</td> <td> 0.181</td> <td>   -0.353</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x370</th>  <td>   -0.2386</td> <td>    0.095</td> <td>   -2.523</td> <td> 0.013</td> <td>   -0.426</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x371</th>  <td>    0.1913</td> <td>    0.112</td> <td>    1.716</td> <td> 0.089</td> <td>   -0.030</td> <td>    0.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x372</th>  <td>    0.2498</td> <td>    0.095</td> <td>    2.642</td> <td> 0.010</td> <td>    0.062</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x373</th>  <td>    0.0829</td> <td>    0.094</td> <td>    0.884</td> <td> 0.379</td> <td>   -0.103</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x374</th>  <td>    0.0499</td> <td>    0.102</td> <td>    0.488</td> <td> 0.627</td> <td>   -0.153</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x375</th>  <td>    0.0362</td> <td>    0.092</td> <td>    0.393</td> <td> 0.695</td> <td>   -0.147</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x376</th>  <td>   -0.0389</td> <td>    0.090</td> <td>   -0.434</td> <td> 0.665</td> <td>   -0.217</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x377</th>  <td>   -0.0424</td> <td>    0.101</td> <td>   -0.418</td> <td> 0.677</td> <td>   -0.243</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x378</th>  <td>   -0.0431</td> <td>    0.096</td> <td>   -0.450</td> <td> 0.654</td> <td>   -0.233</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x379</th>  <td>   -0.0939</td> <td>    0.094</td> <td>   -1.002</td> <td> 0.319</td> <td>   -0.280</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x380</th>  <td>    0.2044</td> <td>    0.100</td> <td>    2.042</td> <td> 0.044</td> <td>    0.006</td> <td>    0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x381</th>  <td>   -0.0935</td> <td>    0.098</td> <td>   -0.949</td> <td> 0.345</td> <td>   -0.289</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x382</th>  <td>   -0.0466</td> <td>    0.102</td> <td>   -0.458</td> <td> 0.648</td> <td>   -0.249</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x383</th>  <td>   -0.0812</td> <td>    0.118</td> <td>   -0.686</td> <td> 0.494</td> <td>   -0.316</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x384</th>  <td>   -0.0774</td> <td>    0.098</td> <td>   -0.793</td> <td> 0.430</td> <td>   -0.271</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x385</th>  <td>    0.1264</td> <td>    0.088</td> <td>    1.437</td> <td> 0.154</td> <td>   -0.048</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x386</th>  <td>   -0.2162</td> <td>    0.102</td> <td>   -2.130</td> <td> 0.036</td> <td>   -0.418</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x387</th>  <td>    0.1551</td> <td>    0.099</td> <td>    1.563</td> <td> 0.121</td> <td>   -0.042</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x388</th>  <td>   -0.0024</td> <td>    0.087</td> <td>   -0.028</td> <td> 0.978</td> <td>   -0.174</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x389</th>  <td>    0.0177</td> <td>    0.093</td> <td>    0.190</td> <td> 0.849</td> <td>   -0.167</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x390</th>  <td>   -0.0097</td> <td>    0.107</td> <td>   -0.091</td> <td> 0.928</td> <td>   -0.222</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x391</th>  <td>    0.1685</td> <td>    0.104</td> <td>    1.616</td> <td> 0.109</td> <td>   -0.038</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x392</th>  <td>   -0.1456</td> <td>    0.087</td> <td>   -1.673</td> <td> 0.097</td> <td>   -0.318</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x393</th>  <td>    0.1659</td> <td>    0.110</td> <td>    1.504</td> <td> 0.136</td> <td>   -0.053</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x394</th>  <td>    0.0853</td> <td>    0.093</td> <td>    0.918</td> <td> 0.361</td> <td>   -0.099</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x395</th>  <td>   -0.0521</td> <td>    0.097</td> <td>   -0.537</td> <td> 0.592</td> <td>   -0.245</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x396</th>  <td>   -0.0281</td> <td>    0.093</td> <td>   -0.301</td> <td> 0.764</td> <td>   -0.213</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x397</th>  <td>    0.0550</td> <td>    0.094</td> <td>    0.583</td> <td> 0.561</td> <td>   -0.132</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x398</th>  <td>   -0.1562</td> <td>    0.100</td> <td>   -1.564</td> <td> 0.121</td> <td>   -0.354</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x399</th>  <td>    0.0488</td> <td>    0.108</td> <td>    0.453</td> <td> 0.652</td> <td>   -0.165</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x400</th>  <td>    0.2709</td> <td>    0.102</td> <td>    2.659</td> <td> 0.009</td> <td>    0.069</td> <td>    0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x401</th>  <td>   -0.0837</td> <td>    0.096</td> <td>   -0.877</td> <td> 0.383</td> <td>   -0.273</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x402</th>  <td>   -0.0102</td> <td>    0.098</td> <td>   -0.105</td> <td> 0.917</td> <td>   -0.205</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x403</th>  <td>    0.0642</td> <td>    0.111</td> <td>    0.577</td> <td> 0.565</td> <td>   -0.157</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x404</th>  <td>    0.1265</td> <td>    0.088</td> <td>    1.437</td> <td> 0.154</td> <td>   -0.048</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x405</th>  <td>   -0.0066</td> <td>    0.094</td> <td>   -0.071</td> <td> 0.944</td> <td>   -0.192</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x406</th>  <td>   -0.0789</td> <td>    0.100</td> <td>   -0.787</td> <td> 0.433</td> <td>   -0.278</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x407</th>  <td>    0.2168</td> <td>    0.090</td> <td>    2.408</td> <td> 0.018</td> <td>    0.038</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x408</th>  <td>    0.2755</td> <td>    0.091</td> <td>    3.027</td> <td> 0.003</td> <td>    0.095</td> <td>    0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x409</th>  <td>    0.0893</td> <td>    0.097</td> <td>    0.923</td> <td> 0.358</td> <td>   -0.103</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x410</th>  <td>    0.0292</td> <td>    0.101</td> <td>    0.290</td> <td> 0.772</td> <td>   -0.170</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x411</th>  <td>    0.0573</td> <td>    0.096</td> <td>    0.595</td> <td> 0.553</td> <td>   -0.134</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x412</th>  <td>    0.0583</td> <td>    0.109</td> <td>    0.535</td> <td> 0.594</td> <td>   -0.158</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x413</th>  <td>    0.0240</td> <td>    0.096</td> <td>    0.252</td> <td> 0.802</td> <td>   -0.165</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x414</th>  <td>    0.0741</td> <td>    0.098</td> <td>    0.760</td> <td> 0.449</td> <td>   -0.119</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x415</th>  <td>   -0.0273</td> <td>    0.108</td> <td>   -0.254</td> <td> 0.800</td> <td>   -0.241</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x416</th>  <td>   -0.0077</td> <td>    0.086</td> <td>   -0.089</td> <td> 0.929</td> <td>   -0.179</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x417</th>  <td>   -0.0315</td> <td>    0.096</td> <td>   -0.328</td> <td> 0.743</td> <td>   -0.222</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x418</th>  <td>    0.0296</td> <td>    0.086</td> <td>    0.342</td> <td> 0.733</td> <td>   -0.142</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x419</th>  <td>    0.0240</td> <td>    0.097</td> <td>    0.246</td> <td> 0.806</td> <td>   -0.169</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x420</th>  <td>   -0.0995</td> <td>    0.096</td> <td>   -1.042</td> <td> 0.300</td> <td>   -0.289</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x421</th>  <td>    0.0330</td> <td>    0.091</td> <td>    0.365</td> <td> 0.716</td> <td>   -0.147</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x422</th>  <td>    0.0966</td> <td>    0.088</td> <td>    1.101</td> <td> 0.274</td> <td>   -0.078</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x423</th>  <td>   -0.1466</td> <td>    0.095</td> <td>   -1.547</td> <td> 0.125</td> <td>   -0.335</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x424</th>  <td>    0.0320</td> <td>    0.084</td> <td>    0.381</td> <td> 0.704</td> <td>   -0.135</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x425</th>  <td>   -0.1023</td> <td>    0.110</td> <td>   -0.933</td> <td> 0.353</td> <td>   -0.320</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x426</th>  <td>    0.0026</td> <td>    0.097</td> <td>    0.027</td> <td> 0.978</td> <td>   -0.189</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x427</th>  <td>    0.0635</td> <td>    0.113</td> <td>    0.560</td> <td> 0.577</td> <td>   -0.162</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x428</th>  <td>    0.0762</td> <td>    0.091</td> <td>    0.836</td> <td> 0.405</td> <td>   -0.105</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x429</th>  <td>   -0.1009</td> <td>    0.092</td> <td>   -1.101</td> <td> 0.274</td> <td>   -0.283</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x430</th>  <td>   -0.0321</td> <td>    0.102</td> <td>   -0.314</td> <td> 0.755</td> <td>   -0.235</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x431</th>  <td>    0.0670</td> <td>    0.094</td> <td>    0.712</td> <td> 0.478</td> <td>   -0.120</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x432</th>  <td>   -0.0495</td> <td>    0.093</td> <td>   -0.533</td> <td> 0.595</td> <td>   -0.234</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x433</th>  <td>    0.1573</td> <td>    0.106</td> <td>    1.483</td> <td> 0.141</td> <td>   -0.053</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x434</th>  <td>    0.0599</td> <td>    0.100</td> <td>    0.599</td> <td> 0.551</td> <td>   -0.139</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x435</th>  <td>   -0.2614</td> <td>    0.098</td> <td>   -2.669</td> <td> 0.009</td> <td>   -0.456</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x436</th>  <td>    0.0397</td> <td>    0.089</td> <td>    0.447</td> <td> 0.656</td> <td>   -0.137</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x437</th>  <td>    0.1227</td> <td>    0.104</td> <td>    1.182</td> <td> 0.240</td> <td>   -0.083</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x438</th>  <td>   -0.2036</td> <td>    0.107</td> <td>   -1.898</td> <td> 0.061</td> <td>   -0.416</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x439</th>  <td>    0.0766</td> <td>    0.094</td> <td>    0.813</td> <td> 0.418</td> <td>   -0.110</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x440</th>  <td>    0.0626</td> <td>    0.095</td> <td>    0.659</td> <td> 0.512</td> <td>   -0.126</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x441</th>  <td>    0.1334</td> <td>    0.102</td> <td>    1.313</td> <td> 0.192</td> <td>   -0.068</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x442</th>  <td>   -0.0219</td> <td>    0.118</td> <td>   -0.186</td> <td> 0.853</td> <td>   -0.256</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x443</th>  <td>   -0.1467</td> <td>    0.097</td> <td>   -1.508</td> <td> 0.135</td> <td>   -0.340</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x444</th>  <td>    0.0979</td> <td>    0.094</td> <td>    1.041</td> <td> 0.300</td> <td>   -0.089</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x445</th>  <td>   -0.1274</td> <td>    0.089</td> <td>   -1.436</td> <td> 0.154</td> <td>   -0.303</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x446</th>  <td>   -0.0071</td> <td>    0.093</td> <td>   -0.077</td> <td> 0.939</td> <td>   -0.191</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x447</th>  <td>    0.1176</td> <td>    0.102</td> <td>    1.148</td> <td> 0.254</td> <td>   -0.086</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x448</th>  <td>    0.0140</td> <td>    0.096</td> <td>    0.147</td> <td> 0.884</td> <td>   -0.176</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x449</th>  <td>    0.0199</td> <td>    0.098</td> <td>    0.204</td> <td> 0.838</td> <td>   -0.174</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x450</th>  <td>   -0.0023</td> <td>    0.093</td> <td>   -0.025</td> <td> 0.980</td> <td>   -0.187</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x451</th>  <td>   -0.0183</td> <td>    0.096</td> <td>   -0.191</td> <td> 0.849</td> <td>   -0.208</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x452</th>  <td>   -0.0820</td> <td>    0.094</td> <td>   -0.870</td> <td> 0.387</td> <td>   -0.269</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x453</th>  <td>   -0.1722</td> <td>    0.098</td> <td>   -1.756</td> <td> 0.082</td> <td>   -0.367</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x454</th>  <td>   -0.1311</td> <td>    0.111</td> <td>   -1.179</td> <td> 0.241</td> <td>   -0.352</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x455</th>  <td>    0.0143</td> <td>    0.094</td> <td>    0.151</td> <td> 0.880</td> <td>   -0.173</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x456</th>  <td>    0.0661</td> <td>    0.104</td> <td>    0.638</td> <td> 0.525</td> <td>   -0.139</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x457</th>  <td>    0.0876</td> <td>    0.091</td> <td>    0.964</td> <td> 0.337</td> <td>   -0.093</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x458</th>  <td>    0.0600</td> <td>    0.102</td> <td>    0.588</td> <td> 0.558</td> <td>   -0.142</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x459</th>  <td>    0.1862</td> <td>    0.102</td> <td>    1.832</td> <td> 0.070</td> <td>   -0.016</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x460</th>  <td>   -0.0654</td> <td>    0.089</td> <td>   -0.733</td> <td> 0.465</td> <td>   -0.243</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x461</th>  <td>    0.0298</td> <td>    0.096</td> <td>    0.312</td> <td> 0.756</td> <td>   -0.160</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x462</th>  <td>    0.0917</td> <td>    0.090</td> <td>    1.016</td> <td> 0.312</td> <td>   -0.087</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x463</th>  <td>    0.0295</td> <td>    0.107</td> <td>    0.276</td> <td> 0.783</td> <td>   -0.183</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x464</th>  <td>    0.1266</td> <td>    0.100</td> <td>    1.272</td> <td> 0.206</td> <td>   -0.071</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x465</th>  <td>   -0.1984</td> <td>    0.090</td> <td>   -2.195</td> <td> 0.031</td> <td>   -0.378</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x466</th>  <td>    0.0761</td> <td>    0.096</td> <td>    0.793</td> <td> 0.430</td> <td>   -0.114</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x467</th>  <td>    0.0434</td> <td>    0.091</td> <td>    0.475</td> <td> 0.636</td> <td>   -0.138</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x468</th>  <td>   -0.2014</td> <td>    0.096</td> <td>   -2.104</td> <td> 0.038</td> <td>   -0.391</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x469</th>  <td>   -0.0476</td> <td>    0.093</td> <td>   -0.514</td> <td> 0.608</td> <td>   -0.231</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x470</th>  <td>    0.0424</td> <td>    0.091</td> <td>    0.464</td> <td> 0.644</td> <td>   -0.139</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x471</th>  <td>   -0.0500</td> <td>    0.097</td> <td>   -0.516</td> <td> 0.607</td> <td>   -0.243</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x472</th>  <td>    0.1295</td> <td>    0.098</td> <td>    1.327</td> <td> 0.188</td> <td>   -0.064</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x473</th>  <td>   -0.0039</td> <td>    0.088</td> <td>   -0.044</td> <td> 0.965</td> <td>   -0.179</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x474</th>  <td>   -0.1622</td> <td>    0.093</td> <td>   -1.750</td> <td> 0.083</td> <td>   -0.346</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x475</th>  <td>    0.0148</td> <td>    0.092</td> <td>    0.161</td> <td> 0.872</td> <td>   -0.167</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x476</th>  <td>   -0.1288</td> <td>    0.095</td> <td>   -1.352</td> <td> 0.180</td> <td>   -0.318</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x477</th>  <td>    0.2245</td> <td>    0.091</td> <td>    2.459</td> <td> 0.016</td> <td>    0.043</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x478</th>  <td>   -0.1532</td> <td>    0.098</td> <td>   -1.557</td> <td> 0.123</td> <td>   -0.348</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x479</th>  <td>    0.1009</td> <td>    0.091</td> <td>    1.106</td> <td> 0.271</td> <td>   -0.080</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x480</th>  <td>   -0.0452</td> <td>    0.097</td> <td>   -0.465</td> <td> 0.643</td> <td>   -0.238</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x481</th>  <td>   -0.1374</td> <td>    0.100</td> <td>   -1.377</td> <td> 0.172</td> <td>   -0.335</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x482</th>  <td>   -0.0920</td> <td>    0.095</td> <td>   -0.970</td> <td> 0.334</td> <td>   -0.280</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x483</th>  <td>   -0.0716</td> <td>    0.087</td> <td>   -0.820</td> <td> 0.414</td> <td>   -0.245</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x484</th>  <td>   -0.0753</td> <td>    0.094</td> <td>   -0.803</td> <td> 0.424</td> <td>   -0.261</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x485</th>  <td>    0.1370</td> <td>    0.106</td> <td>    1.294</td> <td> 0.199</td> <td>   -0.073</td> <td>    0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x486</th>  <td>    0.0167</td> <td>    0.098</td> <td>    0.170</td> <td> 0.865</td> <td>   -0.179</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x487</th>  <td>   -0.0673</td> <td>    0.104</td> <td>   -0.650</td> <td> 0.517</td> <td>   -0.273</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x488</th>  <td>    0.0348</td> <td>    0.095</td> <td>    0.368</td> <td> 0.714</td> <td>   -0.153</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x489</th>  <td>    0.2082</td> <td>    0.098</td> <td>    2.134</td> <td> 0.035</td> <td>    0.015</td> <td>    0.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x490</th>  <td>    0.0350</td> <td>    0.087</td> <td>    0.400</td> <td> 0.690</td> <td>   -0.139</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x491</th>  <td>    0.1917</td> <td>    0.092</td> <td>    2.089</td> <td> 0.039</td> <td>    0.010</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x492</th>  <td>    0.1758</td> <td>    0.089</td> <td>    1.984</td> <td> 0.050</td> <td>-6.62e-05</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x493</th>  <td>    0.2226</td> <td>    0.101</td> <td>    2.198</td> <td> 0.030</td> <td>    0.022</td> <td>    0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x494</th>  <td>    0.0377</td> <td>    0.102</td> <td>    0.368</td> <td> 0.713</td> <td>   -0.166</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x495</th>  <td>   -0.0485</td> <td>    0.084</td> <td>   -0.580</td> <td> 0.563</td> <td>   -0.215</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x496</th>  <td>   -0.0844</td> <td>    0.084</td> <td>   -1.007</td> <td> 0.317</td> <td>   -0.251</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x497</th>  <td>    0.0391</td> <td>    0.086</td> <td>    0.456</td> <td> 0.650</td> <td>   -0.131</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x498</th>  <td>   -0.0455</td> <td>    0.093</td> <td>   -0.488</td> <td> 0.627</td> <td>   -0.231</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x499</th>  <td>    0.1273</td> <td>    0.086</td> <td>    1.474</td> <td> 0.144</td> <td>   -0.044</td> <td>    0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x500</th>  <td>   -0.0013</td> <td>    0.099</td> <td>   -0.014</td> <td> 0.989</td> <td>   -0.197</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x501</th>  <td>    0.1116</td> <td>    0.096</td> <td>    1.164</td> <td> 0.247</td> <td>   -0.079</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x502</th>  <td>    0.1800</td> <td>    0.094</td> <td>    1.920</td> <td> 0.058</td> <td>   -0.006</td> <td>    0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x503</th>  <td>    0.1937</td> <td>    0.096</td> <td>    2.022</td> <td> 0.046</td> <td>    0.004</td> <td>    0.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x504</th>  <td>    0.1303</td> <td>    0.091</td> <td>    1.433</td> <td> 0.155</td> <td>   -0.050</td> <td>    0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x505</th>  <td>    0.0318</td> <td>    0.109</td> <td>    0.291</td> <td> 0.771</td> <td>   -0.185</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x506</th>  <td>    0.0499</td> <td>    0.090</td> <td>    0.554</td> <td> 0.581</td> <td>   -0.129</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x507</th>  <td>   -0.0801</td> <td>    0.091</td> <td>   -0.880</td> <td> 0.381</td> <td>   -0.261</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x508</th>  <td>    0.0571</td> <td>    0.090</td> <td>    0.634</td> <td> 0.527</td> <td>   -0.122</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x509</th>  <td>    0.1327</td> <td>    0.087</td> <td>    1.525</td> <td> 0.130</td> <td>   -0.040</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x510</th>  <td>    0.0465</td> <td>    0.092</td> <td>    0.503</td> <td> 0.616</td> <td>   -0.137</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x511</th>  <td>    0.0471</td> <td>    0.110</td> <td>    0.429</td> <td> 0.669</td> <td>   -0.171</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x512</th>  <td>   -0.1812</td> <td>    0.102</td> <td>   -1.784</td> <td> 0.077</td> <td>   -0.383</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x513</th>  <td>   -0.0109</td> <td>    0.102</td> <td>   -0.107</td> <td> 0.915</td> <td>   -0.213</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x514</th>  <td>    0.1507</td> <td>    0.089</td> <td>    1.700</td> <td> 0.092</td> <td>   -0.025</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x515</th>  <td>    0.0657</td> <td>    0.087</td> <td>    0.751</td> <td> 0.455</td> <td>   -0.108</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x516</th>  <td>    0.1365</td> <td>    0.103</td> <td>    1.329</td> <td> 0.187</td> <td>   -0.067</td> <td>    0.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x517</th>  <td>    0.0134</td> <td>    0.087</td> <td>    0.155</td> <td> 0.878</td> <td>   -0.159</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x518</th>  <td>   -0.0155</td> <td>    0.096</td> <td>   -0.161</td> <td> 0.872</td> <td>   -0.206</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x519</th>  <td>   -0.1199</td> <td>    0.110</td> <td>   -1.094</td> <td> 0.277</td> <td>   -0.337</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x520</th>  <td>    0.1991</td> <td>    0.102</td> <td>    1.950</td> <td> 0.054</td> <td>   -0.004</td> <td>    0.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x521</th>  <td>   -0.1128</td> <td>    0.092</td> <td>   -1.231</td> <td> 0.221</td> <td>   -0.295</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x522</th>  <td>    0.1754</td> <td>    0.103</td> <td>    1.701</td> <td> 0.092</td> <td>   -0.029</td> <td>    0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x523</th>  <td>   -0.0449</td> <td>    0.104</td> <td>   -0.433</td> <td> 0.666</td> <td>   -0.250</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x524</th>  <td>   -0.0809</td> <td>    0.099</td> <td>   -0.816</td> <td> 0.417</td> <td>   -0.278</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x525</th>  <td>   -0.1478</td> <td>    0.113</td> <td>   -1.310</td> <td> 0.193</td> <td>   -0.372</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x526</th>  <td>    0.1286</td> <td>    0.098</td> <td>    1.309</td> <td> 0.194</td> <td>   -0.066</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x527</th>  <td>    0.0964</td> <td>    0.087</td> <td>    1.102</td> <td> 0.273</td> <td>   -0.077</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x528</th>  <td>    0.0306</td> <td>    0.088</td> <td>    0.348</td> <td> 0.728</td> <td>   -0.144</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x529</th>  <td>   -0.0311</td> <td>    0.099</td> <td>   -0.314</td> <td> 0.754</td> <td>   -0.228</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x530</th>  <td>    0.0694</td> <td>    0.091</td> <td>    0.760</td> <td> 0.449</td> <td>   -0.112</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x531</th>  <td>   -0.1207</td> <td>    0.092</td> <td>   -1.313</td> <td> 0.192</td> <td>   -0.303</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x532</th>  <td>    0.0312</td> <td>    0.108</td> <td>    0.288</td> <td> 0.774</td> <td>   -0.184</td> <td>    0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x533</th>  <td>   -0.0070</td> <td>    0.111</td> <td>   -0.063</td> <td> 0.950</td> <td>   -0.228</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x534</th>  <td>   -0.1468</td> <td>    0.103</td> <td>   -1.427</td> <td> 0.157</td> <td>   -0.351</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x535</th>  <td>    0.0609</td> <td>    0.096</td> <td>    0.632</td> <td> 0.529</td> <td>   -0.130</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x536</th>  <td>    0.1526</td> <td>    0.111</td> <td>    1.377</td> <td> 0.172</td> <td>   -0.067</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x537</th>  <td>    0.0490</td> <td>    0.095</td> <td>    0.517</td> <td> 0.606</td> <td>   -0.139</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x538</th>  <td>    0.1973</td> <td>    0.089</td> <td>    2.226</td> <td> 0.028</td> <td>    0.021</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x539</th>  <td>   -0.1739</td> <td>    0.095</td> <td>   -1.836</td> <td> 0.069</td> <td>   -0.362</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x540</th>  <td>   -0.0313</td> <td>    0.096</td> <td>   -0.325</td> <td> 0.746</td> <td>   -0.222</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x541</th>  <td>   -0.1672</td> <td>    0.089</td> <td>   -1.874</td> <td> 0.064</td> <td>   -0.344</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x542</th>  <td>    0.0731</td> <td>    0.107</td> <td>    0.685</td> <td> 0.495</td> <td>   -0.139</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x543</th>  <td>   -0.1114</td> <td>    0.092</td> <td>   -1.215</td> <td> 0.227</td> <td>   -0.293</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x544</th>  <td>   -0.0819</td> <td>    0.096</td> <td>   -0.849</td> <td> 0.398</td> <td>   -0.273</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x545</th>  <td>   -0.0138</td> <td>    0.101</td> <td>   -0.137</td> <td> 0.892</td> <td>   -0.214</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x546</th>  <td>   -0.0312</td> <td>    0.104</td> <td>   -0.300</td> <td> 0.765</td> <td>   -0.237</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x547</th>  <td>    0.0400</td> <td>    0.090</td> <td>    0.442</td> <td> 0.659</td> <td>   -0.139</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x548</th>  <td>   -0.0113</td> <td>    0.084</td> <td>   -0.134</td> <td> 0.894</td> <td>   -0.179</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x549</th>  <td>   -0.2650</td> <td>    0.100</td> <td>   -2.639</td> <td> 0.010</td> <td>   -0.464</td> <td>   -0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x550</th>  <td>    0.1158</td> <td>    0.088</td> <td>    1.316</td> <td> 0.191</td> <td>   -0.059</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x551</th>  <td>    0.0455</td> <td>    0.094</td> <td>    0.486</td> <td> 0.628</td> <td>   -0.140</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x552</th>  <td>    0.0526</td> <td>    0.094</td> <td>    0.560</td> <td> 0.576</td> <td>   -0.134</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x553</th>  <td>    0.1862</td> <td>    0.093</td> <td>    2.005</td> <td> 0.048</td> <td>    0.002</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x554</th>  <td>   -0.1394</td> <td>    0.093</td> <td>   -1.498</td> <td> 0.137</td> <td>   -0.324</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x555</th>  <td>    0.0056</td> <td>    0.086</td> <td>    0.065</td> <td> 0.949</td> <td>   -0.166</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x556</th>  <td>    0.2161</td> <td>    0.104</td> <td>    2.081</td> <td> 0.040</td> <td>    0.010</td> <td>    0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x557</th>  <td>    0.1428</td> <td>    0.099</td> <td>    1.445</td> <td> 0.152</td> <td>   -0.053</td> <td>    0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x558</th>  <td>    0.0285</td> <td>    0.095</td> <td>    0.300</td> <td> 0.765</td> <td>   -0.160</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x559</th>  <td>   -0.0024</td> <td>    0.104</td> <td>   -0.023</td> <td> 0.982</td> <td>   -0.208</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x560</th>  <td>   -0.0963</td> <td>    0.100</td> <td>   -0.967</td> <td> 0.336</td> <td>   -0.294</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x561</th>  <td>   -0.1320</td> <td>    0.094</td> <td>   -1.409</td> <td> 0.162</td> <td>   -0.318</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x562</th>  <td>    0.0881</td> <td>    0.101</td> <td>    0.871</td> <td> 0.386</td> <td>   -0.113</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x563</th>  <td>    0.0391</td> <td>    0.092</td> <td>    0.424</td> <td> 0.673</td> <td>   -0.144</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x564</th>  <td>   -0.1032</td> <td>    0.106</td> <td>   -0.976</td> <td> 0.331</td> <td>   -0.313</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x565</th>  <td>   -0.1194</td> <td>    0.093</td> <td>   -1.279</td> <td> 0.204</td> <td>   -0.305</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x566</th>  <td>    0.1884</td> <td>    0.100</td> <td>    1.879</td> <td> 0.063</td> <td>   -0.011</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x567</th>  <td>   -0.1295</td> <td>    0.100</td> <td>   -1.293</td> <td> 0.199</td> <td>   -0.328</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x568</th>  <td>    0.0868</td> <td>    0.104</td> <td>    0.834</td> <td> 0.407</td> <td>   -0.120</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x569</th>  <td>   -0.0542</td> <td>    0.106</td> <td>   -0.512</td> <td> 0.610</td> <td>   -0.264</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x570</th>  <td>    0.1676</td> <td>    0.097</td> <td>    1.735</td> <td> 0.086</td> <td>   -0.024</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x571</th>  <td>    0.0716</td> <td>    0.085</td> <td>    0.840</td> <td> 0.403</td> <td>   -0.098</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x572</th>  <td>   -0.0638</td> <td>    0.102</td> <td>   -0.625</td> <td> 0.534</td> <td>   -0.267</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x573</th>  <td>    0.2153</td> <td>    0.093</td> <td>    2.309</td> <td> 0.023</td> <td>    0.030</td> <td>    0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x574</th>  <td>   -0.0119</td> <td>    0.096</td> <td>   -0.124</td> <td> 0.902</td> <td>   -0.202</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x575</th>  <td>    0.0442</td> <td>    0.096</td> <td>    0.460</td> <td> 0.647</td> <td>   -0.147</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x576</th>  <td>   -0.0551</td> <td>    0.092</td> <td>   -0.596</td> <td> 0.552</td> <td>   -0.238</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x577</th>  <td>    0.0124</td> <td>    0.092</td> <td>    0.135</td> <td> 0.893</td> <td>   -0.170</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x578</th>  <td>    0.0011</td> <td>    0.090</td> <td>    0.012</td> <td> 0.991</td> <td>   -0.177</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x579</th>  <td>    0.0772</td> <td>    0.095</td> <td>    0.810</td> <td> 0.420</td> <td>   -0.112</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x580</th>  <td>    0.0157</td> <td>    0.094</td> <td>    0.167</td> <td> 0.867</td> <td>   -0.170</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x581</th>  <td>    0.0921</td> <td>    0.094</td> <td>    0.981</td> <td> 0.329</td> <td>   -0.094</td> <td>    0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x582</th>  <td>    0.0913</td> <td>    0.088</td> <td>    1.041</td> <td> 0.301</td> <td>   -0.083</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x583</th>  <td>    0.1262</td> <td>    0.092</td> <td>    1.368</td> <td> 0.174</td> <td>   -0.057</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x584</th>  <td>    0.1914</td> <td>    0.091</td> <td>    2.096</td> <td> 0.039</td> <td>    0.010</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x585</th>  <td>    0.0512</td> <td>    0.104</td> <td>    0.492</td> <td> 0.624</td> <td>   -0.155</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x586</th>  <td>   -0.1524</td> <td>    0.099</td> <td>   -1.534</td> <td> 0.128</td> <td>   -0.349</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x587</th>  <td>   -0.0095</td> <td>    0.103</td> <td>   -0.092</td> <td> 0.927</td> <td>   -0.215</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x588</th>  <td>    0.2141</td> <td>    0.094</td> <td>    2.287</td> <td> 0.024</td> <td>    0.028</td> <td>    0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x589</th>  <td>   -0.0398</td> <td>    0.101</td> <td>   -0.393</td> <td> 0.695</td> <td>   -0.241</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x590</th>  <td>    0.0090</td> <td>    0.091</td> <td>    0.098</td> <td> 0.922</td> <td>   -0.172</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x591</th>  <td>    0.0523</td> <td>    0.096</td> <td>    0.545</td> <td> 0.587</td> <td>   -0.138</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x592</th>  <td>    0.0905</td> <td>    0.109</td> <td>    0.829</td> <td> 0.409</td> <td>   -0.126</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x593</th>  <td>   -0.2845</td> <td>    0.103</td> <td>   -2.772</td> <td> 0.007</td> <td>   -0.488</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x594</th>  <td>    0.0927</td> <td>    0.106</td> <td>    0.873</td> <td> 0.385</td> <td>   -0.118</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x595</th>  <td>   -0.1795</td> <td>    0.106</td> <td>   -1.698</td> <td> 0.093</td> <td>   -0.389</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x596</th>  <td>   -0.1899</td> <td>    0.091</td> <td>   -2.092</td> <td> 0.039</td> <td>   -0.370</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x597</th>  <td>   -0.1125</td> <td>    0.097</td> <td>   -1.162</td> <td> 0.248</td> <td>   -0.305</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x598</th>  <td>    0.1216</td> <td>    0.097</td> <td>    1.251</td> <td> 0.214</td> <td>   -0.071</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x599</th>  <td>   -0.0677</td> <td>    0.093</td> <td>   -0.726</td> <td> 0.469</td> <td>   -0.253</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x600</th>  <td>   -0.2357</td> <td>    0.100</td> <td>   -2.354</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x601</th>  <td>   -0.1311</td> <td>    0.096</td> <td>   -1.372</td> <td> 0.173</td> <td>   -0.321</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x602</th>  <td>    0.0658</td> <td>    0.093</td> <td>    0.706</td> <td> 0.482</td> <td>   -0.119</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x603</th>  <td>    0.1706</td> <td>    0.103</td> <td>    1.663</td> <td> 0.099</td> <td>   -0.033</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x604</th>  <td>    0.1049</td> <td>    0.111</td> <td>    0.942</td> <td> 0.349</td> <td>   -0.116</td> <td>    0.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x605</th>  <td>    0.0382</td> <td>    0.092</td> <td>    0.414</td> <td> 0.680</td> <td>   -0.145</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x606</th>  <td>   -0.1086</td> <td>    0.101</td> <td>   -1.076</td> <td> 0.284</td> <td>   -0.309</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x607</th>  <td>    0.1947</td> <td>    0.116</td> <td>    1.681</td> <td> 0.096</td> <td>   -0.035</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x608</th>  <td>   -0.0038</td> <td>    0.091</td> <td>   -0.042</td> <td> 0.966</td> <td>   -0.184</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x609</th>  <td>   -0.0574</td> <td>    0.088</td> <td>   -0.653</td> <td> 0.515</td> <td>   -0.232</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x610</th>  <td>   -0.0103</td> <td>    0.087</td> <td>   -0.118</td> <td> 0.906</td> <td>   -0.183</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x611</th>  <td>    0.1057</td> <td>    0.103</td> <td>    1.031</td> <td> 0.305</td> <td>   -0.098</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x612</th>  <td>   -0.0351</td> <td>    0.094</td> <td>   -0.375</td> <td> 0.708</td> <td>   -0.221</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x613</th>  <td>   -0.0713</td> <td>    0.094</td> <td>   -0.761</td> <td> 0.448</td> <td>   -0.257</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x614</th>  <td>   -0.0664</td> <td>    0.106</td> <td>   -0.626</td> <td> 0.533</td> <td>   -0.277</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x615</th>  <td>    0.0150</td> <td>    0.101</td> <td>    0.148</td> <td> 0.883</td> <td>   -0.186</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x616</th>  <td>   -0.0790</td> <td>    0.099</td> <td>   -0.801</td> <td> 0.425</td> <td>   -0.275</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x617</th>  <td>   -0.0891</td> <td>    0.092</td> <td>   -0.969</td> <td> 0.335</td> <td>   -0.271</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x618</th>  <td>   -0.0395</td> <td>    0.102</td> <td>   -0.385</td> <td> 0.701</td> <td>   -0.243</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x619</th>  <td>   -0.1356</td> <td>    0.099</td> <td>   -1.372</td> <td> 0.173</td> <td>   -0.332</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x620</th>  <td>    0.0571</td> <td>    0.084</td> <td>    0.676</td> <td> 0.501</td> <td>   -0.110</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x621</th>  <td>    0.0721</td> <td>    0.089</td> <td>    0.809</td> <td> 0.421</td> <td>   -0.105</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x622</th>  <td>    0.1361</td> <td>    0.093</td> <td>    1.471</td> <td> 0.144</td> <td>   -0.047</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x623</th>  <td>   -0.0610</td> <td>    0.097</td> <td>   -0.626</td> <td> 0.533</td> <td>   -0.254</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x624</th>  <td>    0.2182</td> <td>    0.099</td> <td>    2.196</td> <td> 0.030</td> <td>    0.021</td> <td>    0.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x625</th>  <td>    0.0556</td> <td>    0.094</td> <td>    0.589</td> <td> 0.557</td> <td>   -0.132</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x626</th>  <td>    0.0097</td> <td>    0.110</td> <td>    0.088</td> <td> 0.930</td> <td>   -0.209</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x627</th>  <td>    0.0694</td> <td>    0.096</td> <td>    0.725</td> <td> 0.470</td> <td>   -0.121</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x628</th>  <td>    0.2932</td> <td>    0.104</td> <td>    2.814</td> <td> 0.006</td> <td>    0.086</td> <td>    0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x629</th>  <td>    0.0612</td> <td>    0.088</td> <td>    0.696</td> <td> 0.488</td> <td>   -0.113</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x630</th>  <td>   -0.2647</td> <td>    0.105</td> <td>   -2.517</td> <td> 0.013</td> <td>   -0.473</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x631</th>  <td>   -0.1924</td> <td>    0.088</td> <td>   -2.182</td> <td> 0.031</td> <td>   -0.367</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x632</th>  <td>   -0.0013</td> <td>    0.086</td> <td>   -0.016</td> <td> 0.988</td> <td>   -0.172</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x633</th>  <td>    0.1526</td> <td>    0.107</td> <td>    1.427</td> <td> 0.157</td> <td>   -0.060</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x634</th>  <td>    0.0590</td> <td>    0.088</td> <td>    0.671</td> <td> 0.504</td> <td>   -0.115</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x635</th>  <td>   -0.0367</td> <td>    0.094</td> <td>   -0.390</td> <td> 0.698</td> <td>   -0.224</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x636</th>  <td>    0.0274</td> <td>    0.092</td> <td>    0.298</td> <td> 0.766</td> <td>   -0.155</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x637</th>  <td>    0.0921</td> <td>    0.110</td> <td>    0.839</td> <td> 0.404</td> <td>   -0.126</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x638</th>  <td>   -0.0419</td> <td>    0.104</td> <td>   -0.403</td> <td> 0.688</td> <td>   -0.248</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x639</th>  <td>   -0.0647</td> <td>    0.089</td> <td>   -0.726</td> <td> 0.469</td> <td>   -0.241</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x640</th>  <td>   -0.1117</td> <td>    0.093</td> <td>   -1.198</td> <td> 0.234</td> <td>   -0.297</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x641</th>  <td>   -0.0469</td> <td>    0.088</td> <td>   -0.531</td> <td> 0.597</td> <td>   -0.222</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x642</th>  <td>    0.0150</td> <td>    0.092</td> <td>    0.163</td> <td> 0.871</td> <td>   -0.168</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x643</th>  <td>    0.0878</td> <td>    0.106</td> <td>    0.830</td> <td> 0.409</td> <td>   -0.122</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x644</th>  <td>   -0.1079</td> <td>    0.107</td> <td>   -1.008</td> <td> 0.316</td> <td>   -0.320</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x645</th>  <td>   -0.0690</td> <td>    0.093</td> <td>   -0.741</td> <td> 0.461</td> <td>   -0.254</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x646</th>  <td>    0.0003</td> <td>    0.090</td> <td>    0.003</td> <td> 0.997</td> <td>   -0.178</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x647</th>  <td>    0.0821</td> <td>    0.101</td> <td>    0.813</td> <td> 0.418</td> <td>   -0.118</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x648</th>  <td>   -0.1314</td> <td>    0.094</td> <td>   -1.391</td> <td> 0.167</td> <td>   -0.319</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x649</th>  <td>   -0.1670</td> <td>    0.092</td> <td>   -1.815</td> <td> 0.073</td> <td>   -0.350</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x650</th>  <td>   -0.1462</td> <td>    0.101</td> <td>   -1.453</td> <td> 0.149</td> <td>   -0.346</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x651</th>  <td>    0.0562</td> <td>    0.087</td> <td>    0.644</td> <td> 0.521</td> <td>   -0.117</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x652</th>  <td>   -0.0588</td> <td>    0.095</td> <td>   -0.617</td> <td> 0.538</td> <td>   -0.248</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x653</th>  <td>    0.0115</td> <td>    0.081</td> <td>    0.142</td> <td> 0.888</td> <td>   -0.150</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x654</th>  <td>    0.0042</td> <td>    0.088</td> <td>    0.047</td> <td> 0.963</td> <td>   -0.171</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x655</th>  <td>   -0.1081</td> <td>    0.079</td> <td>   -1.363</td> <td> 0.176</td> <td>   -0.266</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x656</th>  <td>   -0.0800</td> <td>    0.093</td> <td>   -0.865</td> <td> 0.389</td> <td>   -0.264</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x657</th>  <td>   -0.0472</td> <td>    0.109</td> <td>   -0.432</td> <td> 0.667</td> <td>   -0.264</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x658</th>  <td>   -0.0128</td> <td>    0.095</td> <td>   -0.135</td> <td> 0.893</td> <td>   -0.201</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x659</th>  <td>    0.0476</td> <td>    0.097</td> <td>    0.493</td> <td> 0.623</td> <td>   -0.144</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x660</th>  <td>    0.0153</td> <td>    0.100</td> <td>    0.154</td> <td> 0.878</td> <td>   -0.182</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x661</th>  <td>    0.0274</td> <td>    0.098</td> <td>    0.279</td> <td> 0.781</td> <td>   -0.168</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x662</th>  <td>   -0.0430</td> <td>    0.089</td> <td>   -0.481</td> <td> 0.631</td> <td>   -0.220</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x663</th>  <td>    0.0150</td> <td>    0.100</td> <td>    0.150</td> <td> 0.881</td> <td>   -0.183</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x664</th>  <td>   -0.0146</td> <td>    0.111</td> <td>   -0.132</td> <td> 0.896</td> <td>   -0.235</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x665</th>  <td>    0.0734</td> <td>    0.098</td> <td>    0.749</td> <td> 0.455</td> <td>   -0.121</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x666</th>  <td>   -0.0317</td> <td>    0.094</td> <td>   -0.336</td> <td> 0.738</td> <td>   -0.219</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x667</th>  <td>    0.1657</td> <td>    0.104</td> <td>    1.593</td> <td> 0.114</td> <td>   -0.041</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x668</th>  <td>    0.0434</td> <td>    0.090</td> <td>    0.481</td> <td> 0.631</td> <td>   -0.136</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x669</th>  <td>   -0.0014</td> <td>    0.100</td> <td>   -0.014</td> <td> 0.989</td> <td>   -0.200</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x670</th>  <td>   -0.0552</td> <td>    0.089</td> <td>   -0.618</td> <td> 0.538</td> <td>   -0.232</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x671</th>  <td>    0.1345</td> <td>    0.093</td> <td>    1.442</td> <td> 0.153</td> <td>   -0.051</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x672</th>  <td>    0.0426</td> <td>    0.089</td> <td>    0.479</td> <td> 0.633</td> <td>   -0.134</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x673</th>  <td>   -0.1002</td> <td>    0.100</td> <td>   -1.003</td> <td> 0.318</td> <td>   -0.298</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x674</th>  <td>   -0.1467</td> <td>    0.102</td> <td>   -1.434</td> <td> 0.155</td> <td>   -0.350</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x675</th>  <td>   -0.0831</td> <td>    0.102</td> <td>   -0.818</td> <td> 0.415</td> <td>   -0.285</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x676</th>  <td>    0.0686</td> <td>    0.092</td> <td>    0.747</td> <td> 0.457</td> <td>   -0.114</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x677</th>  <td>    0.0432</td> <td>    0.105</td> <td>    0.411</td> <td> 0.682</td> <td>   -0.165</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x678</th>  <td>   -0.0421</td> <td>    0.091</td> <td>   -0.465</td> <td> 0.643</td> <td>   -0.222</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x679</th>  <td>   -0.0209</td> <td>    0.105</td> <td>   -0.200</td> <td> 0.842</td> <td>   -0.229</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x680</th>  <td>    0.2189</td> <td>    0.086</td> <td>    2.554</td> <td> 0.012</td> <td>    0.049</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x681</th>  <td>    0.0100</td> <td>    0.082</td> <td>    0.122</td> <td> 0.903</td> <td>   -0.153</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x682</th>  <td>    0.1668</td> <td>    0.094</td> <td>    1.775</td> <td> 0.079</td> <td>   -0.020</td> <td>    0.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x683</th>  <td>    0.0351</td> <td>    0.095</td> <td>    0.371</td> <td> 0.711</td> <td>   -0.153</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x684</th>  <td>    0.0935</td> <td>    0.091</td> <td>    1.028</td> <td> 0.306</td> <td>   -0.087</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x685</th>  <td>    0.0230</td> <td>    0.086</td> <td>    0.268</td> <td> 0.789</td> <td>   -0.147</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x686</th>  <td>   -0.1384</td> <td>    0.093</td> <td>   -1.480</td> <td> 0.142</td> <td>   -0.324</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x687</th>  <td>    0.1165</td> <td>    0.093</td> <td>    1.251</td> <td> 0.214</td> <td>   -0.068</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x688</th>  <td>    0.1061</td> <td>    0.109</td> <td>    0.976</td> <td> 0.332</td> <td>   -0.110</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x689</th>  <td>    0.0976</td> <td>    0.093</td> <td>    1.048</td> <td> 0.297</td> <td>   -0.087</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x690</th>  <td>   -0.0700</td> <td>    0.100</td> <td>   -0.704</td> <td> 0.483</td> <td>   -0.268</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x691</th>  <td>    0.0451</td> <td>    0.098</td> <td>    0.460</td> <td> 0.647</td> <td>   -0.149</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x692</th>  <td>    0.0774</td> <td>    0.104</td> <td>    0.741</td> <td> 0.460</td> <td>   -0.130</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x693</th>  <td>    0.0532</td> <td>    0.105</td> <td>    0.508</td> <td> 0.613</td> <td>   -0.155</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x694</th>  <td>    0.0140</td> <td>    0.097</td> <td>    0.144</td> <td> 0.886</td> <td>   -0.179</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x695</th>  <td>    0.0227</td> <td>    0.100</td> <td>    0.226</td> <td> 0.821</td> <td>   -0.177</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x696</th>  <td>   -0.1453</td> <td>    0.107</td> <td>   -1.355</td> <td> 0.178</td> <td>   -0.358</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x697</th>  <td>    0.0925</td> <td>    0.095</td> <td>    0.974</td> <td> 0.333</td> <td>   -0.096</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x698</th>  <td>   -0.0542</td> <td>    0.092</td> <td>   -0.590</td> <td> 0.556</td> <td>   -0.236</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x699</th>  <td>    0.0079</td> <td>    0.112</td> <td>    0.070</td> <td> 0.944</td> <td>   -0.214</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x700</th>  <td>   -0.0023</td> <td>    0.089</td> <td>   -0.026</td> <td> 0.979</td> <td>   -0.179</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x701</th>  <td>   -0.1276</td> <td>    0.091</td> <td>   -1.403</td> <td> 0.164</td> <td>   -0.308</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x702</th>  <td>   -0.1266</td> <td>    0.098</td> <td>   -1.286</td> <td> 0.202</td> <td>   -0.322</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x703</th>  <td>   -0.0085</td> <td>    0.097</td> <td>   -0.088</td> <td> 0.930</td> <td>   -0.201</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x704</th>  <td>    0.0095</td> <td>    0.101</td> <td>    0.094</td> <td> 0.925</td> <td>   -0.191</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x705</th>  <td>   -0.0976</td> <td>    0.093</td> <td>   -1.051</td> <td> 0.296</td> <td>   -0.282</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x706</th>  <td>    0.0361</td> <td>    0.098</td> <td>    0.368</td> <td> 0.713</td> <td>   -0.158</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x707</th>  <td>    0.0465</td> <td>    0.095</td> <td>    0.488</td> <td> 0.627</td> <td>   -0.143</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x708</th>  <td>    0.0039</td> <td>    0.094</td> <td>    0.042</td> <td> 0.967</td> <td>   -0.183</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x709</th>  <td>    0.1457</td> <td>    0.085</td> <td>    1.723</td> <td> 0.088</td> <td>   -0.022</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x710</th>  <td>   -0.0188</td> <td>    0.097</td> <td>   -0.195</td> <td> 0.846</td> <td>   -0.211</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x711</th>  <td>    0.1378</td> <td>    0.115</td> <td>    1.196</td> <td> 0.234</td> <td>   -0.091</td> <td>    0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x712</th>  <td>   -0.0785</td> <td>    0.097</td> <td>   -0.810</td> <td> 0.420</td> <td>   -0.271</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x713</th>  <td>   -0.1894</td> <td>    0.099</td> <td>   -1.913</td> <td> 0.059</td> <td>   -0.386</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x714</th>  <td>    0.0481</td> <td>    0.105</td> <td>    0.457</td> <td> 0.649</td> <td>   -0.161</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x715</th>  <td>   -0.1206</td> <td>    0.094</td> <td>   -1.282</td> <td> 0.203</td> <td>   -0.307</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x716</th>  <td>   -0.0205</td> <td>    0.092</td> <td>   -0.223</td> <td> 0.824</td> <td>   -0.203</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x717</th>  <td>   -0.1686</td> <td>    0.102</td> <td>   -1.654</td> <td> 0.101</td> <td>   -0.371</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x718</th>  <td>   -0.0115</td> <td>    0.090</td> <td>   -0.128</td> <td> 0.898</td> <td>   -0.190</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x719</th>  <td>    0.1099</td> <td>    0.103</td> <td>    1.065</td> <td> 0.290</td> <td>   -0.095</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x720</th>  <td>    0.0328</td> <td>    0.097</td> <td>    0.339</td> <td> 0.735</td> <td>   -0.159</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x721</th>  <td>   -0.1353</td> <td>    0.101</td> <td>   -1.339</td> <td> 0.184</td> <td>   -0.336</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x722</th>  <td>   -0.0409</td> <td>    0.096</td> <td>   -0.425</td> <td> 0.672</td> <td>   -0.232</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x723</th>  <td>    0.2041</td> <td>    0.088</td> <td>    2.316</td> <td> 0.023</td> <td>    0.029</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x724</th>  <td>   -0.0001</td> <td>    0.090</td> <td>   -0.002</td> <td> 0.999</td> <td>   -0.178</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x725</th>  <td>    0.0908</td> <td>    0.103</td> <td>    0.880</td> <td> 0.381</td> <td>   -0.114</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x726</th>  <td>   -0.0990</td> <td>    0.098</td> <td>   -1.011</td> <td> 0.314</td> <td>   -0.293</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x727</th>  <td>   -0.1107</td> <td>    0.102</td> <td>   -1.081</td> <td> 0.282</td> <td>   -0.314</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x728</th>  <td>    0.1882</td> <td>    0.096</td> <td>    1.959</td> <td> 0.053</td> <td>   -0.002</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x729</th>  <td>    0.0570</td> <td>    0.106</td> <td>    0.540</td> <td> 0.590</td> <td>   -0.153</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x730</th>  <td>   -0.0466</td> <td>    0.096</td> <td>   -0.487</td> <td> 0.628</td> <td>   -0.237</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x731</th>  <td>    0.1224</td> <td>    0.098</td> <td>    1.247</td> <td> 0.215</td> <td>   -0.072</td> <td>    0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x732</th>  <td>   -0.1166</td> <td>    0.091</td> <td>   -1.282</td> <td> 0.203</td> <td>   -0.297</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x733</th>  <td>    0.1651</td> <td>    0.094</td> <td>    1.748</td> <td> 0.084</td> <td>   -0.022</td> <td>    0.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x734</th>  <td>    0.0208</td> <td>    0.098</td> <td>    0.212</td> <td> 0.833</td> <td>   -0.174</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x735</th>  <td>   -0.0532</td> <td>    0.104</td> <td>   -0.510</td> <td> 0.611</td> <td>   -0.260</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x736</th>  <td>    0.1062</td> <td>    0.091</td> <td>    1.171</td> <td> 0.244</td> <td>   -0.074</td> <td>    0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x737</th>  <td>   -0.1480</td> <td>    0.100</td> <td>   -1.482</td> <td> 0.142</td> <td>   -0.346</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x738</th>  <td>   -0.0059</td> <td>    0.101</td> <td>   -0.059</td> <td> 0.953</td> <td>   -0.206</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x739</th>  <td>    0.1053</td> <td>    0.111</td> <td>    0.947</td> <td> 0.346</td> <td>   -0.115</td> <td>    0.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x740</th>  <td>   -0.0694</td> <td>    0.101</td> <td>   -0.686</td> <td> 0.494</td> <td>   -0.270</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x741</th>  <td>    0.1218</td> <td>    0.094</td> <td>    1.298</td> <td> 0.197</td> <td>   -0.064</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x742</th>  <td>    0.1819</td> <td>    0.097</td> <td>    1.878</td> <td> 0.063</td> <td>   -0.010</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x743</th>  <td>   -0.0099</td> <td>    0.093</td> <td>   -0.106</td> <td> 0.916</td> <td>   -0.195</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x744</th>  <td>   -0.0136</td> <td>    0.096</td> <td>   -0.142</td> <td> 0.887</td> <td>   -0.204</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x745</th>  <td>   -0.0269</td> <td>    0.083</td> <td>   -0.326</td> <td> 0.745</td> <td>   -0.191</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x746</th>  <td>   -0.0028</td> <td>    0.100</td> <td>   -0.028</td> <td> 0.978</td> <td>   -0.202</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x747</th>  <td>    0.0538</td> <td>    0.098</td> <td>    0.551</td> <td> 0.583</td> <td>   -0.140</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x748</th>  <td>   -0.0524</td> <td>    0.102</td> <td>   -0.515</td> <td> 0.608</td> <td>   -0.254</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x749</th>  <td>   -0.1446</td> <td>    0.092</td> <td>   -1.567</td> <td> 0.120</td> <td>   -0.328</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x750</th>  <td>    0.1018</td> <td>    0.093</td> <td>    1.097</td> <td> 0.275</td> <td>   -0.082</td> <td>    0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x751</th>  <td>   -0.1548</td> <td>    0.104</td> <td>   -1.492</td> <td> 0.139</td> <td>   -0.361</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x752</th>  <td>    0.0150</td> <td>    0.109</td> <td>    0.138</td> <td> 0.890</td> <td>   -0.201</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x753</th>  <td>   -0.1256</td> <td>    0.092</td> <td>   -1.365</td> <td> 0.175</td> <td>   -0.308</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x754</th>  <td>    0.0013</td> <td>    0.107</td> <td>    0.012</td> <td> 0.990</td> <td>   -0.212</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x755</th>  <td>   -0.0023</td> <td>    0.089</td> <td>   -0.026</td> <td> 0.979</td> <td>   -0.180</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x756</th>  <td>   -0.0171</td> <td>    0.089</td> <td>   -0.192</td> <td> 0.848</td> <td>   -0.193</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x757</th>  <td>-7.481e-05</td> <td>    0.092</td> <td>   -0.001</td> <td> 0.999</td> <td>   -0.182</td> <td>    0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x758</th>  <td>   -0.1076</td> <td>    0.082</td> <td>   -1.310</td> <td> 0.193</td> <td>   -0.270</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x759</th>  <td>    0.3098</td> <td>    0.096</td> <td>    3.220</td> <td> 0.002</td> <td>    0.119</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x760</th>  <td>    0.1370</td> <td>    0.091</td> <td>    1.505</td> <td> 0.135</td> <td>   -0.044</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x761</th>  <td>   -0.1119</td> <td>    0.091</td> <td>   -1.228</td> <td> 0.222</td> <td>   -0.293</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x762</th>  <td>   -0.0823</td> <td>    0.104</td> <td>   -0.793</td> <td> 0.430</td> <td>   -0.288</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x763</th>  <td>   -0.2148</td> <td>    0.108</td> <td>   -1.984</td> <td> 0.050</td> <td>   -0.430</td> <td> 6.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x764</th>  <td>    0.2981</td> <td>    0.118</td> <td>    2.525</td> <td> 0.013</td> <td>    0.064</td> <td>    0.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x765</th>  <td>    0.1548</td> <td>    0.099</td> <td>    1.563</td> <td> 0.121</td> <td>   -0.042</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x766</th>  <td>    0.0173</td> <td>    0.098</td> <td>    0.177</td> <td> 0.860</td> <td>   -0.177</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x767</th>  <td>    0.1258</td> <td>    0.102</td> <td>    1.239</td> <td> 0.218</td> <td>   -0.076</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x768</th>  <td>   -0.0273</td> <td>    0.093</td> <td>   -0.294</td> <td> 0.769</td> <td>   -0.211</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x769</th>  <td>   -0.1941</td> <td>    0.103</td> <td>   -1.879</td> <td> 0.063</td> <td>   -0.399</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x770</th>  <td>   -0.0685</td> <td>    0.092</td> <td>   -0.747</td> <td> 0.457</td> <td>   -0.250</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x771</th>  <td>    0.0228</td> <td>    0.075</td> <td>    0.303</td> <td> 0.762</td> <td>   -0.126</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x772</th>  <td>   -0.1868</td> <td>    0.100</td> <td>   -1.864</td> <td> 0.065</td> <td>   -0.386</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x773</th>  <td>    0.0632</td> <td>    0.099</td> <td>    0.636</td> <td> 0.526</td> <td>   -0.134</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x774</th>  <td>    0.0774</td> <td>    0.086</td> <td>    0.901</td> <td> 0.370</td> <td>   -0.093</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x775</th>  <td>   -0.0447</td> <td>    0.090</td> <td>   -0.498</td> <td> 0.620</td> <td>   -0.223</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x776</th>  <td>   -0.1334</td> <td>    0.091</td> <td>   -1.471</td> <td> 0.145</td> <td>   -0.313</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x777</th>  <td>   -0.0079</td> <td>    0.099</td> <td>   -0.080</td> <td> 0.936</td> <td>   -0.204</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x778</th>  <td>    0.0401</td> <td>    0.095</td> <td>    0.423</td> <td> 0.673</td> <td>   -0.148</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x779</th>  <td>    0.0948</td> <td>    0.095</td> <td>    0.999</td> <td> 0.320</td> <td>   -0.094</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x780</th>  <td>    0.0042</td> <td>    0.086</td> <td>    0.049</td> <td> 0.961</td> <td>   -0.166</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x781</th>  <td>    0.1698</td> <td>    0.093</td> <td>    1.834</td> <td> 0.070</td> <td>   -0.014</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x782</th>  <td>    0.0995</td> <td>    0.094</td> <td>    1.063</td> <td> 0.291</td> <td>   -0.086</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x783</th>  <td>    0.0377</td> <td>    0.106</td> <td>    0.355</td> <td> 0.723</td> <td>   -0.173</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x784</th>  <td>    0.1086</td> <td>    0.107</td> <td>    1.018</td> <td> 0.311</td> <td>   -0.103</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x785</th>  <td>    0.1492</td> <td>    0.099</td> <td>    1.507</td> <td> 0.135</td> <td>   -0.047</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x786</th>  <td>   -0.0329</td> <td>    0.086</td> <td>   -0.385</td> <td> 0.701</td> <td>   -0.203</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x787</th>  <td>    0.0976</td> <td>    0.096</td> <td>    1.017</td> <td> 0.312</td> <td>   -0.093</td> <td>    0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x788</th>  <td>    0.1266</td> <td>    0.096</td> <td>    1.320</td> <td> 0.190</td> <td>   -0.064</td> <td>    0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x789</th>  <td>    0.0481</td> <td>    0.089</td> <td>    0.543</td> <td> 0.589</td> <td>   -0.128</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x790</th>  <td>    0.2014</td> <td>    0.096</td> <td>    2.088</td> <td> 0.039</td> <td>    0.010</td> <td>    0.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x791</th>  <td>    0.1015</td> <td>    0.103</td> <td>    0.989</td> <td> 0.325</td> <td>   -0.102</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x792</th>  <td>   -0.1390</td> <td>    0.095</td> <td>   -1.460</td> <td> 0.148</td> <td>   -0.328</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x793</th>  <td>   -0.0150</td> <td>    0.086</td> <td>   -0.175</td> <td> 0.862</td> <td>   -0.185</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x794</th>  <td>   -0.0772</td> <td>    0.092</td> <td>   -0.840</td> <td> 0.403</td> <td>   -0.260</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x795</th>  <td>   -0.1152</td> <td>    0.104</td> <td>   -1.106</td> <td> 0.271</td> <td>   -0.322</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x796</th>  <td>    0.0383</td> <td>    0.104</td> <td>    0.367</td> <td> 0.714</td> <td>   -0.169</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x797</th>  <td>   -0.1142</td> <td>    0.095</td> <td>   -1.203</td> <td> 0.232</td> <td>   -0.303</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x798</th>  <td>    0.0414</td> <td>    0.086</td> <td>    0.483</td> <td> 0.630</td> <td>   -0.129</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x799</th>  <td>    0.0199</td> <td>    0.094</td> <td>    0.212</td> <td> 0.833</td> <td>   -0.166</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x800</th>  <td>   -0.1120</td> <td>    0.090</td> <td>   -1.250</td> <td> 0.214</td> <td>   -0.290</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x801</th>  <td>   -0.1437</td> <td>    0.097</td> <td>   -1.476</td> <td> 0.143</td> <td>   -0.337</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x802</th>  <td>    0.0449</td> <td>    0.087</td> <td>    0.515</td> <td> 0.608</td> <td>   -0.128</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x803</th>  <td>   -0.1140</td> <td>    0.094</td> <td>   -1.209</td> <td> 0.229</td> <td>   -0.301</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x804</th>  <td>   -0.0473</td> <td>    0.096</td> <td>   -0.491</td> <td> 0.624</td> <td>   -0.238</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x805</th>  <td>   -0.0453</td> <td>    0.103</td> <td>   -0.440</td> <td> 0.661</td> <td>   -0.249</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x806</th>  <td>   -0.0876</td> <td>    0.090</td> <td>   -0.970</td> <td> 0.334</td> <td>   -0.267</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x807</th>  <td>   -0.0086</td> <td>    0.092</td> <td>   -0.093</td> <td> 0.926</td> <td>   -0.192</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x808</th>  <td>    0.0618</td> <td>    0.094</td> <td>    0.659</td> <td> 0.512</td> <td>   -0.124</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x809</th>  <td>    0.0244</td> <td>    0.101</td> <td>    0.242</td> <td> 0.809</td> <td>   -0.175</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x810</th>  <td>   -0.1666</td> <td>    0.093</td> <td>   -1.801</td> <td> 0.075</td> <td>   -0.350</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x811</th>  <td>   -0.1080</td> <td>    0.099</td> <td>   -1.094</td> <td> 0.277</td> <td>   -0.304</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x812</th>  <td>   -0.0944</td> <td>    0.105</td> <td>   -0.895</td> <td> 0.373</td> <td>   -0.304</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x813</th>  <td>   -0.0607</td> <td>    0.088</td> <td>   -0.687</td> <td> 0.494</td> <td>   -0.236</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x814</th>  <td>    0.0012</td> <td>    0.106</td> <td>    0.011</td> <td> 0.991</td> <td>   -0.209</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x815</th>  <td>    0.1062</td> <td>    0.117</td> <td>    0.910</td> <td> 0.365</td> <td>   -0.125</td> <td>    0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x816</th>  <td>    0.0348</td> <td>    0.098</td> <td>    0.353</td> <td> 0.724</td> <td>   -0.161</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x817</th>  <td>   -0.0486</td> <td>    0.095</td> <td>   -0.509</td> <td> 0.612</td> <td>   -0.238</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x818</th>  <td>    0.0120</td> <td>    0.105</td> <td>    0.115</td> <td> 0.909</td> <td>   -0.196</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x819</th>  <td>    0.0937</td> <td>    0.094</td> <td>    0.995</td> <td> 0.322</td> <td>   -0.093</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x820</th>  <td>   -0.0093</td> <td>    0.105</td> <td>   -0.088</td> <td> 0.930</td> <td>   -0.218</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x821</th>  <td>    0.1028</td> <td>    0.091</td> <td>    1.133</td> <td> 0.260</td> <td>   -0.077</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x822</th>  <td>    0.0507</td> <td>    0.105</td> <td>    0.483</td> <td> 0.630</td> <td>   -0.158</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x823</th>  <td>    0.0586</td> <td>    0.085</td> <td>    0.686</td> <td> 0.494</td> <td>   -0.111</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x824</th>  <td>    0.0817</td> <td>    0.096</td> <td>    0.851</td> <td> 0.397</td> <td>   -0.109</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x825</th>  <td>   -0.0786</td> <td>    0.097</td> <td>   -0.809</td> <td> 0.420</td> <td>   -0.271</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x826</th>  <td>   -0.0036</td> <td>    0.097</td> <td>   -0.037</td> <td> 0.970</td> <td>   -0.195</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x827</th>  <td>    0.0773</td> <td>    0.088</td> <td>    0.879</td> <td> 0.382</td> <td>   -0.097</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x828</th>  <td>   -0.1818</td> <td>    0.089</td> <td>   -2.054</td> <td> 0.043</td> <td>   -0.357</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x829</th>  <td>   -0.0755</td> <td>    0.088</td> <td>   -0.856</td> <td> 0.394</td> <td>   -0.251</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x830</th>  <td>    0.0312</td> <td>    0.084</td> <td>    0.372</td> <td> 0.711</td> <td>   -0.135</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x831</th>  <td>   -0.0341</td> <td>    0.103</td> <td>   -0.330</td> <td> 0.742</td> <td>   -0.239</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x832</th>  <td>    0.1999</td> <td>    0.113</td> <td>    1.765</td> <td> 0.081</td> <td>   -0.025</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x833</th>  <td>   -0.0139</td> <td>    0.093</td> <td>   -0.149</td> <td> 0.882</td> <td>   -0.199</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x834</th>  <td>    0.1078</td> <td>    0.106</td> <td>    1.014</td> <td> 0.313</td> <td>   -0.103</td> <td>    0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x835</th>  <td>    0.0475</td> <td>    0.096</td> <td>    0.496</td> <td> 0.621</td> <td>   -0.142</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x836</th>  <td>    0.1624</td> <td>    0.101</td> <td>    1.614</td> <td> 0.110</td> <td>   -0.037</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x837</th>  <td>    0.1401</td> <td>    0.092</td> <td>    1.520</td> <td> 0.132</td> <td>   -0.043</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x838</th>  <td>    0.0264</td> <td>    0.098</td> <td>    0.269</td> <td> 0.789</td> <td>   -0.168</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x839</th>  <td>   -0.0576</td> <td>    0.110</td> <td>   -0.525</td> <td> 0.601</td> <td>   -0.275</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x840</th>  <td>    0.1127</td> <td>    0.089</td> <td>    1.264</td> <td> 0.209</td> <td>   -0.064</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x841</th>  <td>   -0.1813</td> <td>    0.104</td> <td>   -1.737</td> <td> 0.086</td> <td>   -0.388</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x842</th>  <td>   -0.0268</td> <td>    0.098</td> <td>   -0.274</td> <td> 0.785</td> <td>   -0.221</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x843</th>  <td>    0.0769</td> <td>    0.089</td> <td>    0.865</td> <td> 0.389</td> <td>   -0.099</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x844</th>  <td>   -0.1635</td> <td>    0.097</td> <td>   -1.678</td> <td> 0.097</td> <td>   -0.357</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x845</th>  <td>   -0.0319</td> <td>    0.099</td> <td>   -0.324</td> <td> 0.747</td> <td>   -0.228</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x846</th>  <td>    0.0618</td> <td>    0.094</td> <td>    0.659</td> <td> 0.511</td> <td>   -0.124</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x847</th>  <td>    0.2039</td> <td>    0.097</td> <td>    2.091</td> <td> 0.039</td> <td>    0.010</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x848</th>  <td>    0.1858</td> <td>    0.094</td> <td>    1.975</td> <td> 0.051</td> <td>   -0.001</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x849</th>  <td>   -0.1376</td> <td>    0.105</td> <td>   -1.309</td> <td> 0.193</td> <td>   -0.346</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x850</th>  <td>    0.0151</td> <td>    0.106</td> <td>    0.142</td> <td> 0.887</td> <td>   -0.195</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x851</th>  <td>   -0.3684</td> <td>    0.097</td> <td>   -3.785</td> <td> 0.000</td> <td>   -0.562</td> <td>   -0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x852</th>  <td>   -0.0086</td> <td>    0.092</td> <td>   -0.094</td> <td> 0.925</td> <td>   -0.190</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x853</th>  <td>    0.0020</td> <td>    0.094</td> <td>    0.021</td> <td> 0.983</td> <td>   -0.185</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x854</th>  <td>   -0.0269</td> <td>    0.103</td> <td>   -0.261</td> <td> 0.795</td> <td>   -0.232</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x855</th>  <td>   -0.0435</td> <td>    0.082</td> <td>   -0.528</td> <td> 0.598</td> <td>   -0.207</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x856</th>  <td>    0.0576</td> <td>    0.098</td> <td>    0.586</td> <td> 0.559</td> <td>   -0.137</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x857</th>  <td>    0.0093</td> <td>    0.100</td> <td>    0.093</td> <td> 0.926</td> <td>   -0.189</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x858</th>  <td>    0.1357</td> <td>    0.085</td> <td>    1.601</td> <td> 0.113</td> <td>   -0.033</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x859</th>  <td>   -0.0513</td> <td>    0.088</td> <td>   -0.586</td> <td> 0.559</td> <td>   -0.225</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x860</th>  <td>   -0.0874</td> <td>    0.090</td> <td>   -0.975</td> <td> 0.332</td> <td>   -0.265</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x861</th>  <td>    0.2403</td> <td>    0.088</td> <td>    2.726</td> <td> 0.008</td> <td>    0.065</td> <td>    0.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x862</th>  <td>   -0.1982</td> <td>    0.086</td> <td>   -2.297</td> <td> 0.024</td> <td>   -0.369</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x863</th>  <td>   -0.1587</td> <td>    0.105</td> <td>   -1.517</td> <td> 0.132</td> <td>   -0.366</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x864</th>  <td>    0.0047</td> <td>    0.089</td> <td>    0.054</td> <td> 0.957</td> <td>   -0.171</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x865</th>  <td>   -0.0858</td> <td>    0.102</td> <td>   -0.844</td> <td> 0.401</td> <td>   -0.288</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x866</th>  <td>   -0.0900</td> <td>    0.093</td> <td>   -0.967</td> <td> 0.336</td> <td>   -0.275</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x867</th>  <td>    0.2366</td> <td>    0.108</td> <td>    2.185</td> <td> 0.031</td> <td>    0.022</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x868</th>  <td>    0.1702</td> <td>    0.097</td> <td>    1.746</td> <td> 0.084</td> <td>   -0.023</td> <td>    0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x869</th>  <td>    0.1215</td> <td>    0.101</td> <td>    1.197</td> <td> 0.234</td> <td>   -0.080</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x870</th>  <td>    0.1027</td> <td>    0.094</td> <td>    1.093</td> <td> 0.277</td> <td>   -0.084</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x871</th>  <td>   -0.0438</td> <td>    0.097</td> <td>   -0.451</td> <td> 0.653</td> <td>   -0.237</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x872</th>  <td>   -0.0659</td> <td>    0.099</td> <td>   -0.667</td> <td> 0.506</td> <td>   -0.262</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x873</th>  <td>    0.1358</td> <td>    0.104</td> <td>    1.311</td> <td> 0.193</td> <td>   -0.070</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x874</th>  <td>   -0.0918</td> <td>    0.099</td> <td>   -0.925</td> <td> 0.357</td> <td>   -0.289</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x875</th>  <td>   -0.0199</td> <td>    0.091</td> <td>   -0.218</td> <td> 0.828</td> <td>   -0.201</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x876</th>  <td>    0.0080</td> <td>    0.097</td> <td>    0.082</td> <td> 0.935</td> <td>   -0.185</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x877</th>  <td>    0.1482</td> <td>    0.100</td> <td>    1.475</td> <td> 0.143</td> <td>   -0.051</td> <td>    0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x878</th>  <td>   -0.0637</td> <td>    0.089</td> <td>   -0.719</td> <td> 0.474</td> <td>   -0.240</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x879</th>  <td>   -0.0786</td> <td>    0.105</td> <td>   -0.745</td> <td> 0.458</td> <td>   -0.288</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x880</th>  <td>   -0.0327</td> <td>    0.109</td> <td>   -0.301</td> <td> 0.764</td> <td>   -0.248</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x881</th>  <td>    0.1002</td> <td>    0.100</td> <td>    0.998</td> <td> 0.321</td> <td>   -0.099</td> <td>    0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x882</th>  <td>    0.1198</td> <td>    0.090</td> <td>    1.325</td> <td> 0.188</td> <td>   -0.060</td> <td>    0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x883</th>  <td>   -0.1121</td> <td>    0.094</td> <td>   -1.190</td> <td> 0.237</td> <td>   -0.299</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x884</th>  <td>    0.0974</td> <td>    0.084</td> <td>    1.154</td> <td> 0.251</td> <td>   -0.070</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x885</th>  <td>   -0.0237</td> <td>    0.089</td> <td>   -0.266</td> <td> 0.791</td> <td>   -0.201</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x886</th>  <td>    0.0121</td> <td>    0.104</td> <td>    0.116</td> <td> 0.908</td> <td>   -0.195</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x887</th>  <td>    0.0511</td> <td>    0.102</td> <td>    0.500</td> <td> 0.618</td> <td>   -0.152</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x888</th>  <td>   -0.0946</td> <td>    0.085</td> <td>   -1.109</td> <td> 0.270</td> <td>   -0.264</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x889</th>  <td>   -0.1491</td> <td>    0.098</td> <td>   -1.525</td> <td> 0.130</td> <td>   -0.343</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x890</th>  <td>    0.0251</td> <td>    0.099</td> <td>    0.253</td> <td> 0.801</td> <td>   -0.172</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x891</th>  <td>    0.0160</td> <td>    0.094</td> <td>    0.170</td> <td> 0.865</td> <td>   -0.171</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x892</th>  <td>    0.2295</td> <td>    0.104</td> <td>    2.216</td> <td> 0.029</td> <td>    0.024</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x893</th>  <td>   -0.1777</td> <td>    0.094</td> <td>   -1.889</td> <td> 0.062</td> <td>   -0.364</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x894</th>  <td>    0.1173</td> <td>    0.088</td> <td>    1.339</td> <td> 0.184</td> <td>   -0.057</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x895</th>  <td>    0.1574</td> <td>    0.100</td> <td>    1.581</td> <td> 0.117</td> <td>   -0.040</td> <td>    0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x896</th>  <td>   -0.0228</td> <td>    0.088</td> <td>   -0.259</td> <td> 0.796</td> <td>   -0.198</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x897</th>  <td>    0.1480</td> <td>    0.098</td> <td>    1.510</td> <td> 0.134</td> <td>   -0.047</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x898</th>  <td>   -0.1257</td> <td>    0.095</td> <td>   -1.322</td> <td> 0.189</td> <td>   -0.314</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x899</th>  <td>   -0.0872</td> <td>    0.086</td> <td>   -1.012</td> <td> 0.314</td> <td>   -0.258</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x900</th>  <td>    0.0684</td> <td>    0.112</td> <td>    0.613</td> <td> 0.542</td> <td>   -0.153</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x901</th>  <td>   -0.0006</td> <td>    0.104</td> <td>   -0.005</td> <td> 0.996</td> <td>   -0.208</td> <td>    0.207</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.158</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.125</td> <th>  Jarque-Bera (JB):  </th> <td>   4.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.062</td> <th>  Prob(JB):          </th> <td>  0.0986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.309</td> <th>  Cond. No.          </th> <td>    36.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.933\n",
       "Model:                            OLS   Adj. R-squared:                  0.320\n",
       "Method:                 Least Squares   F-statistic:                     1.522\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):            0.00469\n",
       "Time:                        19:26:57   Log-Likelihood:                -210.59\n",
       "No. Observations:                1000   AIC:                             2225.\n",
       "Df Residuals:                      98   BIC:                             6652.\n",
       "Df Model:                         901                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0689      0.093      0.737      0.463      -0.117       0.254\n",
       "x1             0.6518      0.098      6.671      0.000       0.458       0.846\n",
       "x2            -0.1241      0.095     -1.306      0.195      -0.313       0.064\n",
       "x3             0.1608      0.108      1.487      0.140      -0.054       0.375\n",
       "x4            -0.0449      0.086     -0.525      0.601      -0.215       0.125\n",
       "x5             0.1317      0.084      1.565      0.121      -0.035       0.299\n",
       "x6            -0.1142      0.096     -1.191      0.237      -0.304       0.076\n",
       "x7             0.3082      0.125      2.458      0.016       0.059       0.557\n",
       "x8             0.0619      0.086      0.722      0.472      -0.108       0.232\n",
       "x9            -0.0602      0.092     -0.657      0.513      -0.242       0.122\n",
       "x10           -0.0581      0.101     -0.574      0.567      -0.259       0.143\n",
       "x11            0.0078      0.099      0.079      0.937      -0.188       0.204\n",
       "x12           -0.0682      0.095     -0.717      0.475      -0.257       0.121\n",
       "x13           -0.1603      0.097     -1.651      0.102      -0.353       0.032\n",
       "x14            0.0697      0.107      0.649      0.518      -0.144       0.283\n",
       "x15           -0.2320      0.108     -2.155      0.034      -0.446      -0.018\n",
       "x16           -0.0905      0.100     -0.907      0.367      -0.289       0.108\n",
       "x17           -0.1728      0.096     -1.804      0.074      -0.363       0.017\n",
       "x18            0.0597      0.091      0.654      0.514      -0.121       0.241\n",
       "x19           -0.0616      0.103     -0.599      0.550      -0.265       0.142\n",
       "x20           -0.0747      0.097     -0.773      0.441      -0.267       0.117\n",
       "x21            0.1111      0.110      1.006      0.317      -0.108       0.330\n",
       "x22            0.1132      0.091      1.247      0.215      -0.067       0.293\n",
       "x23           -0.1014      0.098     -1.031      0.305      -0.296       0.094\n",
       "x24           -0.0118      0.103     -0.115      0.909      -0.217       0.193\n",
       "x25           -0.1430      0.101     -1.417      0.160      -0.343       0.057\n",
       "x26            0.1758      0.099      1.769      0.080      -0.021       0.373\n",
       "x27            0.0374      0.102      0.365      0.716      -0.166       0.241\n",
       "x28           -0.1522      0.096     -1.582      0.117      -0.343       0.039\n",
       "x29            0.0639      0.089      0.722      0.472      -0.112       0.240\n",
       "x30            0.1140      0.094      1.212      0.228      -0.073       0.301\n",
       "x31           -0.0099      0.094     -0.106      0.916      -0.197       0.177\n",
       "x32            0.1487      0.095      1.566      0.121      -0.040       0.337\n",
       "x33           -0.0387      0.094     -0.411      0.682      -0.226       0.148\n",
       "x34            0.0227      0.095      0.239      0.811      -0.165       0.211\n",
       "x35            0.0347      0.086      0.402      0.688      -0.137       0.206\n",
       "x36           -0.0587      0.101     -0.579      0.564      -0.260       0.143\n",
       "x37           -0.0511      0.099     -0.515      0.608      -0.248       0.146\n",
       "x38           -0.1198      0.097     -1.237      0.219      -0.312       0.072\n",
       "x39           -0.0934      0.108     -0.863      0.390      -0.308       0.121\n",
       "x40            0.0716      0.096      0.743      0.459      -0.119       0.263\n",
       "x41            0.2645      0.110      2.395      0.018       0.045       0.484\n",
       "x42            0.0013      0.091      0.015      0.988      -0.179       0.181\n",
       "x43            0.0325      0.094      0.346      0.730      -0.154       0.219\n",
       "x44           -0.0747      0.097     -0.770      0.443      -0.267       0.118\n",
       "x45           -0.0946      0.100     -0.943      0.348      -0.294       0.104\n",
       "x46            0.0331      0.104      0.320      0.750      -0.172       0.239\n",
       "x47           -0.0234      0.104     -0.224      0.823      -0.231       0.184\n",
       "x48           -0.1362      0.098     -1.396      0.166      -0.330       0.057\n",
       "x49            0.0205      0.096      0.214      0.831      -0.170       0.211\n",
       "x50            0.1232      0.089      1.377      0.172      -0.054       0.301\n",
       "x51            0.0174      0.099      0.176      0.861      -0.179       0.213\n",
       "x52           -0.0316      0.093     -0.340      0.734      -0.216       0.153\n",
       "x53            0.0154      0.092      0.167      0.868      -0.168       0.199\n",
       "x54           -0.0972      0.092     -1.057      0.293      -0.280       0.085\n",
       "x55           -0.1017      0.093     -1.097      0.275      -0.285       0.082\n",
       "x56           -0.0360      0.107     -0.337      0.737      -0.248       0.176\n",
       "x57            0.0424      0.093      0.454      0.651      -0.143       0.228\n",
       "x58           -0.1929      0.085     -2.259      0.026      -0.362      -0.023\n",
       "x59           -0.1194      0.094     -1.275      0.205      -0.305       0.066\n",
       "x60           -0.1468      0.115     -1.271      0.207      -0.376       0.082\n",
       "x61            0.2386      0.102      2.347      0.021       0.037       0.440\n",
       "x62           -0.0960      0.088     -1.091      0.278      -0.271       0.079\n",
       "x63           -0.0274      0.091     -0.300      0.764      -0.208       0.154\n",
       "x64            0.0741      0.090      0.822      0.413      -0.105       0.253\n",
       "x65           -0.1528      0.102     -1.493      0.139      -0.356       0.050\n",
       "x66           -0.1495      0.099     -1.507      0.135      -0.346       0.047\n",
       "x67           -0.1483      0.110     -1.348      0.181      -0.367       0.070\n",
       "x68           -0.0441      0.090     -0.492      0.624      -0.222       0.134\n",
       "x69           -0.0070      0.077     -0.090      0.928      -0.161       0.147\n",
       "x70           -0.0707      0.090     -0.784      0.435      -0.250       0.108\n",
       "x71           -0.0107      0.106     -0.101      0.920      -0.221       0.200\n",
       "x72           -0.2737      0.104     -2.623      0.010      -0.481      -0.067\n",
       "x73            0.1977      0.091      2.185      0.031       0.018       0.377\n",
       "x74            0.1325      0.096      1.374      0.172      -0.059       0.324\n",
       "x75            0.1569      0.099      1.580      0.117      -0.040       0.354\n",
       "x76            0.1292      0.101      1.284      0.202      -0.071       0.329\n",
       "x77           -0.0537      0.095     -0.568      0.572      -0.242       0.134\n",
       "x78           -0.0002      0.103     -0.002      0.998      -0.205       0.205\n",
       "x79            0.2563      0.090      2.835      0.006       0.077       0.436\n",
       "x80           -0.1127      0.106     -1.064      0.290      -0.323       0.097\n",
       "x81            0.0892      0.109      0.815      0.417      -0.128       0.306\n",
       "x82            0.1673      0.105      1.588      0.115      -0.042       0.376\n",
       "x83           -0.0070      0.100     -0.070      0.945      -0.205       0.192\n",
       "x84            0.1772      0.104      1.710      0.090      -0.028       0.383\n",
       "x85            0.0336      0.089      0.378      0.706      -0.143       0.210\n",
       "x86           -0.1389      0.088     -1.575      0.118      -0.314       0.036\n",
       "x87           -0.0384      0.108     -0.356      0.722      -0.252       0.175\n",
       "x88            0.1223      0.089      1.378      0.171      -0.054       0.298\n",
       "x89           -0.0563      0.095     -0.595      0.553      -0.244       0.131\n",
       "x90           -0.1359      0.089     -1.529      0.130      -0.312       0.041\n",
       "x91            0.0544      0.096      0.569      0.571      -0.135       0.244\n",
       "x92           -0.0126      0.085     -0.148      0.883      -0.182       0.157\n",
       "x93            0.0257      0.094      0.275      0.784      -0.160       0.212\n",
       "x94            0.0526      0.104      0.508      0.613      -0.153       0.258\n",
       "x95           -0.0387      0.094     -0.414      0.680      -0.224       0.147\n",
       "x96            0.0392      0.108      0.365      0.716      -0.174       0.253\n",
       "x97            0.0203      0.092      0.221      0.826      -0.162       0.202\n",
       "x98            0.1530      0.107      1.433      0.155      -0.059       0.365\n",
       "x99           -0.2688      0.104     -2.594      0.011      -0.474      -0.063\n",
       "x100           0.0777      0.098      0.796      0.428      -0.116       0.271\n",
       "x101          -0.1207      0.103     -1.168      0.246      -0.326       0.084\n",
       "x102          -0.1128      0.086     -1.307      0.194      -0.284       0.058\n",
       "x103           0.1069      0.107      1.003      0.318      -0.105       0.319\n",
       "x104           0.0558      0.093      0.602      0.549      -0.128       0.240\n",
       "x105           0.0513      0.103      0.497      0.620      -0.153       0.256\n",
       "x106           0.1188      0.100      1.186      0.239      -0.080       0.318\n",
       "x107           0.1834      0.110      1.670      0.098      -0.035       0.401\n",
       "x108           0.0329      0.101      0.326      0.745      -0.167       0.233\n",
       "x109           0.2485      0.097      2.573      0.012       0.057       0.440\n",
       "x110          -0.0983      0.082     -1.192      0.236      -0.262       0.065\n",
       "x111           0.0029      0.095      0.030      0.976      -0.186       0.192\n",
       "x112          -0.2383      0.101     -2.367      0.020      -0.438      -0.039\n",
       "x113           0.0415      0.092      0.449      0.654      -0.142       0.225\n",
       "x114           0.0427      0.089      0.481      0.632      -0.134       0.219\n",
       "x115           0.0063      0.102      0.062      0.951      -0.197       0.209\n",
       "x116           0.1491      0.093      1.604      0.112      -0.035       0.334\n",
       "x117          -0.1267      0.081     -1.558      0.122      -0.288       0.035\n",
       "x118           0.0899      0.108      0.835      0.406      -0.124       0.303\n",
       "x119           0.1420      0.096      1.483      0.141      -0.048       0.332\n",
       "x120           0.0369      0.090      0.408      0.684      -0.142       0.216\n",
       "x121           0.0365      0.096      0.382      0.703      -0.153       0.226\n",
       "x122           0.0158      0.100      0.158      0.874      -0.182       0.214\n",
       "x123          -0.1779      0.092     -1.933      0.056      -0.360       0.005\n",
       "x124           0.1677      0.088      1.908      0.059      -0.007       0.342\n",
       "x125          -0.0721      0.100     -0.724      0.471      -0.270       0.125\n",
       "x126           0.1319      0.099      1.329      0.187      -0.065       0.329\n",
       "x127          -0.0574      0.088     -0.654      0.515      -0.232       0.117\n",
       "x128           0.1494      0.098      1.530      0.129      -0.044       0.343\n",
       "x129          -0.0641      0.090     -0.715      0.476      -0.242       0.114\n",
       "x130          -0.2117      0.102     -2.068      0.041      -0.415      -0.009\n",
       "x131           0.0080      0.086      0.093      0.926      -0.163       0.179\n",
       "x132           0.2239      0.088      2.537      0.013       0.049       0.399\n",
       "x133           0.0156      0.096      0.162      0.872      -0.175       0.206\n",
       "x134          -0.0134      0.096     -0.140      0.889      -0.203       0.176\n",
       "x135           0.0163      0.095      0.172      0.864      -0.171       0.204\n",
       "x136           0.0167      0.103      0.162      0.871      -0.187       0.220\n",
       "x137          -0.0382      0.103     -0.373      0.710      -0.242       0.165\n",
       "x138           0.2713      0.099      2.751      0.007       0.076       0.467\n",
       "x139           0.0011      0.088      0.013      0.990      -0.174       0.176\n",
       "x140          -0.0325      0.091     -0.357      0.721      -0.213       0.148\n",
       "x141           0.1099      0.099      1.109      0.270      -0.087       0.307\n",
       "x142           0.0464      0.108      0.429      0.669      -0.168       0.261\n",
       "x143          -0.1365      0.092     -1.476      0.143      -0.320       0.047\n",
       "x144          -0.0563      0.107     -0.528      0.599      -0.268       0.155\n",
       "x145           0.0694      0.092      0.754      0.452      -0.113       0.252\n",
       "x146          -0.0624      0.102     -0.612      0.542      -0.265       0.140\n",
       "x147           0.1139      0.091      1.248      0.215      -0.067       0.295\n",
       "x148           0.0549      0.088      0.626      0.533      -0.119       0.229\n",
       "x149          -0.1183      0.092     -1.287      0.201      -0.301       0.064\n",
       "x150          -0.1122      0.106     -1.056      0.294      -0.323       0.099\n",
       "x151           0.0507      0.093      0.548      0.585      -0.133       0.235\n",
       "x152           0.0716      0.102      0.698      0.487      -0.132       0.275\n",
       "x153           0.1872      0.107      1.750      0.083      -0.025       0.400\n",
       "x154           0.1174      0.101      1.162      0.248      -0.083       0.318\n",
       "x155           0.0767      0.103      0.745      0.458      -0.127       0.281\n",
       "x156           0.0388      0.092      0.420      0.675      -0.145       0.222\n",
       "x157           0.0076      0.097      0.078      0.938      -0.185       0.200\n",
       "x158           0.1458      0.082      1.773      0.079      -0.017       0.309\n",
       "x159          -0.3022      0.099     -3.038      0.003      -0.500      -0.105\n",
       "x160           0.0685      0.100      0.683      0.496      -0.130       0.267\n",
       "x161          -0.0914      0.089     -1.030      0.306      -0.267       0.085\n",
       "x162           0.1205      0.101      1.189      0.237      -0.081       0.322\n",
       "x163          -0.1700      0.090     -1.885      0.062      -0.349       0.009\n",
       "x164          -0.0161      0.114     -0.142      0.887      -0.242       0.209\n",
       "x165          -0.1175      0.101     -1.158      0.250      -0.319       0.084\n",
       "x166           0.0905      0.096      0.940      0.349      -0.100       0.281\n",
       "x167          -0.0323      0.114     -0.284      0.777      -0.259       0.194\n",
       "x168           0.0022      0.088      0.025      0.980      -0.173       0.177\n",
       "x169          -0.1243      0.095     -1.314      0.192      -0.312       0.063\n",
       "x170           0.0666      0.095      0.703      0.484      -0.121       0.255\n",
       "x171           0.0135      0.089      0.151      0.880      -0.164       0.191\n",
       "x172           0.2430      0.108      2.251      0.027       0.029       0.457\n",
       "x173           0.0767      0.098      0.780      0.437      -0.118       0.272\n",
       "x174          -0.2467      0.084     -2.922      0.004      -0.414      -0.079\n",
       "x175           0.0502      0.117      0.429      0.669      -0.182       0.283\n",
       "x176          -0.0622      0.107     -0.579      0.564      -0.275       0.151\n",
       "x177           0.1050      0.097      1.083      0.281      -0.087       0.297\n",
       "x178          -0.2222      0.092     -2.403      0.018      -0.406      -0.039\n",
       "x179           0.0924      0.107      0.864      0.390      -0.120       0.305\n",
       "x180          -0.0195      0.091     -0.215      0.830      -0.200       0.161\n",
       "x181           0.1207      0.094      1.283      0.203      -0.066       0.307\n",
       "x182          -0.0375      0.103     -0.363      0.717      -0.242       0.167\n",
       "x183           0.0117      0.107      0.109      0.914      -0.201       0.225\n",
       "x184           0.1184      0.110      1.081      0.282      -0.099       0.336\n",
       "x185          -0.0303      0.088     -0.343      0.732      -0.205       0.145\n",
       "x186           0.0240      0.093      0.259      0.796      -0.160       0.208\n",
       "x187          -0.0855      0.087     -0.977      0.331      -0.259       0.088\n",
       "x188           0.1224      0.104      1.175      0.243      -0.084       0.329\n",
       "x189          -0.0815      0.110     -0.738      0.462      -0.301       0.138\n",
       "x190           0.1136      0.099      1.147      0.254      -0.083       0.310\n",
       "x191           0.0073      0.100      0.073      0.942      -0.192       0.206\n",
       "x192           0.0088      0.097      0.090      0.928      -0.184       0.202\n",
       "x193          -0.0688      0.106     -0.649      0.518      -0.279       0.141\n",
       "x194          -0.0063      0.096     -0.065      0.948      -0.197       0.185\n",
       "x195          -0.0124      0.092     -0.135      0.893      -0.195       0.170\n",
       "x196          -0.1842      0.107     -1.717      0.089      -0.397       0.029\n",
       "x197          -0.0608      0.096     -0.634      0.527      -0.251       0.129\n",
       "x198          -0.0361      0.097     -0.371      0.711      -0.229       0.157\n",
       "x199          -0.0211      0.100     -0.212      0.833      -0.219       0.177\n",
       "x200          -0.0686      0.092     -0.749      0.456      -0.250       0.113\n",
       "x201           0.0619      0.101      0.615      0.540      -0.138       0.262\n",
       "x202          -0.1188      0.096     -1.237      0.219      -0.310       0.072\n",
       "x203          -0.1423      0.091     -1.567      0.120      -0.322       0.038\n",
       "x204           0.0742      0.101      0.736      0.463      -0.126       0.274\n",
       "x205          -0.1232      0.109     -1.130      0.261      -0.339       0.093\n",
       "x206          -0.1031      0.104     -0.991      0.324      -0.310       0.103\n",
       "x207           0.0329      0.105      0.312      0.756      -0.176       0.242\n",
       "x208          -0.1038      0.096     -1.079      0.283      -0.295       0.087\n",
       "x209           0.0631      0.094      0.670      0.504      -0.124       0.250\n",
       "x210          -0.2320      0.101     -2.302      0.023      -0.432      -0.032\n",
       "x211           0.0293      0.096      0.304      0.762      -0.162       0.221\n",
       "x212          -0.3021      0.107     -2.830      0.006      -0.514      -0.090\n",
       "x213           0.1520      0.080      1.907      0.060      -0.006       0.310\n",
       "x214           0.0511      0.103      0.496      0.621      -0.153       0.256\n",
       "x215          -0.1273      0.103     -1.237      0.219      -0.331       0.077\n",
       "x216           0.0109      0.087      0.125      0.901      -0.163       0.184\n",
       "x217           0.0515      0.097      0.533      0.595      -0.140       0.243\n",
       "x218           0.0399      0.100      0.398      0.692      -0.159       0.239\n",
       "x219           0.0275      0.098      0.280      0.780      -0.167       0.222\n",
       "x220          -0.0915      0.104     -0.878      0.382      -0.298       0.115\n",
       "x221          -0.1841      0.095     -1.939      0.055      -0.373       0.004\n",
       "x222          -0.0031      0.093     -0.033      0.974      -0.187       0.181\n",
       "x223          -0.0803      0.105     -0.765      0.446      -0.288       0.128\n",
       "x224           0.0304      0.097      0.312      0.756      -0.163       0.224\n",
       "x225           0.1578      0.089      1.779      0.078      -0.018       0.334\n",
       "x226           0.0323      0.096      0.338      0.736      -0.157       0.222\n",
       "x227          -0.0306      0.080     -0.384      0.702      -0.189       0.128\n",
       "x228          -0.0980      0.098     -1.002      0.319      -0.292       0.096\n",
       "x229          -0.0347      0.108     -0.322      0.748      -0.249       0.179\n",
       "x230           0.1874      0.106      1.766      0.080      -0.023       0.398\n",
       "x231          -0.1462      0.091     -1.604      0.112      -0.327       0.035\n",
       "x232           0.1813      0.097      1.865      0.065      -0.012       0.374\n",
       "x233           0.0514      0.104      0.493      0.623      -0.155       0.258\n",
       "x234          -0.2205      0.101     -2.192      0.031      -0.420      -0.021\n",
       "x235           0.0909      0.098      0.926      0.357      -0.104       0.286\n",
       "x236           0.0675      0.114      0.590      0.557      -0.159       0.294\n",
       "x237          -0.2021      0.104     -1.947      0.054      -0.408       0.004\n",
       "x238           0.1379      0.104      1.325      0.188      -0.069       0.345\n",
       "x239          -0.0926      0.094     -0.987      0.326      -0.279       0.094\n",
       "x240          -0.1299      0.088     -1.481      0.142      -0.304       0.044\n",
       "x241          -0.0542      0.091     -0.593      0.555      -0.236       0.127\n",
       "x242          -0.0469      0.090     -0.523      0.602      -0.225       0.131\n",
       "x243          -0.0447      0.087     -0.515      0.607      -0.217       0.127\n",
       "x244          -0.2715      0.097     -2.805      0.006      -0.464      -0.079\n",
       "x245           0.0796      0.090      0.883      0.380      -0.099       0.259\n",
       "x246           0.0414      0.087      0.474      0.637      -0.132       0.215\n",
       "x247           0.1927      0.119      1.620      0.108      -0.043       0.429\n",
       "x248          -0.0901      0.093     -0.972      0.333      -0.274       0.094\n",
       "x249           0.1095      0.095      1.147      0.254      -0.080       0.299\n",
       "x250          -0.1233      0.095     -1.302      0.196      -0.311       0.065\n",
       "x251          -0.0366      0.092     -0.399      0.691      -0.219       0.146\n",
       "x252          -0.1879      0.104     -1.803      0.074      -0.395       0.019\n",
       "x253          -0.0824      0.098     -0.840      0.403      -0.277       0.112\n",
       "x254          -0.1967      0.090     -2.175      0.032      -0.376      -0.017\n",
       "x255          -0.2006      0.106     -1.900      0.060      -0.410       0.009\n",
       "x256          -0.0005      0.090     -0.006      0.995      -0.180       0.179\n",
       "x257          -0.0861      0.101     -0.849      0.398      -0.287       0.115\n",
       "x258          -0.0057      0.094     -0.061      0.952      -0.192       0.181\n",
       "x259          -0.1008      0.097     -1.036      0.303      -0.294       0.092\n",
       "x260           0.1092      0.108      1.012      0.314      -0.105       0.323\n",
       "x261           0.0695      0.107      0.652      0.516      -0.142       0.281\n",
       "x262           0.0869      0.097      0.897      0.372      -0.105       0.279\n",
       "x263          -0.1211      0.096     -1.263      0.210      -0.311       0.069\n",
       "x264          -0.1357      0.088     -1.538      0.127      -0.311       0.039\n",
       "x265           0.0690      0.090      0.764      0.447      -0.110       0.248\n",
       "x266          -0.1704      0.093     -1.825      0.071      -0.356       0.015\n",
       "x267          -0.0292      0.092     -0.318      0.751      -0.211       0.153\n",
       "x268           0.0317      0.095      0.332      0.740      -0.157       0.221\n",
       "x269           0.0154      0.096      0.160      0.873      -0.175       0.206\n",
       "x270          -0.0731      0.088     -0.826      0.411      -0.249       0.103\n",
       "x271          -0.0131      0.102     -0.129      0.898      -0.216       0.189\n",
       "x272          -0.2091      0.100     -2.082      0.040      -0.408      -0.010\n",
       "x273           0.0430      0.093      0.460      0.646      -0.142       0.228\n",
       "x274          -0.1206      0.106     -1.139      0.257      -0.331       0.090\n",
       "x275           0.1919      0.102      1.875      0.064      -0.011       0.395\n",
       "x276          -0.1260      0.100     -1.257      0.212      -0.325       0.073\n",
       "x277          -0.0156      0.101     -0.154      0.878      -0.217       0.186\n",
       "x278           0.1237      0.092      1.338      0.184      -0.060       0.307\n",
       "x279          -0.1207      0.103     -1.172      0.244      -0.325       0.084\n",
       "x280           0.0675      0.108      0.625      0.533      -0.147       0.282\n",
       "x281          -0.0307      0.089     -0.346      0.730      -0.207       0.145\n",
       "x282          -0.1886      0.093     -2.038      0.044      -0.372      -0.005\n",
       "x283          -0.0262      0.088     -0.299      0.766      -0.200       0.148\n",
       "x284           0.1654      0.097      1.713      0.090      -0.026       0.357\n",
       "x285          -0.0225      0.093     -0.241      0.810      -0.208       0.163\n",
       "x286           0.0055      0.102      0.054      0.957      -0.197       0.207\n",
       "x287           0.0864      0.096      0.899      0.371      -0.104       0.277\n",
       "x288           0.1221      0.098      1.252      0.214      -0.071       0.316\n",
       "x289           0.0383      0.090      0.424      0.673      -0.141       0.217\n",
       "x290          -0.0112      0.105     -0.107      0.915      -0.219       0.196\n",
       "x291           0.0017      0.084      0.020      0.984      -0.166       0.169\n",
       "x292           0.0262      0.102      0.256      0.798      -0.176       0.229\n",
       "x293          -0.1821      0.093     -1.957      0.053      -0.367       0.003\n",
       "x294           0.0161      0.111      0.146      0.884      -0.203       0.236\n",
       "x295           0.0565      0.094      0.603      0.548      -0.129       0.242\n",
       "x296           0.0653      0.098      0.666      0.507      -0.129       0.260\n",
       "x297           0.0685      0.099      0.691      0.491      -0.128       0.265\n",
       "x298          -0.0558      0.087     -0.641      0.523      -0.229       0.117\n",
       "x299          -0.0260      0.089     -0.292      0.771      -0.202       0.150\n",
       "x300          -0.1151      0.099     -1.165      0.247      -0.311       0.081\n",
       "x301           0.0103      0.094      0.109      0.914      -0.177       0.198\n",
       "x302          -0.0634      0.098     -0.650      0.517      -0.257       0.130\n",
       "x303           0.1010      0.098      1.034      0.304      -0.093       0.295\n",
       "x304          -0.0330      0.096     -0.344      0.731      -0.223       0.157\n",
       "x305          -0.0455      0.098     -0.466      0.642      -0.239       0.148\n",
       "x306          -0.1239      0.089     -1.394      0.167      -0.300       0.053\n",
       "x307          -0.1180      0.087     -1.350      0.180      -0.291       0.055\n",
       "x308          -0.0132      0.087     -0.151      0.880      -0.187       0.160\n",
       "x309          -0.1094      0.100     -1.096      0.276      -0.308       0.089\n",
       "x310           0.0585      0.102      0.575      0.566      -0.143       0.260\n",
       "x311          -0.0574      0.083     -0.689      0.493      -0.223       0.108\n",
       "x312           0.0541      0.089      0.607      0.545      -0.123       0.231\n",
       "x313          -0.1389      0.095     -1.460      0.148      -0.328       0.050\n",
       "x314          -0.0674      0.095     -0.711      0.478      -0.255       0.121\n",
       "x315           0.2338      0.095      2.456      0.016       0.045       0.423\n",
       "x316           0.0138      0.107      0.129      0.898      -0.199       0.227\n",
       "x317          -0.0599      0.090     -0.662      0.509      -0.240       0.120\n",
       "x318           0.0442      0.082      0.537      0.592      -0.119       0.207\n",
       "x319          -0.1601      0.084     -1.906      0.060      -0.327       0.007\n",
       "x320          -0.2258      0.098     -2.309      0.023      -0.420      -0.032\n",
       "x321           0.1742      0.096      1.812      0.073      -0.017       0.365\n",
       "x322          -0.1382      0.098     -1.407      0.162      -0.333       0.057\n",
       "x323           0.0593      0.107      0.553      0.581      -0.153       0.272\n",
       "x324           0.0505      0.096      0.528      0.599      -0.139       0.241\n",
       "x325           0.0613      0.092      0.666      0.507      -0.121       0.244\n",
       "x326          -0.2138      0.099     -2.154      0.034      -0.411      -0.017\n",
       "x327          -0.0933      0.088     -1.056      0.294      -0.269       0.082\n",
       "x328           0.0948      0.087      1.087      0.280      -0.078       0.268\n",
       "x329          -0.2036      0.092     -2.215      0.029      -0.386      -0.021\n",
       "x330          -0.1470      0.095     -1.543      0.126      -0.336       0.042\n",
       "x331           0.0210      0.101      0.209      0.835      -0.179       0.221\n",
       "x332          -0.1556      0.091     -1.702      0.092      -0.337       0.026\n",
       "x333          -0.0174      0.091     -0.192      0.848      -0.197       0.162\n",
       "x334           0.0712      0.092      0.776      0.440      -0.111       0.253\n",
       "x335          -0.0238      0.109     -0.219      0.827      -0.240       0.192\n",
       "x336           0.1141      0.095      1.206      0.231      -0.074       0.302\n",
       "x337          -0.1903      0.097     -1.968      0.052      -0.382       0.002\n",
       "x338           0.2025      0.096      2.120      0.036       0.013       0.392\n",
       "x339           0.2132      0.096      2.223      0.029       0.023       0.404\n",
       "x340           0.0441      0.088      0.504      0.616      -0.130       0.218\n",
       "x341          -0.1502      0.103     -1.457      0.148      -0.355       0.054\n",
       "x342          -0.1692      0.099     -1.705      0.091      -0.366       0.028\n",
       "x343          -0.0336      0.088     -0.384      0.702      -0.208       0.140\n",
       "x344          -0.0036      0.092     -0.039      0.969      -0.186       0.179\n",
       "x345          -0.0798      0.094     -0.850      0.398      -0.266       0.107\n",
       "x346           0.0369      0.096      0.383      0.703      -0.154       0.228\n",
       "x347           0.0085      0.088      0.097      0.923      -0.165       0.182\n",
       "x348          -0.0753      0.096     -0.783      0.436      -0.266       0.116\n",
       "x349           0.0711      0.092      0.773      0.441      -0.111       0.253\n",
       "x350           0.1258      0.092      1.367      0.175      -0.057       0.309\n",
       "x351          -0.0136      0.100     -0.136      0.892      -0.212       0.185\n",
       "x352          -0.0433      0.103     -0.423      0.674      -0.247       0.160\n",
       "x353           0.0833      0.103      0.812      0.419      -0.120       0.287\n",
       "x354          -0.0559      0.086     -0.651      0.517      -0.226       0.114\n",
       "x355          -0.1099      0.103     -1.065      0.290      -0.315       0.095\n",
       "x356          -0.1491      0.091     -1.646      0.103      -0.329       0.031\n",
       "x357           0.0899      0.103      0.874      0.384      -0.114       0.294\n",
       "x358           0.0981      0.107      0.918      0.361      -0.114       0.310\n",
       "x359          -0.0234      0.090     -0.260      0.795      -0.202       0.155\n",
       "x360           0.0177      0.099      0.179      0.859      -0.179       0.214\n",
       "x361          -0.0373      0.105     -0.354      0.724      -0.247       0.172\n",
       "x362          -0.1120      0.100     -1.116      0.267      -0.311       0.087\n",
       "x363          -0.0976      0.088     -1.115      0.268      -0.271       0.076\n",
       "x364          -0.2084      0.094     -2.225      0.028      -0.394      -0.023\n",
       "x365           0.0369      0.104      0.354      0.724      -0.170       0.244\n",
       "x366           0.0903      0.108      0.833      0.407      -0.125       0.306\n",
       "x367           0.0575      0.088      0.650      0.518      -0.118       0.233\n",
       "x368           0.0553      0.098      0.564      0.574      -0.139       0.250\n",
       "x369          -0.1429      0.106     -1.347      0.181      -0.353       0.068\n",
       "x370          -0.2386      0.095     -2.523      0.013      -0.426      -0.051\n",
       "x371           0.1913      0.112      1.716      0.089      -0.030       0.413\n",
       "x372           0.2498      0.095      2.642      0.010       0.062       0.437\n",
       "x373           0.0829      0.094      0.884      0.379      -0.103       0.269\n",
       "x374           0.0499      0.102      0.488      0.627      -0.153       0.253\n",
       "x375           0.0362      0.092      0.393      0.695      -0.147       0.219\n",
       "x376          -0.0389      0.090     -0.434      0.665      -0.217       0.139\n",
       "x377          -0.0424      0.101     -0.418      0.677      -0.243       0.159\n",
       "x378          -0.0431      0.096     -0.450      0.654      -0.233       0.147\n",
       "x379          -0.0939      0.094     -1.002      0.319      -0.280       0.092\n",
       "x380           0.2044      0.100      2.042      0.044       0.006       0.403\n",
       "x381          -0.0935      0.098     -0.949      0.345      -0.289       0.102\n",
       "x382          -0.0466      0.102     -0.458      0.648      -0.249       0.155\n",
       "x383          -0.0812      0.118     -0.686      0.494      -0.316       0.154\n",
       "x384          -0.0774      0.098     -0.793      0.430      -0.271       0.116\n",
       "x385           0.1264      0.088      1.437      0.154      -0.048       0.301\n",
       "x386          -0.2162      0.102     -2.130      0.036      -0.418      -0.015\n",
       "x387           0.1551      0.099      1.563      0.121      -0.042       0.352\n",
       "x388          -0.0024      0.087     -0.028      0.978      -0.174       0.170\n",
       "x389           0.0177      0.093      0.190      0.849      -0.167       0.202\n",
       "x390          -0.0097      0.107     -0.091      0.928      -0.222       0.202\n",
       "x391           0.1685      0.104      1.616      0.109      -0.038       0.376\n",
       "x392          -0.1456      0.087     -1.673      0.097      -0.318       0.027\n",
       "x393           0.1659      0.110      1.504      0.136      -0.053       0.385\n",
       "x394           0.0853      0.093      0.918      0.361      -0.099       0.270\n",
       "x395          -0.0521      0.097     -0.537      0.592      -0.245       0.141\n",
       "x396          -0.0281      0.093     -0.301      0.764      -0.213       0.157\n",
       "x397           0.0550      0.094      0.583      0.561      -0.132       0.242\n",
       "x398          -0.1562      0.100     -1.564      0.121      -0.354       0.042\n",
       "x399           0.0488      0.108      0.453      0.652      -0.165       0.263\n",
       "x400           0.2709      0.102      2.659      0.009       0.069       0.473\n",
       "x401          -0.0837      0.096     -0.877      0.383      -0.273       0.106\n",
       "x402          -0.0102      0.098     -0.105      0.917      -0.205       0.184\n",
       "x403           0.0642      0.111      0.577      0.565      -0.157       0.285\n",
       "x404           0.1265      0.088      1.437      0.154      -0.048       0.301\n",
       "x405          -0.0066      0.094     -0.071      0.944      -0.192       0.179\n",
       "x406          -0.0789      0.100     -0.787      0.433      -0.278       0.120\n",
       "x407           0.2168      0.090      2.408      0.018       0.038       0.396\n",
       "x408           0.2755      0.091      3.027      0.003       0.095       0.456\n",
       "x409           0.0893      0.097      0.923      0.358      -0.103       0.281\n",
       "x410           0.0292      0.101      0.290      0.772      -0.170       0.229\n",
       "x411           0.0573      0.096      0.595      0.553      -0.134       0.248\n",
       "x412           0.0583      0.109      0.535      0.594      -0.158       0.275\n",
       "x413           0.0240      0.096      0.252      0.802      -0.165       0.214\n",
       "x414           0.0741      0.098      0.760      0.449      -0.119       0.268\n",
       "x415          -0.0273      0.108     -0.254      0.800      -0.241       0.186\n",
       "x416          -0.0077      0.086     -0.089      0.929      -0.179       0.163\n",
       "x417          -0.0315      0.096     -0.328      0.743      -0.222       0.159\n",
       "x418           0.0296      0.086      0.342      0.733      -0.142       0.201\n",
       "x419           0.0240      0.097      0.246      0.806      -0.169       0.217\n",
       "x420          -0.0995      0.096     -1.042      0.300      -0.289       0.090\n",
       "x421           0.0330      0.091      0.365      0.716      -0.147       0.213\n",
       "x422           0.0966      0.088      1.101      0.274      -0.078       0.271\n",
       "x423          -0.1466      0.095     -1.547      0.125      -0.335       0.041\n",
       "x424           0.0320      0.084      0.381      0.704      -0.135       0.199\n",
       "x425          -0.1023      0.110     -0.933      0.353      -0.320       0.115\n",
       "x426           0.0026      0.097      0.027      0.978      -0.189       0.194\n",
       "x427           0.0635      0.113      0.560      0.577      -0.162       0.289\n",
       "x428           0.0762      0.091      0.836      0.405      -0.105       0.257\n",
       "x429          -0.1009      0.092     -1.101      0.274      -0.283       0.081\n",
       "x430          -0.0321      0.102     -0.314      0.755      -0.235       0.171\n",
       "x431           0.0670      0.094      0.712      0.478      -0.120       0.254\n",
       "x432          -0.0495      0.093     -0.533      0.595      -0.234       0.135\n",
       "x433           0.1573      0.106      1.483      0.141      -0.053       0.368\n",
       "x434           0.0599      0.100      0.599      0.551      -0.139       0.259\n",
       "x435          -0.2614      0.098     -2.669      0.009      -0.456      -0.067\n",
       "x436           0.0397      0.089      0.447      0.656      -0.137       0.216\n",
       "x437           0.1227      0.104      1.182      0.240      -0.083       0.329\n",
       "x438          -0.2036      0.107     -1.898      0.061      -0.416       0.009\n",
       "x439           0.0766      0.094      0.813      0.418      -0.110       0.263\n",
       "x440           0.0626      0.095      0.659      0.512      -0.126       0.251\n",
       "x441           0.1334      0.102      1.313      0.192      -0.068       0.335\n",
       "x442          -0.0219      0.118     -0.186      0.853      -0.256       0.212\n",
       "x443          -0.1467      0.097     -1.508      0.135      -0.340       0.046\n",
       "x444           0.0979      0.094      1.041      0.300      -0.089       0.284\n",
       "x445          -0.1274      0.089     -1.436      0.154      -0.303       0.049\n",
       "x446          -0.0071      0.093     -0.077      0.939      -0.191       0.177\n",
       "x447           0.1176      0.102      1.148      0.254      -0.086       0.321\n",
       "x448           0.0140      0.096      0.147      0.884      -0.176       0.204\n",
       "x449           0.0199      0.098      0.204      0.838      -0.174       0.214\n",
       "x450          -0.0023      0.093     -0.025      0.980      -0.187       0.183\n",
       "x451          -0.0183      0.096     -0.191      0.849      -0.208       0.171\n",
       "x452          -0.0820      0.094     -0.870      0.387      -0.269       0.105\n",
       "x453          -0.1722      0.098     -1.756      0.082      -0.367       0.022\n",
       "x454          -0.1311      0.111     -1.179      0.241      -0.352       0.090\n",
       "x455           0.0143      0.094      0.151      0.880      -0.173       0.201\n",
       "x456           0.0661      0.104      0.638      0.525      -0.139       0.271\n",
       "x457           0.0876      0.091      0.964      0.337      -0.093       0.268\n",
       "x458           0.0600      0.102      0.588      0.558      -0.142       0.262\n",
       "x459           0.1862      0.102      1.832      0.070      -0.016       0.388\n",
       "x460          -0.0654      0.089     -0.733      0.465      -0.243       0.112\n",
       "x461           0.0298      0.096      0.312      0.756      -0.160       0.220\n",
       "x462           0.0917      0.090      1.016      0.312      -0.087       0.271\n",
       "x463           0.0295      0.107      0.276      0.783      -0.183       0.242\n",
       "x464           0.1266      0.100      1.272      0.206      -0.071       0.324\n",
       "x465          -0.1984      0.090     -2.195      0.031      -0.378      -0.019\n",
       "x466           0.0761      0.096      0.793      0.430      -0.114       0.266\n",
       "x467           0.0434      0.091      0.475      0.636      -0.138       0.225\n",
       "x468          -0.2014      0.096     -2.104      0.038      -0.391      -0.011\n",
       "x469          -0.0476      0.093     -0.514      0.608      -0.231       0.136\n",
       "x470           0.0424      0.091      0.464      0.644      -0.139       0.224\n",
       "x471          -0.0500      0.097     -0.516      0.607      -0.243       0.143\n",
       "x472           0.1295      0.098      1.327      0.188      -0.064       0.323\n",
       "x473          -0.0039      0.088     -0.044      0.965      -0.179       0.172\n",
       "x474          -0.1622      0.093     -1.750      0.083      -0.346       0.022\n",
       "x475           0.0148      0.092      0.161      0.872      -0.167       0.197\n",
       "x476          -0.1288      0.095     -1.352      0.180      -0.318       0.060\n",
       "x477           0.2245      0.091      2.459      0.016       0.043       0.406\n",
       "x478          -0.1532      0.098     -1.557      0.123      -0.348       0.042\n",
       "x479           0.1009      0.091      1.106      0.271      -0.080       0.282\n",
       "x480          -0.0452      0.097     -0.465      0.643      -0.238       0.148\n",
       "x481          -0.1374      0.100     -1.377      0.172      -0.335       0.061\n",
       "x482          -0.0920      0.095     -0.970      0.334      -0.280       0.096\n",
       "x483          -0.0716      0.087     -0.820      0.414      -0.245       0.102\n",
       "x484          -0.0753      0.094     -0.803      0.424      -0.261       0.111\n",
       "x485           0.1370      0.106      1.294      0.199      -0.073       0.347\n",
       "x486           0.0167      0.098      0.170      0.865      -0.179       0.212\n",
       "x487          -0.0673      0.104     -0.650      0.517      -0.273       0.138\n",
       "x488           0.0348      0.095      0.368      0.714      -0.153       0.223\n",
       "x489           0.2082      0.098      2.134      0.035       0.015       0.402\n",
       "x490           0.0350      0.087      0.400      0.690      -0.139       0.209\n",
       "x491           0.1917      0.092      2.089      0.039       0.010       0.374\n",
       "x492           0.1758      0.089      1.984      0.050   -6.62e-05       0.352\n",
       "x493           0.2226      0.101      2.198      0.030       0.022       0.423\n",
       "x494           0.0377      0.102      0.368      0.713      -0.166       0.241\n",
       "x495          -0.0485      0.084     -0.580      0.563      -0.215       0.117\n",
       "x496          -0.0844      0.084     -1.007      0.317      -0.251       0.082\n",
       "x497           0.0391      0.086      0.456      0.650      -0.131       0.210\n",
       "x498          -0.0455      0.093     -0.488      0.627      -0.231       0.140\n",
       "x499           0.1273      0.086      1.474      0.144      -0.044       0.299\n",
       "x500          -0.0013      0.099     -0.014      0.989      -0.197       0.194\n",
       "x501           0.1116      0.096      1.164      0.247      -0.079       0.302\n",
       "x502           0.1800      0.094      1.920      0.058      -0.006       0.366\n",
       "x503           0.1937      0.096      2.022      0.046       0.004       0.384\n",
       "x504           0.1303      0.091      1.433      0.155      -0.050       0.311\n",
       "x505           0.0318      0.109      0.291      0.771      -0.185       0.248\n",
       "x506           0.0499      0.090      0.554      0.581      -0.129       0.229\n",
       "x507          -0.0801      0.091     -0.880      0.381      -0.261       0.101\n",
       "x508           0.0571      0.090      0.634      0.527      -0.122       0.236\n",
       "x509           0.1327      0.087      1.525      0.130      -0.040       0.305\n",
       "x510           0.0465      0.092      0.503      0.616      -0.137       0.230\n",
       "x511           0.0471      0.110      0.429      0.669      -0.171       0.265\n",
       "x512          -0.1812      0.102     -1.784      0.077      -0.383       0.020\n",
       "x513          -0.0109      0.102     -0.107      0.915      -0.213       0.191\n",
       "x514           0.1507      0.089      1.700      0.092      -0.025       0.327\n",
       "x515           0.0657      0.087      0.751      0.455      -0.108       0.239\n",
       "x516           0.1365      0.103      1.329      0.187      -0.067       0.340\n",
       "x517           0.0134      0.087      0.155      0.878      -0.159       0.186\n",
       "x518          -0.0155      0.096     -0.161      0.872      -0.206       0.175\n",
       "x519          -0.1199      0.110     -1.094      0.277      -0.337       0.098\n",
       "x520           0.1991      0.102      1.950      0.054      -0.004       0.402\n",
       "x521          -0.1128      0.092     -1.231      0.221      -0.295       0.069\n",
       "x522           0.1754      0.103      1.701      0.092      -0.029       0.380\n",
       "x523          -0.0449      0.104     -0.433      0.666      -0.250       0.161\n",
       "x524          -0.0809      0.099     -0.816      0.417      -0.278       0.116\n",
       "x525          -0.1478      0.113     -1.310      0.193      -0.372       0.076\n",
       "x526           0.1286      0.098      1.309      0.194      -0.066       0.324\n",
       "x527           0.0964      0.087      1.102      0.273      -0.077       0.270\n",
       "x528           0.0306      0.088      0.348      0.728      -0.144       0.205\n",
       "x529          -0.0311      0.099     -0.314      0.754      -0.228       0.166\n",
       "x530           0.0694      0.091      0.760      0.449      -0.112       0.251\n",
       "x531          -0.1207      0.092     -1.313      0.192      -0.303       0.062\n",
       "x532           0.0312      0.108      0.288      0.774      -0.184       0.246\n",
       "x533          -0.0070      0.111     -0.063      0.950      -0.228       0.214\n",
       "x534          -0.1468      0.103     -1.427      0.157      -0.351       0.057\n",
       "x535           0.0609      0.096      0.632      0.529      -0.130       0.252\n",
       "x536           0.1526      0.111      1.377      0.172      -0.067       0.372\n",
       "x537           0.0490      0.095      0.517      0.606      -0.139       0.237\n",
       "x538           0.1973      0.089      2.226      0.028       0.021       0.373\n",
       "x539          -0.1739      0.095     -1.836      0.069      -0.362       0.014\n",
       "x540          -0.0313      0.096     -0.325      0.746      -0.222       0.159\n",
       "x541          -0.1672      0.089     -1.874      0.064      -0.344       0.010\n",
       "x542           0.0731      0.107      0.685      0.495      -0.139       0.285\n",
       "x543          -0.1114      0.092     -1.215      0.227      -0.293       0.071\n",
       "x544          -0.0819      0.096     -0.849      0.398      -0.273       0.109\n",
       "x545          -0.0138      0.101     -0.137      0.892      -0.214       0.186\n",
       "x546          -0.0312      0.104     -0.300      0.765      -0.237       0.175\n",
       "x547           0.0400      0.090      0.442      0.659      -0.139       0.219\n",
       "x548          -0.0113      0.084     -0.134      0.894      -0.179       0.156\n",
       "x549          -0.2650      0.100     -2.639      0.010      -0.464      -0.066\n",
       "x550           0.1158      0.088      1.316      0.191      -0.059       0.291\n",
       "x551           0.0455      0.094      0.486      0.628      -0.140       0.231\n",
       "x552           0.0526      0.094      0.560      0.576      -0.134       0.239\n",
       "x553           0.1862      0.093      2.005      0.048       0.002       0.371\n",
       "x554          -0.1394      0.093     -1.498      0.137      -0.324       0.045\n",
       "x555           0.0056      0.086      0.065      0.949      -0.166       0.177\n",
       "x556           0.2161      0.104      2.081      0.040       0.010       0.422\n",
       "x557           0.1428      0.099      1.445      0.152      -0.053       0.339\n",
       "x558           0.0285      0.095      0.300      0.765      -0.160       0.217\n",
       "x559          -0.0024      0.104     -0.023      0.982      -0.208       0.203\n",
       "x560          -0.0963      0.100     -0.967      0.336      -0.294       0.101\n",
       "x561          -0.1320      0.094     -1.409      0.162      -0.318       0.054\n",
       "x562           0.0881      0.101      0.871      0.386      -0.113       0.289\n",
       "x563           0.0391      0.092      0.424      0.673      -0.144       0.222\n",
       "x564          -0.1032      0.106     -0.976      0.331      -0.313       0.107\n",
       "x565          -0.1194      0.093     -1.279      0.204      -0.305       0.066\n",
       "x566           0.1884      0.100      1.879      0.063      -0.011       0.387\n",
       "x567          -0.1295      0.100     -1.293      0.199      -0.328       0.069\n",
       "x568           0.0868      0.104      0.834      0.407      -0.120       0.293\n",
       "x569          -0.0542      0.106     -0.512      0.610      -0.264       0.156\n",
       "x570           0.1676      0.097      1.735      0.086      -0.024       0.359\n",
       "x571           0.0716      0.085      0.840      0.403      -0.098       0.241\n",
       "x572          -0.0638      0.102     -0.625      0.534      -0.267       0.139\n",
       "x573           0.2153      0.093      2.309      0.023       0.030       0.400\n",
       "x574          -0.0119      0.096     -0.124      0.902      -0.202       0.179\n",
       "x575           0.0442      0.096      0.460      0.647      -0.147       0.235\n",
       "x576          -0.0551      0.092     -0.596      0.552      -0.238       0.128\n",
       "x577           0.0124      0.092      0.135      0.893      -0.170       0.194\n",
       "x578           0.0011      0.090      0.012      0.991      -0.177       0.179\n",
       "x579           0.0772      0.095      0.810      0.420      -0.112       0.266\n",
       "x580           0.0157      0.094      0.167      0.867      -0.170       0.202\n",
       "x581           0.0921      0.094      0.981      0.329      -0.094       0.278\n",
       "x582           0.0913      0.088      1.041      0.301      -0.083       0.265\n",
       "x583           0.1262      0.092      1.368      0.174      -0.057       0.309\n",
       "x584           0.1914      0.091      2.096      0.039       0.010       0.373\n",
       "x585           0.0512      0.104      0.492      0.624      -0.155       0.258\n",
       "x586          -0.1524      0.099     -1.534      0.128      -0.349       0.045\n",
       "x587          -0.0095      0.103     -0.092      0.927      -0.215       0.195\n",
       "x588           0.2141      0.094      2.287      0.024       0.028       0.400\n",
       "x589          -0.0398      0.101     -0.393      0.695      -0.241       0.161\n",
       "x590           0.0090      0.091      0.098      0.922      -0.172       0.190\n",
       "x591           0.0523      0.096      0.545      0.587      -0.138       0.243\n",
       "x592           0.0905      0.109      0.829      0.409      -0.126       0.307\n",
       "x593          -0.2845      0.103     -2.772      0.007      -0.488      -0.081\n",
       "x594           0.0927      0.106      0.873      0.385      -0.118       0.303\n",
       "x595          -0.1795      0.106     -1.698      0.093      -0.389       0.030\n",
       "x596          -0.1899      0.091     -2.092      0.039      -0.370      -0.010\n",
       "x597          -0.1125      0.097     -1.162      0.248      -0.305       0.080\n",
       "x598           0.1216      0.097      1.251      0.214      -0.071       0.315\n",
       "x599          -0.0677      0.093     -0.726      0.469      -0.253       0.117\n",
       "x600          -0.2357      0.100     -2.354      0.021      -0.434      -0.037\n",
       "x601          -0.1311      0.096     -1.372      0.173      -0.321       0.059\n",
       "x602           0.0658      0.093      0.706      0.482      -0.119       0.251\n",
       "x603           0.1706      0.103      1.663      0.099      -0.033       0.374\n",
       "x604           0.1049      0.111      0.942      0.349      -0.116       0.326\n",
       "x605           0.0382      0.092      0.414      0.680      -0.145       0.222\n",
       "x606          -0.1086      0.101     -1.076      0.284      -0.309       0.092\n",
       "x607           0.1947      0.116      1.681      0.096      -0.035       0.425\n",
       "x608          -0.0038      0.091     -0.042      0.966      -0.184       0.176\n",
       "x609          -0.0574      0.088     -0.653      0.515      -0.232       0.117\n",
       "x610          -0.0103      0.087     -0.118      0.906      -0.183       0.162\n",
       "x611           0.1057      0.103      1.031      0.305      -0.098       0.309\n",
       "x612          -0.0351      0.094     -0.375      0.708      -0.221       0.151\n",
       "x613          -0.0713      0.094     -0.761      0.448      -0.257       0.115\n",
       "x614          -0.0664      0.106     -0.626      0.533      -0.277       0.144\n",
       "x615           0.0150      0.101      0.148      0.883      -0.186       0.216\n",
       "x616          -0.0790      0.099     -0.801      0.425      -0.275       0.117\n",
       "x617          -0.0891      0.092     -0.969      0.335      -0.271       0.093\n",
       "x618          -0.0395      0.102     -0.385      0.701      -0.243       0.164\n",
       "x619          -0.1356      0.099     -1.372      0.173      -0.332       0.061\n",
       "x620           0.0571      0.084      0.676      0.501      -0.110       0.225\n",
       "x621           0.0721      0.089      0.809      0.421      -0.105       0.249\n",
       "x622           0.1361      0.093      1.471      0.144      -0.047       0.320\n",
       "x623          -0.0610      0.097     -0.626      0.533      -0.254       0.132\n",
       "x624           0.2182      0.099      2.196      0.030       0.021       0.415\n",
       "x625           0.0556      0.094      0.589      0.557      -0.132       0.243\n",
       "x626           0.0097      0.110      0.088      0.930      -0.209       0.228\n",
       "x627           0.0694      0.096      0.725      0.470      -0.121       0.260\n",
       "x628           0.2932      0.104      2.814      0.006       0.086       0.500\n",
       "x629           0.0612      0.088      0.696      0.488      -0.113       0.236\n",
       "x630          -0.2647      0.105     -2.517      0.013      -0.473      -0.056\n",
       "x631          -0.1924      0.088     -2.182      0.031      -0.367      -0.017\n",
       "x632          -0.0013      0.086     -0.016      0.988      -0.172       0.169\n",
       "x633           0.1526      0.107      1.427      0.157      -0.060       0.365\n",
       "x634           0.0590      0.088      0.671      0.504      -0.115       0.233\n",
       "x635          -0.0367      0.094     -0.390      0.698      -0.224       0.150\n",
       "x636           0.0274      0.092      0.298      0.766      -0.155       0.210\n",
       "x637           0.0921      0.110      0.839      0.404      -0.126       0.310\n",
       "x638          -0.0419      0.104     -0.403      0.688      -0.248       0.164\n",
       "x639          -0.0647      0.089     -0.726      0.469      -0.241       0.112\n",
       "x640          -0.1117      0.093     -1.198      0.234      -0.297       0.073\n",
       "x641          -0.0469      0.088     -0.531      0.597      -0.222       0.128\n",
       "x642           0.0150      0.092      0.163      0.871      -0.168       0.198\n",
       "x643           0.0878      0.106      0.830      0.409      -0.122       0.298\n",
       "x644          -0.1079      0.107     -1.008      0.316      -0.320       0.104\n",
       "x645          -0.0690      0.093     -0.741      0.461      -0.254       0.116\n",
       "x646           0.0003      0.090      0.003      0.997      -0.178       0.179\n",
       "x647           0.0821      0.101      0.813      0.418      -0.118       0.283\n",
       "x648          -0.1314      0.094     -1.391      0.167      -0.319       0.056\n",
       "x649          -0.1670      0.092     -1.815      0.073      -0.350       0.016\n",
       "x650          -0.1462      0.101     -1.453      0.149      -0.346       0.053\n",
       "x651           0.0562      0.087      0.644      0.521      -0.117       0.229\n",
       "x652          -0.0588      0.095     -0.617      0.538      -0.248       0.130\n",
       "x653           0.0115      0.081      0.142      0.888      -0.150       0.173\n",
       "x654           0.0042      0.088      0.047      0.963      -0.171       0.180\n",
       "x655          -0.1081      0.079     -1.363      0.176      -0.266       0.049\n",
       "x656          -0.0800      0.093     -0.865      0.389      -0.264       0.104\n",
       "x657          -0.0472      0.109     -0.432      0.667      -0.264       0.170\n",
       "x658          -0.0128      0.095     -0.135      0.893      -0.201       0.176\n",
       "x659           0.0476      0.097      0.493      0.623      -0.144       0.239\n",
       "x660           0.0153      0.100      0.154      0.878      -0.182       0.213\n",
       "x661           0.0274      0.098      0.279      0.781      -0.168       0.222\n",
       "x662          -0.0430      0.089     -0.481      0.631      -0.220       0.134\n",
       "x663           0.0150      0.100      0.150      0.881      -0.183       0.213\n",
       "x664          -0.0146      0.111     -0.132      0.896      -0.235       0.206\n",
       "x665           0.0734      0.098      0.749      0.455      -0.121       0.268\n",
       "x666          -0.0317      0.094     -0.336      0.738      -0.219       0.156\n",
       "x667           0.1657      0.104      1.593      0.114      -0.041       0.372\n",
       "x668           0.0434      0.090      0.481      0.631      -0.136       0.223\n",
       "x669          -0.0014      0.100     -0.014      0.989      -0.200       0.197\n",
       "x670          -0.0552      0.089     -0.618      0.538      -0.232       0.122\n",
       "x671           0.1345      0.093      1.442      0.153      -0.051       0.320\n",
       "x672           0.0426      0.089      0.479      0.633      -0.134       0.219\n",
       "x673          -0.1002      0.100     -1.003      0.318      -0.298       0.098\n",
       "x674          -0.1467      0.102     -1.434      0.155      -0.350       0.056\n",
       "x675          -0.0831      0.102     -0.818      0.415      -0.285       0.118\n",
       "x676           0.0686      0.092      0.747      0.457      -0.114       0.251\n",
       "x677           0.0432      0.105      0.411      0.682      -0.165       0.252\n",
       "x678          -0.0421      0.091     -0.465      0.643      -0.222       0.138\n",
       "x679          -0.0209      0.105     -0.200      0.842      -0.229       0.187\n",
       "x680           0.2189      0.086      2.554      0.012       0.049       0.389\n",
       "x681           0.0100      0.082      0.122      0.903      -0.153       0.174\n",
       "x682           0.1668      0.094      1.775      0.079      -0.020       0.353\n",
       "x683           0.0351      0.095      0.371      0.711      -0.153       0.223\n",
       "x684           0.0935      0.091      1.028      0.306      -0.087       0.274\n",
       "x685           0.0230      0.086      0.268      0.789      -0.147       0.193\n",
       "x686          -0.1384      0.093     -1.480      0.142      -0.324       0.047\n",
       "x687           0.1165      0.093      1.251      0.214      -0.068       0.301\n",
       "x688           0.1061      0.109      0.976      0.332      -0.110       0.322\n",
       "x689           0.0976      0.093      1.048      0.297      -0.087       0.282\n",
       "x690          -0.0700      0.100     -0.704      0.483      -0.268       0.127\n",
       "x691           0.0451      0.098      0.460      0.647      -0.149       0.240\n",
       "x692           0.0774      0.104      0.741      0.460      -0.130       0.285\n",
       "x693           0.0532      0.105      0.508      0.613      -0.155       0.261\n",
       "x694           0.0140      0.097      0.144      0.886      -0.179       0.207\n",
       "x695           0.0227      0.100      0.226      0.821      -0.177       0.222\n",
       "x696          -0.1453      0.107     -1.355      0.178      -0.358       0.067\n",
       "x697           0.0925      0.095      0.974      0.333      -0.096       0.281\n",
       "x698          -0.0542      0.092     -0.590      0.556      -0.236       0.128\n",
       "x699           0.0079      0.112      0.070      0.944      -0.214       0.230\n",
       "x700          -0.0023      0.089     -0.026      0.979      -0.179       0.175\n",
       "x701          -0.1276      0.091     -1.403      0.164      -0.308       0.053\n",
       "x702          -0.1266      0.098     -1.286      0.202      -0.322       0.069\n",
       "x703          -0.0085      0.097     -0.088      0.930      -0.201       0.184\n",
       "x704           0.0095      0.101      0.094      0.925      -0.191       0.210\n",
       "x705          -0.0976      0.093     -1.051      0.296      -0.282       0.087\n",
       "x706           0.0361      0.098      0.368      0.713      -0.158       0.230\n",
       "x707           0.0465      0.095      0.488      0.627      -0.143       0.236\n",
       "x708           0.0039      0.094      0.042      0.967      -0.183       0.190\n",
       "x709           0.1457      0.085      1.723      0.088      -0.022       0.313\n",
       "x710          -0.0188      0.097     -0.195      0.846      -0.211       0.173\n",
       "x711           0.1378      0.115      1.196      0.234      -0.091       0.366\n",
       "x712          -0.0785      0.097     -0.810      0.420      -0.271       0.114\n",
       "x713          -0.1894      0.099     -1.913      0.059      -0.386       0.007\n",
       "x714           0.0481      0.105      0.457      0.649      -0.161       0.257\n",
       "x715          -0.1206      0.094     -1.282      0.203      -0.307       0.066\n",
       "x716          -0.0205      0.092     -0.223      0.824      -0.203       0.162\n",
       "x717          -0.1686      0.102     -1.654      0.101      -0.371       0.034\n",
       "x718          -0.0115      0.090     -0.128      0.898      -0.190       0.167\n",
       "x719           0.1099      0.103      1.065      0.290      -0.095       0.315\n",
       "x720           0.0328      0.097      0.339      0.735      -0.159       0.224\n",
       "x721          -0.1353      0.101     -1.339      0.184      -0.336       0.065\n",
       "x722          -0.0409      0.096     -0.425      0.672      -0.232       0.150\n",
       "x723           0.2041      0.088      2.316      0.023       0.029       0.379\n",
       "x724          -0.0001      0.090     -0.002      0.999      -0.178       0.178\n",
       "x725           0.0908      0.103      0.880      0.381      -0.114       0.295\n",
       "x726          -0.0990      0.098     -1.011      0.314      -0.293       0.095\n",
       "x727          -0.1107      0.102     -1.081      0.282      -0.314       0.092\n",
       "x728           0.1882      0.096      1.959      0.053      -0.002       0.379\n",
       "x729           0.0570      0.106      0.540      0.590      -0.153       0.267\n",
       "x730          -0.0466      0.096     -0.487      0.628      -0.237       0.144\n",
       "x731           0.1224      0.098      1.247      0.215      -0.072       0.317\n",
       "x732          -0.1166      0.091     -1.282      0.203      -0.297       0.064\n",
       "x733           0.1651      0.094      1.748      0.084      -0.022       0.353\n",
       "x734           0.0208      0.098      0.212      0.833      -0.174       0.216\n",
       "x735          -0.0532      0.104     -0.510      0.611      -0.260       0.154\n",
       "x736           0.1062      0.091      1.171      0.244      -0.074       0.286\n",
       "x737          -0.1480      0.100     -1.482      0.142      -0.346       0.050\n",
       "x738          -0.0059      0.101     -0.059      0.953      -0.206       0.194\n",
       "x739           0.1053      0.111      0.947      0.346      -0.115       0.326\n",
       "x740          -0.0694      0.101     -0.686      0.494      -0.270       0.131\n",
       "x741           0.1218      0.094      1.298      0.197      -0.064       0.308\n",
       "x742           0.1819      0.097      1.878      0.063      -0.010       0.374\n",
       "x743          -0.0099      0.093     -0.106      0.916      -0.195       0.175\n",
       "x744          -0.0136      0.096     -0.142      0.887      -0.204       0.177\n",
       "x745          -0.0269      0.083     -0.326      0.745      -0.191       0.137\n",
       "x746          -0.0028      0.100     -0.028      0.978      -0.202       0.196\n",
       "x747           0.0538      0.098      0.551      0.583      -0.140       0.247\n",
       "x748          -0.0524      0.102     -0.515      0.608      -0.254       0.149\n",
       "x749          -0.1446      0.092     -1.567      0.120      -0.328       0.039\n",
       "x750           0.1018      0.093      1.097      0.275      -0.082       0.286\n",
       "x751          -0.1548      0.104     -1.492      0.139      -0.361       0.051\n",
       "x752           0.0150      0.109      0.138      0.890      -0.201       0.231\n",
       "x753          -0.1256      0.092     -1.365      0.175      -0.308       0.057\n",
       "x754           0.0013      0.107      0.012      0.990      -0.212       0.215\n",
       "x755          -0.0023      0.089     -0.026      0.979      -0.180       0.175\n",
       "x756          -0.0171      0.089     -0.192      0.848      -0.193       0.159\n",
       "x757       -7.481e-05      0.092     -0.001      0.999      -0.182       0.182\n",
       "x758          -0.1076      0.082     -1.310      0.193      -0.270       0.055\n",
       "x759           0.3098      0.096      3.220      0.002       0.119       0.501\n",
       "x760           0.1370      0.091      1.505      0.135      -0.044       0.318\n",
       "x761          -0.1119      0.091     -1.228      0.222      -0.293       0.069\n",
       "x762          -0.0823      0.104     -0.793      0.430      -0.288       0.124\n",
       "x763          -0.2148      0.108     -1.984      0.050      -0.430    6.41e-05\n",
       "x764           0.2981      0.118      2.525      0.013       0.064       0.532\n",
       "x765           0.1548      0.099      1.563      0.121      -0.042       0.351\n",
       "x766           0.0173      0.098      0.177      0.860      -0.177       0.212\n",
       "x767           0.1258      0.102      1.239      0.218      -0.076       0.327\n",
       "x768          -0.0273      0.093     -0.294      0.769      -0.211       0.157\n",
       "x769          -0.1941      0.103     -1.879      0.063      -0.399       0.011\n",
       "x770          -0.0685      0.092     -0.747      0.457      -0.250       0.113\n",
       "x771           0.0228      0.075      0.303      0.762      -0.126       0.172\n",
       "x772          -0.1868      0.100     -1.864      0.065      -0.386       0.012\n",
       "x773           0.0632      0.099      0.636      0.526      -0.134       0.260\n",
       "x774           0.0774      0.086      0.901      0.370      -0.093       0.248\n",
       "x775          -0.0447      0.090     -0.498      0.620      -0.223       0.133\n",
       "x776          -0.1334      0.091     -1.471      0.145      -0.313       0.047\n",
       "x777          -0.0079      0.099     -0.080      0.936      -0.204       0.189\n",
       "x778           0.0401      0.095      0.423      0.673      -0.148       0.228\n",
       "x779           0.0948      0.095      0.999      0.320      -0.094       0.283\n",
       "x780           0.0042      0.086      0.049      0.961      -0.166       0.174\n",
       "x781           0.1698      0.093      1.834      0.070      -0.014       0.354\n",
       "x782           0.0995      0.094      1.063      0.291      -0.086       0.285\n",
       "x783           0.0377      0.106      0.355      0.723      -0.173       0.249\n",
       "x784           0.1086      0.107      1.018      0.311      -0.103       0.320\n",
       "x785           0.1492      0.099      1.507      0.135      -0.047       0.346\n",
       "x786          -0.0329      0.086     -0.385      0.701      -0.203       0.137\n",
       "x787           0.0976      0.096      1.017      0.312      -0.093       0.288\n",
       "x788           0.1266      0.096      1.320      0.190      -0.064       0.317\n",
       "x789           0.0481      0.089      0.543      0.589      -0.128       0.224\n",
       "x790           0.2014      0.096      2.088      0.039       0.010       0.393\n",
       "x791           0.1015      0.103      0.989      0.325      -0.102       0.305\n",
       "x792          -0.1390      0.095     -1.460      0.148      -0.328       0.050\n",
       "x793          -0.0150      0.086     -0.175      0.862      -0.185       0.155\n",
       "x794          -0.0772      0.092     -0.840      0.403      -0.260       0.105\n",
       "x795          -0.1152      0.104     -1.106      0.271      -0.322       0.092\n",
       "x796           0.0383      0.104      0.367      0.714      -0.169       0.245\n",
       "x797          -0.1142      0.095     -1.203      0.232      -0.303       0.074\n",
       "x798           0.0414      0.086      0.483      0.630      -0.129       0.211\n",
       "x799           0.0199      0.094      0.212      0.833      -0.166       0.206\n",
       "x800          -0.1120      0.090     -1.250      0.214      -0.290       0.066\n",
       "x801          -0.1437      0.097     -1.476      0.143      -0.337       0.050\n",
       "x802           0.0449      0.087      0.515      0.608      -0.128       0.218\n",
       "x803          -0.1140      0.094     -1.209      0.229      -0.301       0.073\n",
       "x804          -0.0473      0.096     -0.491      0.624      -0.238       0.144\n",
       "x805          -0.0453      0.103     -0.440      0.661      -0.249       0.159\n",
       "x806          -0.0876      0.090     -0.970      0.334      -0.267       0.092\n",
       "x807          -0.0086      0.092     -0.093      0.926      -0.192       0.174\n",
       "x808           0.0618      0.094      0.659      0.512      -0.124       0.248\n",
       "x809           0.0244      0.101      0.242      0.809      -0.175       0.224\n",
       "x810          -0.1666      0.093     -1.801      0.075      -0.350       0.017\n",
       "x811          -0.1080      0.099     -1.094      0.277      -0.304       0.088\n",
       "x812          -0.0944      0.105     -0.895      0.373      -0.304       0.115\n",
       "x813          -0.0607      0.088     -0.687      0.494      -0.236       0.115\n",
       "x814           0.0012      0.106      0.011      0.991      -0.209       0.211\n",
       "x815           0.1062      0.117      0.910      0.365      -0.125       0.338\n",
       "x816           0.0348      0.098      0.353      0.724      -0.161       0.230\n",
       "x817          -0.0486      0.095     -0.509      0.612      -0.238       0.141\n",
       "x818           0.0120      0.105      0.115      0.909      -0.196       0.220\n",
       "x819           0.0937      0.094      0.995      0.322      -0.093       0.280\n",
       "x820          -0.0093      0.105     -0.088      0.930      -0.218       0.200\n",
       "x821           0.1028      0.091      1.133      0.260      -0.077       0.283\n",
       "x822           0.0507      0.105      0.483      0.630      -0.158       0.259\n",
       "x823           0.0586      0.085      0.686      0.494      -0.111       0.228\n",
       "x824           0.0817      0.096      0.851      0.397      -0.109       0.272\n",
       "x825          -0.0786      0.097     -0.809      0.420      -0.271       0.114\n",
       "x826          -0.0036      0.097     -0.037      0.970      -0.195       0.188\n",
       "x827           0.0773      0.088      0.879      0.382      -0.097       0.252\n",
       "x828          -0.1818      0.089     -2.054      0.043      -0.357      -0.006\n",
       "x829          -0.0755      0.088     -0.856      0.394      -0.251       0.100\n",
       "x830           0.0312      0.084      0.372      0.711      -0.135       0.198\n",
       "x831          -0.0341      0.103     -0.330      0.742      -0.239       0.171\n",
       "x832           0.1999      0.113      1.765      0.081      -0.025       0.425\n",
       "x833          -0.0139      0.093     -0.149      0.882      -0.199       0.171\n",
       "x834           0.1078      0.106      1.014      0.313      -0.103       0.319\n",
       "x835           0.0475      0.096      0.496      0.621      -0.142       0.237\n",
       "x836           0.1624      0.101      1.614      0.110      -0.037       0.362\n",
       "x837           0.1401      0.092      1.520      0.132      -0.043       0.323\n",
       "x838           0.0264      0.098      0.269      0.789      -0.168       0.221\n",
       "x839          -0.0576      0.110     -0.525      0.601      -0.275       0.160\n",
       "x840           0.1127      0.089      1.264      0.209      -0.064       0.290\n",
       "x841          -0.1813      0.104     -1.737      0.086      -0.388       0.026\n",
       "x842          -0.0268      0.098     -0.274      0.785      -0.221       0.167\n",
       "x843           0.0769      0.089      0.865      0.389      -0.099       0.253\n",
       "x844          -0.1635      0.097     -1.678      0.097      -0.357       0.030\n",
       "x845          -0.0319      0.099     -0.324      0.747      -0.228       0.164\n",
       "x846           0.0618      0.094      0.659      0.511      -0.124       0.248\n",
       "x847           0.2039      0.097      2.091      0.039       0.010       0.397\n",
       "x848           0.1858      0.094      1.975      0.051      -0.001       0.372\n",
       "x849          -0.1376      0.105     -1.309      0.193      -0.346       0.071\n",
       "x850           0.0151      0.106      0.142      0.887      -0.195       0.225\n",
       "x851          -0.3684      0.097     -3.785      0.000      -0.562      -0.175\n",
       "x852          -0.0086      0.092     -0.094      0.925      -0.190       0.173\n",
       "x853           0.0020      0.094      0.021      0.983      -0.185       0.189\n",
       "x854          -0.0269      0.103     -0.261      0.795      -0.232       0.178\n",
       "x855          -0.0435      0.082     -0.528      0.598      -0.207       0.120\n",
       "x856           0.0576      0.098      0.586      0.559      -0.137       0.253\n",
       "x857           0.0093      0.100      0.093      0.926      -0.189       0.208\n",
       "x858           0.1357      0.085      1.601      0.113      -0.033       0.304\n",
       "x859          -0.0513      0.088     -0.586      0.559      -0.225       0.122\n",
       "x860          -0.0874      0.090     -0.975      0.332      -0.265       0.090\n",
       "x861           0.2403      0.088      2.726      0.008       0.065       0.415\n",
       "x862          -0.1982      0.086     -2.297      0.024      -0.369      -0.027\n",
       "x863          -0.1587      0.105     -1.517      0.132      -0.366       0.049\n",
       "x864           0.0047      0.089      0.054      0.957      -0.171       0.181\n",
       "x865          -0.0858      0.102     -0.844      0.401      -0.288       0.116\n",
       "x866          -0.0900      0.093     -0.967      0.336      -0.275       0.095\n",
       "x867           0.2366      0.108      2.185      0.031       0.022       0.451\n",
       "x868           0.1702      0.097      1.746      0.084      -0.023       0.364\n",
       "x869           0.1215      0.101      1.197      0.234      -0.080       0.323\n",
       "x870           0.1027      0.094      1.093      0.277      -0.084       0.289\n",
       "x871          -0.0438      0.097     -0.451      0.653      -0.237       0.149\n",
       "x872          -0.0659      0.099     -0.667      0.506      -0.262       0.130\n",
       "x873           0.1358      0.104      1.311      0.193      -0.070       0.341\n",
       "x874          -0.0918      0.099     -0.925      0.357      -0.289       0.105\n",
       "x875          -0.0199      0.091     -0.218      0.828      -0.201       0.161\n",
       "x876           0.0080      0.097      0.082      0.935      -0.185       0.201\n",
       "x877           0.1482      0.100      1.475      0.143      -0.051       0.348\n",
       "x878          -0.0637      0.089     -0.719      0.474      -0.240       0.112\n",
       "x879          -0.0786      0.105     -0.745      0.458      -0.288       0.131\n",
       "x880          -0.0327      0.109     -0.301      0.764      -0.248       0.183\n",
       "x881           0.1002      0.100      0.998      0.321      -0.099       0.299\n",
       "x882           0.1198      0.090      1.325      0.188      -0.060       0.299\n",
       "x883          -0.1121      0.094     -1.190      0.237      -0.299       0.075\n",
       "x884           0.0974      0.084      1.154      0.251      -0.070       0.265\n",
       "x885          -0.0237      0.089     -0.266      0.791      -0.201       0.153\n",
       "x886           0.0121      0.104      0.116      0.908      -0.195       0.219\n",
       "x887           0.0511      0.102      0.500      0.618      -0.152       0.254\n",
       "x888          -0.0946      0.085     -1.109      0.270      -0.264       0.075\n",
       "x889          -0.1491      0.098     -1.525      0.130      -0.343       0.045\n",
       "x890           0.0251      0.099      0.253      0.801      -0.172       0.222\n",
       "x891           0.0160      0.094      0.170      0.865      -0.171       0.203\n",
       "x892           0.2295      0.104      2.216      0.029       0.024       0.435\n",
       "x893          -0.1777      0.094     -1.889      0.062      -0.364       0.009\n",
       "x894           0.1173      0.088      1.339      0.184      -0.057       0.291\n",
       "x895           0.1574      0.100      1.581      0.117      -0.040       0.355\n",
       "x896          -0.0228      0.088     -0.259      0.796      -0.198       0.152\n",
       "x897           0.1480      0.098      1.510      0.134      -0.047       0.343\n",
       "x898          -0.1257      0.095     -1.322      0.189      -0.314       0.063\n",
       "x899          -0.0872      0.086     -1.012      0.314      -0.258       0.084\n",
       "x900           0.0684      0.112      0.613      0.542      -0.153       0.290\n",
       "x901          -0.0006      0.104     -0.005      0.996      -0.208       0.207\n",
       "==============================================================================\n",
       "Omnibus:                        4.158   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.125   Jarque-Bera (JB):                4.634\n",
       "Skew:                          -0.062   Prob(JB):                       0.0986\n",
       "Kurtosis:                       3.309   Cond. No.                         36.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the regression\n",
    "model = sm.OLS(IV_data[1][:,None], np.hstack((np.ones([N,1]), Z, np.random.randn(N,900))))\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660a757",
   "metadata": {},
   "source": [
    "Indeed, the F-statistic is rather small. Even though the bias in the 2SLS coefficients should vanish asymptotically, the literature finds that it can nonetheless be substantial even with an enormous number of observations! The take away here is that you should not take weak instruments lightly and that just adding all potentially available instruments is not guaranteed to solve the endogeneity problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc81085",
   "metadata": {},
   "source": [
    "# 3.0 DiD estimation:\n",
    "\n",
    "To illustrate how DiD works, we are again writing a small simulation function. To make things less abstract, let's assume the following:\n",
    "\n",
    "* $Y$ is some measure of employment for a random selection of companies. The government wants us to evaluate a program that is supposed to boost employment. \n",
    "\n",
    "To construct our DiD estimator, we need observations for a treatment and a control group before and after treatment. In particular, we need to simulate:\n",
    "\n",
    "* The control group, both, before and after treatment\n",
    "* The treatment group, both, before and after treatment\n",
    "\n",
    "In our setup, $\\alpha_c$ and $\\alpha_t$ are going to denote the intercept or level of employment and $\\beta_c$ and $\\beta_t$ are going to denote the path of employment for the treatment and the control group. We will look at the data in a second, so don't worry, if this sounds abstract at the moment. \n",
    "\n",
    "Let's start by setting up a simulation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61e43803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simul_DiD(N, αc, αt, βc, βt):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function simulates basic data to illustrate DiD estimation of treatment effects. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate data for the control group\n",
    "    # before treatment\n",
    "    #εc = np.random.randn(N)\n",
    "    Y00 = αc + np.random.randn(N)\n",
    "    # after treatment\n",
    "    Y01 = αc + βc*1 + np.random.randn(N)\n",
    "    \n",
    "    # Simulate data for the treatment group\n",
    "    # before treatment\n",
    "    #εt = np.random.randn(N)\n",
    "    Y10 = αt + np.random.randn(N)\n",
    "    # after treatment\n",
    "    Y11 = αt + βt*1 + np.random.randn(N)\n",
    "    \n",
    "    return Y00, Y01, Y10, Y11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c96b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "αc = 0.5\n",
    "αt = 1\n",
    "βc = 0.5\n",
    "βt = 1\n",
    "\n",
    "# simulate some data\n",
    "data = simul_DiD(N, αc, αt, βc, βt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c945d",
   "metadata": {},
   "source": [
    "With the data simulated, we can now look at the path of employment for the treatment and the control group before and after treatment. We will also construct a counterfactual. A counterfactual is a hypothetical and unobserved quantity that indicates how employment in the treatment group would have developed in the absence of treatment. For this reason, the common trend assumption requires that the treatment and the control group evolved similarly before treatment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cae7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read out the simulated data\n",
    "Y00 = data[0]\n",
    "Y01 = data[1]\n",
    "Y10 = data[2]\n",
    "Y11 = data[3]\n",
    "\n",
    "# plot the control and treatment group\n",
    "c = np.vstack((Y00, Y01))\n",
    "t = np.vstack((Y10, Y11))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.mean(c, axis=1), label='control group')\n",
    "ax.plot(np.mean(t, axis=1), label='treatment group')\n",
    "ax.plot(np.mean(c +(np.mean(Y10) - np.mean(Y00)), axis=1),'--', label='counterfactual')\n",
    "plt.xticks(np.arange(0, 1.1, 1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedd93f",
   "metadata": {},
   "source": [
    "Think about why this makes sense. If we simply computed the difference between the control and the treatment group, we would falsely attribute the difference between the treatment and the control group that existed prior to treatment to the treatment effect. If we simply computed the difference between the treatment group before and after treatment, however, we would falsely attribute the growth that seems to happen regardless of the treatment (the positive slope) to the treatment effect. Thus we need to control for the differences across time and across groups.  \n",
    "\n",
    "The treatment effect is hence given as the difference between the counterfactual and the treatment group. The treatment effect can hence also be computed using:\n",
    "\n",
    "| Y          |    D = 1                         |     D = 0                       | Difference  |\n",
    "| :---       |    :----:                        |     :----:                      |     :----:  |\n",
    "| T = 1      |$\\bar {Y_{11}}$                   |$\\bar {Y_{10}}$                  |$\\bar {Y_{10}}$ - $\\bar {Y_{11}}$|\n",
    "| T = 0      |$\\bar {Y_{01}}$                   |$\\bar {Y_{00}}$                  |$\\bar {Y_{00}}$ - $\\bar {Y_{01}}$|\n",
    "| Change     |$\\bar {Y_{01}}$ - $\\bar {Y_{11}}$ |$\\bar {Y_{00}}$ - $\\bar {Y_{10}}$|($\\bar {Y_{00}}$ - $\\bar {Y_{01}}$)-($\\bar {Y_{10}}$ - $\\bar {Y_{11}}$)| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473802c",
   "metadata": {},
   "source": [
    "The bottom right cell thus gives us the treatment effect. We can hence also calculate it using the respective formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29529220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.500271401413526"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TE = (np.mean(Y00)-np.mean(Y01))-(np.mean(Y10)-np.mean(Y11))\n",
    "TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e94688",
   "metadata": {},
   "source": [
    "It turns out, however, that we can also calculate the treatment effect using the following regression:\n",
    "\n",
    "$$\n",
    "Y = \\alpha + \\beta_1\\cdot T + \\beta_2\\cdot  D + \\beta_3\\cdot (T\\cdot D) + u\n",
    "$$\n",
    "\n",
    "In this case the treatment effect will be given as the coefficient on the interaction term, $\\beta_3$. To see this, let us recycle our table from above and fill the cells with the regression coefficients that result conditional on $T$ and $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f9721",
   "metadata": {},
   "source": [
    "| Y          |    D = 1     |   D = 0      | Difference  |\n",
    "| :---       |    :----:    |   :----:     |     :----:  |\n",
    "| T = 1      | 𝛼+𝛽1+𝛽2+𝛽3   |   𝛼+𝛽1       |  𝛽2+𝛽3      |\n",
    "| T = 0      | 𝛼+𝛽2         |   𝛼          |  𝛽2         |\n",
    "| Change     | 𝛽1+𝛽3        |   𝛽1         |  𝛽3         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc1a1e",
   "metadata": {},
   "source": [
    "Before we proceed with estimation, we need to set up the treatment dummy ($D$) - indicating the before/after treatment period - and the dummy identifying the control and the treatment group ($T$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c2fd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>D</th>\n",
       "      <th>TD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>1.726686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>1.127512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>-0.437296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>2.331875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>2.082195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y    T    D   TD\n",
       "4253  1.726686  0.0  1.0  0.0\n",
       "7522  1.127512  1.0  1.0  1.0\n",
       "1084 -0.437296  0.0  0.0  0.0\n",
       "5110  2.331875  0.0  1.0  0.0\n",
       "893   2.082195  0.0  0.0  0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the control and treatment groups with the T and D dummies\n",
    "C = np.hstack((np.hstack((Y00, Y01))[:,None], np.vstack((np.zeros([N,1]), np.ones([N,1]))), np.zeros([2*N,1])))\n",
    "T = np.hstack((np.hstack((Y10, Y11))[:,None], np.vstack((np.zeros([N,1]), np.ones([N,1]))), np.ones([2*N,1])))\n",
    "\n",
    "# stack all observations\n",
    "data = np.vstack((C, T))\n",
    "\n",
    "# let's randmoize the row order and look at our data in a dataframe\n",
    "data = pd.DataFrame(data, columns=['Y', 'T', 'D'])\n",
    "data = data.sample(frac=1)\n",
    "data['TD'] = data['T'] * data['D']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0cd712",
   "metadata": {},
   "source": [
    "With the data in place, we can now run the regression above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2db57e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.222</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.221</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   759.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:26:58</td>     <th>  Log-Likelihood:    </th> <td> -11291.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8000</td>      <th>  AIC:               </th> <td>2.259e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  7996</td>      <th>  BIC:               </th> <td>2.262e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5139</td> <td>    0.022</td> <td>   23.152</td> <td> 0.000</td> <td>    0.470</td> <td>    0.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4673</td> <td>    0.031</td> <td>   14.887</td> <td> 0.000</td> <td>    0.406</td> <td>    0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.4883</td> <td>    0.031</td> <td>   15.557</td> <td> 0.000</td> <td>    0.427</td> <td>    0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.5003</td> <td>    0.044</td> <td>   11.269</td> <td> 0.000</td> <td>    0.413</td> <td>    0.587</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.558</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.278</td> <th>  Jarque-Bera (JB):  </th> <td>   2.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.043</td> <th>  Prob(JB):          </th> <td>   0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.980</td> <th>  Cond. No.          </th> <td>    6.85</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.222\n",
       "Model:                            OLS   Adj. R-squared:                  0.221\n",
       "Method:                 Least Squares   F-statistic:                     759.5\n",
       "Date:                Fri, 23 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        19:26:58   Log-Likelihood:                -11291.\n",
       "No. Observations:                8000   AIC:                         2.259e+04\n",
       "Df Residuals:                    7996   BIC:                         2.262e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5139      0.022     23.152      0.000       0.470       0.557\n",
       "x1             0.4673      0.031     14.887      0.000       0.406       0.529\n",
       "x2             0.4883      0.031     15.557      0.000       0.427       0.550\n",
       "x3             0.5003      0.044     11.269      0.000       0.413       0.587\n",
       "==============================================================================\n",
       "Omnibus:                        2.558   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.278   Jarque-Bera (JB):                2.581\n",
       "Skew:                          -0.043   Prob(JB):                        0.275\n",
       "Kurtosis:                       2.980   Cond. No.                         6.85\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate input arguments for regression\n",
    "Y = np.asarray(data.Y)[:,None]\n",
    "X = np.hstack((np.ones([Y.shape[0],1]), np.asarray(data['T'])[:,None], np.asarray(data.D)[:,None], np.asarray(data['TD'])[:,None]))\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843477b2",
   "metadata": {},
   "source": [
    "As you can see, $\\beta_3$ in indeed the same as the treatment effect that we estimated above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a31598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
