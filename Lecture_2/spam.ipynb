{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSMBY0cJUdJMaNw1tna1zt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BI-DS/EBA-3530/blob/main/Lecture_2/spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spam detection with the Logistic Regression"
      ],
      "metadata": {
        "id": "YzilEDoGODau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "jsdLDiRlONmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data directly from github\n",
        "url = 'https://raw.githubusercontent.com/BI-DS/EBA-3530/main/Lecture_2/spam.csv'\n",
        "df = pd.read_csv(url, delimiter=',')\n",
        "\n",
        "# print no. of rows and columns\n",
        "print(df.shape)\n",
        "\n",
        "# print a summary of the data\n",
        "print(df.head(5))\n",
        "\n",
        "# print variable names\n",
        "print(list(df))"
      ],
      "metadata": {
        "id": "RnHRX2TSOHoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visualization"
      ],
      "metadata": {
        "id": "lThtyMjO8dAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2)\n",
        "num_mails = np.linspace(0,df.shape[0], num=df.shape[0])\n",
        "\n",
        "ax[0].step(num_mails, df.word_free)\n",
        "ax[0].set(xlabel='mail number')\n",
        "ax[0].set(ylabel='count or no count')\n",
        "\n",
        "ax[1].step(num_mails, df.word_meeting)\n",
        "ax[1].set(xlabel='mail number')\n",
        "ax[1].set(ylabel='count or no count')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ewU-evFPN9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Logistic regression"
      ],
      "metadata": {
        "id": "Y-rxt9lzV9gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use statsmodels in python\n",
        "\n",
        "# get y variable an x variables\n",
        "y = df.spam\n",
        "# get all variables, but y, to fit a logistic regression\n",
        "x = df.drop(columns=['spam']).copy()\n",
        "\n",
        "# add an intercept term beta_0\n",
        "x = sm.add_constant(x)\n",
        "logistic_regression = sm.Logit(y, x).fit()\n",
        "print(logistic_regression.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL95xFb5OXJI",
        "outputId": "c3e6aea0-2820-4573-cc1e-a1c4087c9cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  x = pd.concat(x[::order], 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.168296\n",
            "         Iterations 12\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                   spam   No. Observations:                 4601\n",
            "Model:                          Logit   Df Residuals:                     4543\n",
            "Method:                           MLE   Df Model:                           57\n",
            "Date:                Wed, 25 Jan 2023   Pseudo R-squ.:                  0.7490\n",
            "Time:                        14:13:17   Log-Likelihood:                -774.33\n",
            "converged:                       True   LL-Null:                       -3085.1\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "==============================================================================================\n",
            "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------------\n",
            "const                         -1.9682      0.147    -13.429      0.000      -2.256      -1.681\n",
            "word_make                     -0.5530      0.236     -2.346      0.019      -1.015      -0.091\n",
            "word_address                  -0.1339      0.222     -0.604      0.546      -0.568       0.301\n",
            "word_all                      -0.4946      0.178     -2.786      0.005      -0.843      -0.147\n",
            "word_3d                        0.8302      0.824      1.007      0.314      -0.786       2.446\n",
            "word_our                       1.1253      0.174      6.471      0.000       0.784       1.466\n",
            "word_over                      0.2751      0.222      1.238      0.216      -0.160       0.711\n",
            "word_remove                    2.4881      0.276      9.013      0.000       1.947       3.029\n",
            "word_internet                  0.9334      0.252      3.702      0.000       0.439       1.428\n",
            "word_order                     0.2196      0.277      0.793      0.428      -0.323       0.762\n",
            "word_mail                      0.3081      0.195      1.579      0.114      -0.074       0.691\n",
            "word_receive                  -0.4392      0.279     -1.576      0.115      -0.985       0.107\n",
            "word_will                     -0.3106      0.160     -1.943      0.052      -0.624       0.003\n",
            "word_people                   -0.9586      0.255     -3.765      0.000      -1.458      -0.460\n",
            "word_report                    0.8467      0.343      2.471      0.013       0.175       1.518\n",
            "word_addresses                 1.2553      0.558      2.248      0.025       0.161       2.350\n",
            "word_free                      1.5427      0.179      8.621      0.000       1.192       1.893\n",
            "word_business                  1.0566      0.250      4.221      0.000       0.566       1.547\n",
            "word_email                    -0.5201      0.211     -2.462      0.014      -0.934      -0.106\n",
            "word_you                       0.1628      0.173      0.944      0.345      -0.175       0.501\n",
            "word_credit                    0.4160      0.409      1.017      0.309      -0.386       1.218\n",
            "word_your                      0.6950      0.171      4.063      0.000       0.360       1.030\n",
            "word_font                      1.2999      0.437      2.974      0.003       0.443       2.157\n",
            "word_000                       1.0350      0.309      3.348      0.001       0.429       1.641\n",
            "word_money                     1.7301      0.299      5.784      0.000       1.144       2.316\n",
            "word_hp                       -3.6044      0.387     -9.316      0.000      -4.363      -2.846\n",
            "word_hpl                      -0.1806      0.409     -0.442      0.659      -0.982       0.620\n",
            "word_george                   -5.7798      0.758     -7.623      0.000      -7.266      -4.294\n",
            "word_650                       2.1047      0.408      5.164      0.000       1.306       2.904\n",
            "word_lab                      -0.6635      0.509     -1.303      0.193      -1.662       0.335\n",
            "word_labs                     -0.1804      0.456     -0.395      0.693      -1.075       0.714\n",
            "word_telnet                   -2.3018      1.099     -2.094      0.036      -4.456      -0.147\n",
            "word_857                      -1.4455      1.271     -1.137      0.256      -3.937       1.046\n",
            "word_data                     -0.7849      0.372     -2.111      0.035      -1.514      -0.056\n",
            "word_415                       0.9195      1.333      0.690      0.490      -1.692       3.531\n",
            "word_85                       -1.7312      0.606     -2.855      0.004      -2.920      -0.543\n",
            "word_technology                0.3720      0.319      1.167      0.243      -0.253       0.997\n",
            "word_1999                     -1.0922      0.279     -3.918      0.000      -1.639      -0.546\n",
            "word_parts                     1.5572      0.613      2.541      0.011       0.356       2.758\n",
            "word_pm                       -0.5686      0.359     -1.583      0.113      -1.273       0.135\n",
            "word_direct                   -0.2828      0.488     -0.579      0.563      -1.240       0.674\n",
            "word_cs                       -6.2967      3.440     -1.830      0.067     -13.039       0.446\n",
            "word_meeting                  -2.5034      0.458     -5.461      0.000      -3.402      -1.605\n",
            "word_original                 -1.2429      0.517     -2.404      0.016      -2.256      -0.229\n",
            "word_project                  -1.6186      0.428     -3.785      0.000      -2.457      -0.780\n",
            "word_re                       -1.0258      0.179     -5.737      0.000      -1.376      -0.675\n",
            "word_edu                      -2.4268      0.322     -7.542      0.000      -3.057      -1.796\n",
            "word_table                     0.2854      0.877      0.326      0.745      -1.433       2.003\n",
            "word_conference               -2.2234      0.582     -3.820      0.000      -3.364      -1.083\n",
            "char_semicolon                -0.2929      0.226     -1.298      0.194      -0.735       0.149\n",
            "char_leftbrac                  0.1257      0.154      0.818      0.413      -0.175       0.427\n",
            "char_leftsquarebrac           -0.3345      0.368     -0.910      0.363      -1.055       0.386\n",
            "char_exclaim                   1.3427      0.146      9.220      0.000       1.057       1.628\n",
            "char_dollar                    1.8707      0.207      9.016      0.000       1.464       2.277\n",
            "char_pound                    -0.8187      0.283     -2.890      0.004      -1.374      -0.263\n",
            "capital_run_length_average    -0.0031      0.016     -0.198      0.843      -0.034       0.028\n",
            "capital_run_length_longest     0.0060      0.003      2.050      0.040       0.000       0.012\n",
            "capital_run_length_total       0.0008      0.000      1.791      0.073   -7.89e-05       0.002\n",
            "==============================================================================================\n",
            "\n",
            "Possibly complete quasi-separation: A fraction 0.17 of observations can be\n",
            "perfectly predicted. This might indicate that there is complete\n",
            "quasi-separation. In this case some parameters will not be identified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.read_html(logistic_regression.summary().tables[1].as_html(),header=0,index_col=0)[0]\n",
        "word_free_coeff = results['coef'][results['coef'].index=='word_free'].values[0]\n",
        "CI_LB = results['[0.025'][results['coef'].index=='word_free'].values[0]\n",
        "CI_UB = results['0.975]'][results['coef'].index=='word_free'].values[0]\n",
        "# Remember the log odds: log(p/(1-p)), meaning that the odds of an event\n",
        "# are the probabilities that it happend over the probability that it does\n",
        "# not.\n",
        "\n",
        "# The coefficients here are related to the log odds:\n",
        "# log(p/(1-p)) = x'B where B are the coefficients and p the probablity for\n",
        "# spam and 1-p the probability for not spam\n",
        "# The odds of spam when the word_free occurs\n",
        "print('The odds for spam increases {0:.1f} times that its coefficient '\\\n",
        "      'is {1:.4f} with confidence interval between {2:.4f} and {3:.4f}'\\\n",
        "      .format(np.exp(word_free_coeff), word_free_coeff, CI_LB, CI_UB))\n",
        "# I.e., the odds of spam increases almost 5 times if the mail contains the\n",
        "# word spam!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeBwN4dfX0PA",
        "outputId": "ea8ec32a-d4f6-4a25-c877-7987f9e541e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The odds for spam increases 4.7 times that its coefficient is 1.5427 with confidence interval between 1.1920 and 1.8930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction for mail number 1 and 4000\n",
        "# i.e. p(y|x)=exp(x'B)/(1+exp(x'B))\n",
        "logistic_regression.predict(x)[[0,3999]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZbFqCy1Brbz",
        "outputId": "bb6b9a5a-d1db-4020-a0b7-3a4e32383efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.883907\n",
              "3999    0.150999\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one parameter logistic regression\n",
        "x = df.word_free\n",
        "logistic_regression = sm.Logit(y, x).fit()\n",
        "print(logistic_regression.summary())"
      ],
      "metadata": {
        "id": "k_2IXGe7X9PT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}